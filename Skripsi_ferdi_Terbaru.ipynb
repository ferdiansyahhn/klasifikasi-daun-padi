{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5ef7415b-a6ae-4639-a365-4b296ce817bc",
      "metadata": {
        "id": "5ef7415b-a6ae-4639-a365-4b296ce817bc"
      },
      "source": [
        "# Rice Crops Diseases Detection Using ResNet50 Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6b4d13b-1346-4b98-b772-a3a9d868b015",
      "metadata": {
        "id": "c6b4d13b-1346-4b98-b772-a3a9d868b015"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2b3bf6c7-c426-44ef-8713-a6eb18915122",
      "metadata": {
        "id": "2b3bf6c7-c426-44ef-8713-a6eb18915122"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras import layers, optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "_E9teUIpG1gY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_E9teUIpG1gY",
        "outputId": "67390d49-f48d-4e8e-bd06-8271365a9af6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Dataset configuration\n",
        "DATASET_PATH = '/content/drive/MyDrive/gambar padi'\n",
        "CLASS_NAMES = ['berat', 'sedang', 'sehat-ringan']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WUn6Nk3jpc9s",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUn6Nk3jpc9s",
        "outputId": "c7db9173-6a0e-4ad5-ef73-8b4a3ae451e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sehat-ringan: 205 gambar\n",
            "sedang: 200 gambar\n",
            "berat: 200 gambar\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "dataset_path = '/content/drive/MyDrive/gambar padi'\n",
        "\n",
        "for class_name in os.listdir(dataset_path):\n",
        "    class_path = os.path.join(dataset_path, class_name)\n",
        "    if os.path.isdir(class_path):\n",
        "        print(f\"{class_name}: {len(os.listdir(class_path))} gambar\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c62c53d7-18cd-4785-b1a6-9035abc8fef0",
      "metadata": {
        "id": "c62c53d7-18cd-4785-b1a6-9035abc8fef0"
      },
      "source": [
        "# Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "9a0e3c75-e07f-4d82-bc29-0ee83ee2a771",
      "metadata": {
        "id": "9a0e3c75-e07f-4d82-bc29-0ee83ee2a771"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "num_classes = 3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "AuYlYsiNNZ2I",
      "metadata": {
        "id": "AuYlYsiNNZ2I"
      },
      "source": [
        "### SPLIT RATIO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "qt_TJPnnIlsJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qt_TJPnnIlsJ",
        "outputId": "ffaf14a8-d98c-4173-8592-6d15ef241d41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📦 Memproses rasio 70:30\n",
            "✅ Dataset berhasil dibagi dan disalin ke: /content/split_dataset_70\n",
            "\n",
            "📦 Memproses rasio 80:20\n",
            "✅ Dataset berhasil dibagi dan disalin ke: /content/split_dataset_80\n",
            "\n",
            "📦 Memproses rasio 90:10\n",
            "✅ Dataset berhasil dibagi dan disalin ke: /content/split_dataset_90\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Konfigurasi\n",
        "original_dataset_dir = '/content/drive/MyDrive/gambar padi'\n",
        "CLASS_NAMES = ['berat', 'sedang', 'sehat-ringan']\n",
        "\n",
        "# Rasio split yang ingin digunakan\n",
        "split_ratios = [0.7, 0.8, 0.9]\n",
        "\n",
        "for split_ratio in split_ratios:\n",
        "    train_percent = round(split_ratio * 100)\n",
        "    val_percent = round((1 - split_ratio) * 100)\n",
        "    print(f\"\\n📦 Memproses rasio {train_percent}:{val_percent}\")\n",
        "\n",
        "    # Path direktori baru\n",
        "    base_dir = f'/content/split_dataset_{train_percent}'\n",
        "    train_dir = os.path.join(base_dir, 'train')\n",
        "    val_dir = os.path.join(base_dir, 'val')\n",
        "\n",
        "    # Hapus folder lama jika ada\n",
        "    if os.path.exists(base_dir):\n",
        "        shutil.rmtree(base_dir)\n",
        "\n",
        "    # Buat struktur folder\n",
        "    for folder in [train_dir, val_dir]:\n",
        "        for class_name in CLASS_NAMES:\n",
        "            os.makedirs(os.path.join(folder, class_name), exist_ok=True)\n",
        "\n",
        "    # Proses pembagian dan penyalinan file\n",
        "    for class_name in CLASS_NAMES:\n",
        "        class_path = os.path.join(original_dataset_dir, class_name)\n",
        "        images = [f for f in os.listdir(class_path) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
        "\n",
        "        # Split data\n",
        "        train_imgs, val_imgs = train_test_split(images, train_size=split_ratio, random_state=42)\n",
        "\n",
        "        # Salin ke train\n",
        "        for img in train_imgs:\n",
        "            shutil.copy(\n",
        "                os.path.join(class_path, img),\n",
        "                os.path.join(train_dir, class_name, img)\n",
        "            )\n",
        "\n",
        "        # Salin ke val\n",
        "        for img in val_imgs:\n",
        "            shutil.copy(\n",
        "                os.path.join(class_path, img),\n",
        "                os.path.join(val_dir, class_name, img)\n",
        "            )\n",
        "\n",
        "    print(f\"✅ Dataset berhasil dibagi dan disalin ke: {base_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98ba7704-1e68-48b2-94a4-a105a489c2c0",
      "metadata": {
        "id": "98ba7704-1e68-48b2-94a4-a105a489c2c0"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a2bc8386-4845-4072-8e3f-17bb9f044a54",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2bc8386-4845-4072-8e3f-17bb9f044a54",
        "outputId": "66be6512-e965-4878-e357-bf9519584c73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-- Memuat data untuk rasio 70:30 --\n",
            "Found 423 images belonging to 3 classes.\n",
            "Found 182 images belonging to 3 classes.\n",
            "\n",
            "-- Memuat data untuk rasio 80:20 --\n",
            "Found 484 images belonging to 3 classes.\n",
            "Found 121 images belonging to 3 classes.\n",
            "\n",
            "-- Memuat data untuk rasio 90:10 --\n",
            "Found 544 images belonging to 3 classes.\n",
            "Found 61 images belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input  # Ganti sesuai model yang Anda gunakan\n",
        "import os\n",
        "\n",
        "# Parameter umum\n",
        "IMAGE_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "CLASS_NAMES = ['berat', 'sedang', 'sehat-ringan']\n",
        "split_ratios = [0.7, 0.8, 0.9]\n",
        "\n",
        "for split_ratio in split_ratios:\n",
        "    # Pembulatan untuk mencetak rasio dengan benar\n",
        "    train_percent = round(split_ratio * 100)\n",
        "    val_percent = round((1 - split_ratio) * 100)\n",
        "\n",
        "    print(f\"\\n-- Memuat data untuk rasio {train_percent}:{val_percent} --\")\n",
        "\n",
        "    # Path direktori dataset hasil split\n",
        "    base_dir = f'/content/split_dataset_{train_percent}'\n",
        "    train_dir = os.path.join(base_dir, 'train')\n",
        "    val_dir = os.path.join(base_dir, 'val')\n",
        "\n",
        "    # Augmentasi untuk data training\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        preprocessing_function=preprocess_input,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True\n",
        "    )\n",
        "\n",
        "    # Data validasi hanya preprocessing\n",
        "    val_datagen = ImageDataGenerator(\n",
        "        preprocessing_function=preprocess_input\n",
        "    )\n",
        "\n",
        "    # Generator untuk training\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical'\n",
        "    )\n",
        "\n",
        "    # Generator untuk validasi\n",
        "    val_generator = val_datagen.flow_from_directory(\n",
        "        val_dir,\n",
        "        target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1dc6daee-9ee2-4366-ab3f-f3000da066d8",
      "metadata": {
        "id": "1dc6daee-9ee2-4366-ab3f-f3000da066d8"
      },
      "source": [
        "# Create a training data generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a7d8db6d-e543-4f41-b995-297afa12e457",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7d8db6d-e543-4f41-b995-297afa12e457",
        "outputId": "765151af-d055-45a3-de9b-a74935276918"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 544 images belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_data_gen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "train_generator = train_data_gen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5619b989-d9e9-40d3-bbcd-fa27d0d5f100",
      "metadata": {
        "id": "5619b989-d9e9-40d3-bbcd-fa27d0d5f100"
      },
      "source": [
        "# Create ResNet Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "5c6252f9-611a-48f9-9d5c-4ddd84caf7db",
      "metadata": {
        "id": "5c6252f9-611a-48f9-9d5c-4ddd84caf7db"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "num_classes = 3  # Jumlah kelas\n",
        "\n",
        "def get_model():\n",
        "    # Load base ResNet50 tanpa fully connected layer\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "    # Freeze sebagian besar layer\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Bangun model baru di atasnya\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(0.5)(x)                    # ✅ Tambahkan dropout untuk regularisasi\n",
        "    x = Dense(128, activation='relu')(x)  # ✅ Kurangi ukuran layer Dense agar tidak terlalu kompleks\n",
        "    x = Dropout(0.5)(x)                    # ✅ Dropout kedua\n",
        "    outputs = Dense(num_classes, activation='softmax', name='fcnew')(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=outputs)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27cbc796-3bc8-4b49-a413-24e330cc5612",
      "metadata": {
        "id": "27cbc796-3bc8-4b49-a413-24e330cc5612"
      },
      "source": [
        "# Compile Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ef0bf6d0-e171-4757-b862-e82b89eddb9b",
      "metadata": {
        "id": "ef0bf6d0-e171-4757-b862-e82b89eddb9b"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "num_classes = 3  # Jumlah kelas\n",
        "\n",
        "def get_model():\n",
        "    # Base ResNet50 tanpa top layer\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "    # Bekukan semua layer awal (initial training phase)\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(0.5)(x)                    # Dropout untuk regularisasi\n",
        "    x = Dense(128, activation='relu')(x)  # Dense layer\n",
        "    x = Dropout(0.5)(x)                    # Dropout kedua\n",
        "    outputs = Dense(num_classes, activation='softmax', name='fcnew')(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# Fungsi untuk compile model\n",
        "def compile_model(lr=0.001):\n",
        "    model = get_model()\n",
        "    optimizer = Adam(learning_rate=lr)\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b113bf00-37bd-4bf4-acde-2f2064a2c1a8",
      "metadata": {
        "id": "b113bf00-37bd-4bf4-acde-2f2064a2c1a8"
      },
      "source": [
        "# Train the Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "1fpilPJlSPwI",
      "metadata": {
        "id": "1fpilPJlSPwI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras import optimizers, regularizers\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "import os\n",
        "\n",
        "IMAGE_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "num_classes = 3  # Jumlah kelas sesuai dataset Anda\n",
        "\n",
        "# Fungsi membuat dan compile model\n",
        "def compile_model(lr=0.001, l2_reg=1e-4):\n",
        "    base_model = tf.keras.applications.ResNet50(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)\n",
        "    )\n",
        "\n",
        "    # Freeze base model\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Custom classifier with Dropout + L2 regularization\n",
        "    x = GlobalAveragePooling2D()(base_model.output)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(128, activation='relu',\n",
        "              kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    output = Dense(num_classes, activation='softmax',\n",
        "                   kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "    optimizer = optimizers.SGD(learning_rate=lr, momentum=0.9, nesterov=True)\n",
        "\n",
        "    model.compile(\n",
        "        loss='categorical_crossentropy',\n",
        "        optimizer=optimizer,\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Fungsi training model\n",
        "def train_model(split_ratio, lr, epochs, l2_reg=1e-4):\n",
        "    split_percent = round(split_ratio * 100)\n",
        "    base_dir = f'/content/split_dataset_{split_percent}'\n",
        "    train_dir = os.path.join(base_dir, 'train')\n",
        "    val_dir = os.path.join(base_dir, 'val')\n",
        "\n",
        "    train_generator = ImageDataGenerator(\n",
        "        preprocessing_function=preprocess_input,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True\n",
        "    ).flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical'\n",
        "    )\n",
        "\n",
        "    val_generator = ImageDataGenerator(\n",
        "        preprocessing_function=preprocess_input\n",
        "    ).flow_from_directory(\n",
        "        val_dir,\n",
        "        target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    model = compile_model(lr=lr, l2_reg=l2_reg)\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        validation_data=val_generator,\n",
        "        epochs=epochs,\n",
        "        verbose=2\n",
        "    )\n",
        "\n",
        "    model_name = f'model_split{split_percent}_lr{lr}_ep{epochs}_l2{l2_reg}.h5'\n",
        "    model.save(model_name)\n",
        "    print(f\"✅ Model berhasil disimpan: {model_name}\")\n",
        "\n",
        "    return model, history\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8tk3JR3SifJh",
      "metadata": {
        "id": "8tk3JR3SifJh"
      },
      "source": [
        "### split ratio 0.7 Learning rate 0.001\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lAYt8UvElXZR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAYt8UvElXZR",
        "outputId": "8b36b94c-3eb1-4498-b9e5-315f4d104102"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📦 Training model dengan split_ratio=70%, learning_rate=0.001, epochs=50\n",
            "Found 423 images belonging to 3 classes.\n",
            "Found 182 images belonging to 3 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "14/14 - 167s - 12s/step - accuracy: 0.3877 - loss: 1.8157 - val_accuracy: 0.5220 - val_loss: 1.0039\n",
            "Epoch 2/50\n",
            "14/14 - 165s - 12s/step - accuracy: 0.4326 - loss: 1.4238 - val_accuracy: 0.5385 - val_loss: 0.9928\n",
            "Epoch 3/50\n",
            "14/14 - 188s - 13s/step - accuracy: 0.4421 - loss: 1.2638 - val_accuracy: 0.5440 - val_loss: 0.9374\n",
            "Epoch 4/50\n",
            "14/14 - 149s - 11s/step - accuracy: 0.4823 - loss: 1.0956 - val_accuracy: 0.5275 - val_loss: 0.9380\n",
            "Epoch 5/50\n",
            "14/14 - 149s - 11s/step - accuracy: 0.5035 - loss: 1.0468 - val_accuracy: 0.5330 - val_loss: 0.9229\n",
            "Epoch 6/50\n",
            "14/14 - 152s - 11s/step - accuracy: 0.5059 - loss: 1.0099 - val_accuracy: 0.5769 - val_loss: 0.9208\n",
            "Epoch 7/50\n",
            "14/14 - 235s - 17s/step - accuracy: 0.5225 - loss: 0.9903 - val_accuracy: 0.6099 - val_loss: 0.9064\n",
            "Epoch 8/50\n",
            "14/14 - 185s - 13s/step - accuracy: 0.5366 - loss: 1.0160 - val_accuracy: 0.5824 - val_loss: 0.9125\n",
            "Epoch 9/50\n",
            "14/14 - 148s - 11s/step - accuracy: 0.5461 - loss: 0.9721 - val_accuracy: 0.5989 - val_loss: 0.9069\n",
            "Epoch 10/50\n",
            "14/14 - 192s - 14s/step - accuracy: 0.5839 - loss: 0.8945 - val_accuracy: 0.6209 - val_loss: 0.8994\n",
            "Epoch 11/50\n",
            "14/14 - 149s - 11s/step - accuracy: 0.5863 - loss: 0.9173 - val_accuracy: 0.5934 - val_loss: 0.8917\n",
            "Epoch 12/50\n",
            "14/14 - 153s - 11s/step - accuracy: 0.5626 - loss: 0.9381 - val_accuracy: 0.6429 - val_loss: 0.8766\n",
            "Epoch 13/50\n",
            "14/14 - 153s - 11s/step - accuracy: 0.5839 - loss: 0.9115 - val_accuracy: 0.6484 - val_loss: 0.8465\n",
            "Epoch 14/50\n",
            "14/14 - 234s - 17s/step - accuracy: 0.5792 - loss: 0.9311 - val_accuracy: 0.6154 - val_loss: 0.8540\n",
            "Epoch 15/50\n",
            "14/14 - 147s - 10s/step - accuracy: 0.5768 - loss: 0.9103 - val_accuracy: 0.6374 - val_loss: 0.8498\n",
            "Epoch 16/50\n",
            "14/14 - 208s - 15s/step - accuracy: 0.5579 - loss: 0.9273 - val_accuracy: 0.6319 - val_loss: 0.8527\n",
            "Epoch 17/50\n",
            "14/14 - 186s - 13s/step - accuracy: 0.6123 - loss: 0.8796 - val_accuracy: 0.6538 - val_loss: 0.8427\n",
            "Epoch 18/50\n",
            "14/14 - 187s - 13s/step - accuracy: 0.5816 - loss: 0.9160 - val_accuracy: 0.6264 - val_loss: 0.8504\n",
            "Epoch 19/50\n",
            "14/14 - 186s - 13s/step - accuracy: 0.6170 - loss: 0.8365 - val_accuracy: 0.5934 - val_loss: 0.8504\n",
            "Epoch 20/50\n",
            "14/14 - 203s - 15s/step - accuracy: 0.6478 - loss: 0.8378 - val_accuracy: 0.6209 - val_loss: 0.8284\n",
            "Epoch 21/50\n",
            "14/14 - 148s - 11s/step - accuracy: 0.6099 - loss: 0.8907 - val_accuracy: 0.6374 - val_loss: 0.8182\n",
            "Epoch 22/50\n",
            "14/14 - 144s - 10s/step - accuracy: 0.6312 - loss: 0.8471 - val_accuracy: 0.6648 - val_loss: 0.8107\n",
            "Epoch 23/50\n",
            "14/14 - 148s - 11s/step - accuracy: 0.6288 - loss: 0.8520 - val_accuracy: 0.6648 - val_loss: 0.8115\n",
            "Epoch 24/50\n",
            "14/14 - 148s - 11s/step - accuracy: 0.6478 - loss: 0.7892 - val_accuracy: 0.6484 - val_loss: 0.7944\n",
            "Epoch 25/50\n",
            "14/14 - 185s - 13s/step - accuracy: 0.6667 - loss: 0.7511 - val_accuracy: 0.6429 - val_loss: 0.7892\n",
            "Epoch 26/50\n",
            "14/14 - 164s - 12s/step - accuracy: 0.6548 - loss: 0.8048 - val_accuracy: 0.6538 - val_loss: 0.7821\n",
            "Epoch 27/50\n",
            "14/14 - 187s - 13s/step - accuracy: 0.5981 - loss: 0.8328 - val_accuracy: 0.6758 - val_loss: 0.7663\n",
            "Epoch 28/50\n",
            "14/14 - 187s - 13s/step - accuracy: 0.6690 - loss: 0.7981 - val_accuracy: 0.6593 - val_loss: 0.7749\n",
            "Epoch 29/50\n",
            "14/14 - 187s - 13s/step - accuracy: 0.6407 - loss: 0.8063 - val_accuracy: 0.6374 - val_loss: 0.7682\n",
            "Epoch 30/50\n",
            "14/14 - 184s - 13s/step - accuracy: 0.6548 - loss: 0.7905 - val_accuracy: 0.6923 - val_loss: 0.7550\n",
            "Epoch 31/50\n",
            "14/14 - 204s - 15s/step - accuracy: 0.6430 - loss: 0.8173 - val_accuracy: 0.6868 - val_loss: 0.7530\n",
            "Epoch 32/50\n",
            "14/14 - 185s - 13s/step - accuracy: 0.6619 - loss: 0.7932 - val_accuracy: 0.6868 - val_loss: 0.7538\n",
            "Epoch 33/50\n",
            "14/14 - 183s - 13s/step - accuracy: 0.6738 - loss: 0.7601 - val_accuracy: 0.6484 - val_loss: 0.7825\n",
            "Epoch 34/50\n",
            "14/14 - 145s - 10s/step - accuracy: 0.6572 - loss: 0.7854 - val_accuracy: 0.6868 - val_loss: 0.7618\n",
            "Epoch 35/50\n",
            "14/14 - 148s - 11s/step - accuracy: 0.6478 - loss: 0.7649 - val_accuracy: 0.6868 - val_loss: 0.7446\n",
            "Epoch 36/50\n",
            "14/14 - 184s - 13s/step - accuracy: 0.6832 - loss: 0.7702 - val_accuracy: 0.6703 - val_loss: 0.7522\n",
            "Epoch 37/50\n",
            "14/14 - 185s - 13s/step - accuracy: 0.6761 - loss: 0.7553 - val_accuracy: 0.6868 - val_loss: 0.7326\n",
            "Epoch 38/50\n",
            "14/14 - 150s - 11s/step - accuracy: 0.6548 - loss: 0.7863 - val_accuracy: 0.7033 - val_loss: 0.7239\n",
            "Epoch 39/50\n",
            "14/14 - 144s - 10s/step - accuracy: 0.6525 - loss: 0.7687 - val_accuracy: 0.7308 - val_loss: 0.7156\n",
            "Epoch 40/50\n",
            "14/14 - 146s - 10s/step - accuracy: 0.6879 - loss: 0.7255 - val_accuracy: 0.6758 - val_loss: 0.7277\n",
            "Epoch 41/50\n",
            "14/14 - 148s - 11s/step - accuracy: 0.6785 - loss: 0.7513 - val_accuracy: 0.6758 - val_loss: 0.7327\n",
            "Epoch 42/50\n",
            "14/14 - 185s - 13s/step - accuracy: 0.7021 - loss: 0.7200 - val_accuracy: 0.6868 - val_loss: 0.7234\n",
            "Epoch 43/50\n",
            "14/14 - 184s - 13s/step - accuracy: 0.7069 - loss: 0.7079 - val_accuracy: 0.6703 - val_loss: 0.7217\n",
            "Epoch 44/50\n",
            "14/14 - 145s - 10s/step - accuracy: 0.6974 - loss: 0.7154 - val_accuracy: 0.6703 - val_loss: 0.7204\n",
            "Epoch 45/50\n",
            "14/14 - 149s - 11s/step - accuracy: 0.7210 - loss: 0.6955 - val_accuracy: 0.6703 - val_loss: 0.7296\n",
            "Epoch 46/50\n",
            "14/14 - 146s - 10s/step - accuracy: 0.6430 - loss: 0.7455 - val_accuracy: 0.7143 - val_loss: 0.7012\n",
            "Epoch 47/50\n",
            "14/14 - 186s - 13s/step - accuracy: 0.6643 - loss: 0.7491 - val_accuracy: 0.7363 - val_loss: 0.6978\n",
            "Epoch 48/50\n",
            "14/14 - 185s - 13s/step - accuracy: 0.6809 - loss: 0.7716 - val_accuracy: 0.7198 - val_loss: 0.7098\n",
            "Epoch 49/50\n",
            "14/14 - 145s - 10s/step - accuracy: 0.7045 - loss: 0.7002 - val_accuracy: 0.7143 - val_loss: 0.7137\n",
            "Epoch 50/50\n",
            "14/14 - 186s - 13s/step - accuracy: 0.7116 - loss: 0.6947 - val_accuracy: 0.6923 - val_loss: 0.7106\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model berhasil disimpan: model_split70_lr0.001_ep50_l20.0001.h5\n"
          ]
        }
      ],
      "source": [
        "split_ratio = 0.7\n",
        "split_percent = round(split_ratio * 100)\n",
        "\n",
        "for lr in [0.001]:\n",
        "    for epoch in [50]:\n",
        "        print(f\"\\n📦 Training model dengan split_ratio={split_percent}%, learning_rate={lr}, epochs={epoch}\")\n",
        "\n",
        "        model, history = train_model(\n",
        "            split_ratio=split_ratio,\n",
        "            lr=lr,\n",
        "            epochs=epoch\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gYDOiFSUms1S",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYDOiFSUms1S",
        "outputId": "f1572594-e2bc-4c1e-f03a-5512c307e9bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📦 Training model dengan split_ratio=70%, learning_rate=0.001, epochs=100\n",
            "Found 423 images belonging to 3 classes.\n",
            "Found 182 images belonging to 3 classes.\n",
            "Epoch 1/100\n",
            "14/14 - 164s - 12s/step - accuracy: 0.3617 - loss: 1.8195 - val_accuracy: 0.4011 - val_loss: 1.0918\n",
            "Epoch 2/100\n",
            "14/14 - 146s - 10s/step - accuracy: 0.4184 - loss: 1.3486 - val_accuracy: 0.5110 - val_loss: 0.9913\n",
            "Epoch 3/100\n",
            "14/14 - 184s - 13s/step - accuracy: 0.4634 - loss: 1.1392 - val_accuracy: 0.5165 - val_loss: 0.9696\n",
            "Epoch 4/100\n",
            "14/14 - 184s - 13s/step - accuracy: 0.4704 - loss: 1.1252 - val_accuracy: 0.5879 - val_loss: 0.9351\n",
            "Epoch 5/100\n",
            "14/14 - 146s - 10s/step - accuracy: 0.5177 - loss: 1.0005 - val_accuracy: 0.5879 - val_loss: 0.9411\n",
            "Epoch 6/100\n",
            "14/14 - 147s - 11s/step - accuracy: 0.5012 - loss: 1.0118 - val_accuracy: 0.5989 - val_loss: 0.9345\n",
            "Epoch 7/100\n",
            "14/14 - 202s - 14s/step - accuracy: 0.5556 - loss: 0.9578 - val_accuracy: 0.6264 - val_loss: 0.9326\n",
            "Epoch 8/100\n",
            "14/14 - 143s - 10s/step - accuracy: 0.5556 - loss: 0.9398 - val_accuracy: 0.5879 - val_loss: 0.9239\n",
            "Epoch 9/100\n",
            "14/14 - 147s - 11s/step - accuracy: 0.5272 - loss: 0.9617 - val_accuracy: 0.6264 - val_loss: 0.9053\n",
            "Epoch 10/100\n",
            "14/14 - 184s - 13s/step - accuracy: 0.5508 - loss: 0.9899 - val_accuracy: 0.6374 - val_loss: 0.8883\n",
            "Epoch 11/100\n",
            "14/14 - 202s - 14s/step - accuracy: 0.5343 - loss: 0.9458 - val_accuracy: 0.6154 - val_loss: 0.8874\n",
            "Epoch 12/100\n",
            "14/14 - 187s - 13s/step - accuracy: 0.6170 - loss: 0.8908 - val_accuracy: 0.6154 - val_loss: 0.8623\n",
            "Epoch 13/100\n",
            "14/14 - 185s - 13s/step - accuracy: 0.6217 - loss: 0.8782 - val_accuracy: 0.6319 - val_loss: 0.8649\n",
            "Epoch 14/100\n",
            "14/14 - 143s - 10s/step - accuracy: 0.5910 - loss: 0.9176 - val_accuracy: 0.6319 - val_loss: 0.8721\n",
            "Epoch 15/100\n",
            "14/14 - 147s - 10s/step - accuracy: 0.5839 - loss: 0.9155 - val_accuracy: 0.6484 - val_loss: 0.8636\n",
            "Epoch 16/100\n",
            "14/14 - 184s - 13s/step - accuracy: 0.6170 - loss: 0.8634 - val_accuracy: 0.6374 - val_loss: 0.8425\n",
            "Epoch 17/100\n",
            "14/14 - 184s - 13s/step - accuracy: 0.6265 - loss: 0.8637 - val_accuracy: 0.6703 - val_loss: 0.8232\n",
            "Epoch 18/100\n",
            "14/14 - 146s - 10s/step - accuracy: 0.6076 - loss: 0.8808 - val_accuracy: 0.6319 - val_loss: 0.8258\n",
            "Epoch 19/100\n",
            "14/14 - 145s - 10s/step - accuracy: 0.6383 - loss: 0.7945 - val_accuracy: 0.6538 - val_loss: 0.8063\n",
            "Epoch 20/100\n",
            "14/14 - 147s - 11s/step - accuracy: 0.6288 - loss: 0.8562 - val_accuracy: 0.6648 - val_loss: 0.8059\n",
            "Epoch 21/100\n",
            "14/14 - 145s - 10s/step - accuracy: 0.6454 - loss: 0.8331 - val_accuracy: 0.6593 - val_loss: 0.7959\n",
            "Epoch 22/100\n",
            "14/14 - 146s - 10s/step - accuracy: 0.6525 - loss: 0.8417 - val_accuracy: 0.6923 - val_loss: 0.7922\n",
            "Epoch 23/100\n",
            "14/14 - 204s - 15s/step - accuracy: 0.6383 - loss: 0.8576 - val_accuracy: 0.7308 - val_loss: 0.7864\n",
            "Epoch 24/100\n",
            "14/14 - 144s - 10s/step - accuracy: 0.6312 - loss: 0.8254 - val_accuracy: 0.6923 - val_loss: 0.7872\n",
            "Epoch 25/100\n",
            "14/14 - 149s - 11s/step - accuracy: 0.6643 - loss: 0.7851 - val_accuracy: 0.7088 - val_loss: 0.7790\n",
            "Epoch 26/100\n",
            "14/14 - 185s - 13s/step - accuracy: 0.6265 - loss: 0.8473 - val_accuracy: 0.6648 - val_loss: 0.7727\n",
            "Epoch 27/100\n",
            "14/14 - 201s - 14s/step - accuracy: 0.6217 - loss: 0.8209 - val_accuracy: 0.7143 - val_loss: 0.7648\n",
            "Epoch 28/100\n",
            "14/14 - 146s - 10s/step - accuracy: 0.6265 - loss: 0.8228 - val_accuracy: 0.6978 - val_loss: 0.7621\n",
            "Epoch 29/100\n",
            "14/14 - 146s - 10s/step - accuracy: 0.6312 - loss: 0.7996 - val_accuracy: 0.6703 - val_loss: 0.7600\n",
            "Epoch 30/100\n",
            "14/14 - 201s - 14s/step - accuracy: 0.6596 - loss: 0.7602 - val_accuracy: 0.6868 - val_loss: 0.7610\n",
            "Epoch 31/100\n",
            "14/14 - 148s - 11s/step - accuracy: 0.6265 - loss: 0.8115 - val_accuracy: 0.6813 - val_loss: 0.7671\n",
            "Epoch 32/100\n",
            "14/14 - 203s - 14s/step - accuracy: 0.6548 - loss: 0.7848 - val_accuracy: 0.6648 - val_loss: 0.7669\n",
            "Epoch 33/100\n",
            "14/14 - 199s - 14s/step - accuracy: 0.6501 - loss: 0.7766 - val_accuracy: 0.6978 - val_loss: 0.7628\n",
            "Epoch 34/100\n",
            "14/14 - 187s - 13s/step - accuracy: 0.6667 - loss: 0.7860 - val_accuracy: 0.7088 - val_loss: 0.7560\n",
            "Epoch 35/100\n",
            "14/14 - 184s - 13s/step - accuracy: 0.6785 - loss: 0.7690 - val_accuracy: 0.6978 - val_loss: 0.7561\n",
            "Epoch 36/100\n",
            "14/14 - 202s - 14s/step - accuracy: 0.6856 - loss: 0.7248 - val_accuracy: 0.7143 - val_loss: 0.7417\n",
            "Epoch 37/100\n",
            "14/14 - 165s - 12s/step - accuracy: 0.6785 - loss: 0.7629 - val_accuracy: 0.7033 - val_loss: 0.7238\n",
            "Epoch 38/100\n",
            "14/14 - 150s - 11s/step - accuracy: 0.6548 - loss: 0.7603 - val_accuracy: 0.7088 - val_loss: 0.7094\n",
            "Epoch 39/100\n",
            "14/14 - 184s - 13s/step - accuracy: 0.7092 - loss: 0.6886 - val_accuracy: 0.6978 - val_loss: 0.7033\n",
            "Epoch 40/100\n",
            "14/14 - 187s - 13s/step - accuracy: 0.6738 - loss: 0.8062 - val_accuracy: 0.6868 - val_loss: 0.7113\n",
            "Epoch 41/100\n",
            "14/14 - 147s - 11s/step - accuracy: 0.7021 - loss: 0.7536 - val_accuracy: 0.7033 - val_loss: 0.7071\n",
            "Epoch 42/100\n",
            "14/14 - 145s - 10s/step - accuracy: 0.6950 - loss: 0.7479 - val_accuracy: 0.7033 - val_loss: 0.7007\n",
            "Epoch 43/100\n",
            "14/14 - 186s - 13s/step - accuracy: 0.6879 - loss: 0.7443 - val_accuracy: 0.7198 - val_loss: 0.6939\n",
            "Epoch 44/100\n",
            "14/14 - 147s - 11s/step - accuracy: 0.6738 - loss: 0.7009 - val_accuracy: 0.7308 - val_loss: 0.6918\n",
            "Epoch 45/100\n",
            "14/14 - 187s - 13s/step - accuracy: 0.6832 - loss: 0.7157 - val_accuracy: 0.6923 - val_loss: 0.7003\n",
            "Epoch 46/100\n",
            "14/14 - 149s - 11s/step - accuracy: 0.6974 - loss: 0.7219 - val_accuracy: 0.6923 - val_loss: 0.7009\n",
            "Epoch 47/100\n",
            "14/14 - 145s - 10s/step - accuracy: 0.6430 - loss: 0.7756 - val_accuracy: 0.6978 - val_loss: 0.7020\n",
            "Epoch 48/100\n",
            "14/14 - 187s - 13s/step - accuracy: 0.6927 - loss: 0.7105 - val_accuracy: 0.7363 - val_loss: 0.6839\n",
            "Epoch 49/100\n",
            "14/14 - 149s - 11s/step - accuracy: 0.6856 - loss: 0.7350 - val_accuracy: 0.7418 - val_loss: 0.6780\n",
            "Epoch 50/100\n",
            "14/14 - 146s - 10s/step - accuracy: 0.7116 - loss: 0.6984 - val_accuracy: 0.7088 - val_loss: 0.6850\n",
            "Epoch 51/100\n",
            "14/14 - 204s - 15s/step - accuracy: 0.6879 - loss: 0.7479 - val_accuracy: 0.6978 - val_loss: 0.6848\n",
            "Epoch 52/100\n",
            "14/14 - 203s - 14s/step - accuracy: 0.6927 - loss: 0.7418 - val_accuracy: 0.7198 - val_loss: 0.6852\n",
            "Epoch 53/100\n",
            "14/14 - 237s - 17s/step - accuracy: 0.6714 - loss: 0.7556 - val_accuracy: 0.7143 - val_loss: 0.6920\n",
            "Epoch 54/100\n",
            "14/14 - 184s - 13s/step - accuracy: 0.6998 - loss: 0.7303 - val_accuracy: 0.7363 - val_loss: 0.6795\n",
            "Epoch 55/100\n",
            "14/14 - 149s - 11s/step - accuracy: 0.7045 - loss: 0.6863 - val_accuracy: 0.7527 - val_loss: 0.6697\n",
            "Epoch 56/100\n",
            "14/14 - 185s - 13s/step - accuracy: 0.6998 - loss: 0.7306 - val_accuracy: 0.7363 - val_loss: 0.6756\n",
            "Epoch 57/100\n",
            "14/14 - 184s - 13s/step - accuracy: 0.7116 - loss: 0.7289 - val_accuracy: 0.7253 - val_loss: 0.6808\n",
            "Epoch 58/100\n",
            "14/14 - 146s - 10s/step - accuracy: 0.7258 - loss: 0.6544 - val_accuracy: 0.6978 - val_loss: 0.6868\n",
            "Epoch 59/100\n",
            "14/14 - 205s - 15s/step - accuracy: 0.7139 - loss: 0.6900 - val_accuracy: 0.6978 - val_loss: 0.6541\n",
            "Epoch 60/100\n",
            "14/14 - 183s - 13s/step - accuracy: 0.7163 - loss: 0.7195 - val_accuracy: 0.7253 - val_loss: 0.6498\n",
            "Epoch 61/100\n",
            "14/14 - 167s - 12s/step - accuracy: 0.7258 - loss: 0.6916 - val_accuracy: 0.7143 - val_loss: 0.6508\n",
            "Epoch 62/100\n",
            "14/14 - 185s - 13s/step - accuracy: 0.6950 - loss: 0.7162 - val_accuracy: 0.7308 - val_loss: 0.6565\n",
            "Epoch 63/100\n",
            "14/14 - 184s - 13s/step - accuracy: 0.7376 - loss: 0.6657 - val_accuracy: 0.7253 - val_loss: 0.6556\n",
            "Epoch 64/100\n",
            "14/14 - 185s - 13s/step - accuracy: 0.7139 - loss: 0.7060 - val_accuracy: 0.7363 - val_loss: 0.6577\n",
            "Epoch 65/100\n",
            "14/14 - 184s - 13s/step - accuracy: 0.7258 - loss: 0.6660 - val_accuracy: 0.7473 - val_loss: 0.6507\n",
            "Epoch 66/100\n",
            "14/14 - 144s - 10s/step - accuracy: 0.7329 - loss: 0.6710 - val_accuracy: 0.7637 - val_loss: 0.6348\n",
            "Epoch 67/100\n",
            "14/14 - 149s - 11s/step - accuracy: 0.7305 - loss: 0.6738 - val_accuracy: 0.7308 - val_loss: 0.6352\n",
            "Epoch 68/100\n",
            "14/14 - 185s - 13s/step - accuracy: 0.7045 - loss: 0.6956 - val_accuracy: 0.7198 - val_loss: 0.6502\n",
            "Epoch 69/100\n",
            "14/14 - 163s - 12s/step - accuracy: 0.7210 - loss: 0.6826 - val_accuracy: 0.7253 - val_loss: 0.6407\n",
            "Epoch 70/100\n",
            "14/14 - 147s - 11s/step - accuracy: 0.7069 - loss: 0.6813 - val_accuracy: 0.7253 - val_loss: 0.6239\n",
            "Epoch 71/100\n",
            "14/14 - 239s - 17s/step - accuracy: 0.7021 - loss: 0.6901 - val_accuracy: 0.7692 - val_loss: 0.6116\n",
            "Epoch 72/100\n",
            "14/14 - 186s - 13s/step - accuracy: 0.7210 - loss: 0.6703 - val_accuracy: 0.7912 - val_loss: 0.6162\n",
            "Epoch 73/100\n",
            "14/14 - 186s - 13s/step - accuracy: 0.6879 - loss: 0.7057 - val_accuracy: 0.7582 - val_loss: 0.6293\n",
            "Epoch 74/100\n",
            "14/14 - 183s - 13s/step - accuracy: 0.7092 - loss: 0.6580 - val_accuracy: 0.7527 - val_loss: 0.6236\n",
            "Epoch 75/100\n",
            "14/14 - 145s - 10s/step - accuracy: 0.7329 - loss: 0.6742 - val_accuracy: 0.7692 - val_loss: 0.6212\n",
            "Epoch 76/100\n",
            "14/14 - 244s - 17s/step - accuracy: 0.7447 - loss: 0.5953 - val_accuracy: 0.7747 - val_loss: 0.6113\n",
            "Epoch 77/100\n",
            "14/14 - 146s - 10s/step - accuracy: 0.7092 - loss: 0.6739 - val_accuracy: 0.7747 - val_loss: 0.6123\n",
            "Epoch 78/100\n",
            "14/14 - 145s - 10s/step - accuracy: 0.7163 - loss: 0.6541 - val_accuracy: 0.7527 - val_loss: 0.6179\n",
            "Epoch 79/100\n",
            "14/14 - 147s - 11s/step - accuracy: 0.7470 - loss: 0.6344 - val_accuracy: 0.7802 - val_loss: 0.5984\n",
            "Epoch 80/100\n",
            "14/14 - 143s - 10s/step - accuracy: 0.7612 - loss: 0.6163 - val_accuracy: 0.7692 - val_loss: 0.6040\n",
            "Epoch 81/100\n",
            "14/14 - 147s - 10s/step - accuracy: 0.7660 - loss: 0.6192 - val_accuracy: 0.7198 - val_loss: 0.6244\n",
            "Epoch 82/100\n",
            "14/14 - 144s - 10s/step - accuracy: 0.7612 - loss: 0.6165 - val_accuracy: 0.7582 - val_loss: 0.6119\n",
            "Epoch 83/100\n",
            "14/14 - 184s - 13s/step - accuracy: 0.6879 - loss: 0.6784 - val_accuracy: 0.7363 - val_loss: 0.6142\n",
            "Epoch 84/100\n",
            "14/14 - 146s - 10s/step - accuracy: 0.7092 - loss: 0.6910 - val_accuracy: 0.7143 - val_loss: 0.6306\n",
            "Epoch 85/100\n",
            "14/14 - 198s - 14s/step - accuracy: 0.7518 - loss: 0.6161 - val_accuracy: 0.7418 - val_loss: 0.6141\n",
            "Epoch 86/100\n",
            "14/14 - 206s - 15s/step - accuracy: 0.7470 - loss: 0.6488 - val_accuracy: 0.7143 - val_loss: 0.6387\n",
            "Epoch 87/100\n",
            "14/14 - 186s - 13s/step - accuracy: 0.7187 - loss: 0.6388 - val_accuracy: 0.7253 - val_loss: 0.6211\n",
            "Epoch 88/100\n",
            "14/14 - 143s - 10s/step - accuracy: 0.7163 - loss: 0.6453 - val_accuracy: 0.7363 - val_loss: 0.6233\n",
            "Epoch 89/100\n",
            "14/14 - 147s - 11s/step - accuracy: 0.6856 - loss: 0.6687 - val_accuracy: 0.7418 - val_loss: 0.6193\n",
            "Epoch 90/100\n",
            "14/14 - 148s - 11s/step - accuracy: 0.7116 - loss: 0.6363 - val_accuracy: 0.7747 - val_loss: 0.6051\n",
            "Epoch 91/100\n",
            "14/14 - 185s - 13s/step - accuracy: 0.7470 - loss: 0.6332 - val_accuracy: 0.7637 - val_loss: 0.6081\n",
            "Epoch 92/100\n",
            "14/14 - 186s - 13s/step - accuracy: 0.7636 - loss: 0.6095 - val_accuracy: 0.7747 - val_loss: 0.5941\n",
            "Epoch 93/100\n",
            "14/14 - 146s - 10s/step - accuracy: 0.7470 - loss: 0.6020 - val_accuracy: 0.7527 - val_loss: 0.6011\n",
            "Epoch 94/100\n",
            "14/14 - 147s - 10s/step - accuracy: 0.7636 - loss: 0.6092 - val_accuracy: 0.7198 - val_loss: 0.6235\n",
            "Epoch 95/100\n",
            "14/14 - 150s - 11s/step - accuracy: 0.7163 - loss: 0.6645 - val_accuracy: 0.7692 - val_loss: 0.5912\n",
            "Epoch 96/100\n",
            "14/14 - 184s - 13s/step - accuracy: 0.7447 - loss: 0.6114 - val_accuracy: 0.7747 - val_loss: 0.5900\n",
            "Epoch 97/100\n",
            "14/14 - 165s - 12s/step - accuracy: 0.7021 - loss: 0.6400 - val_accuracy: 0.7473 - val_loss: 0.6108\n",
            "Epoch 98/100\n",
            "14/14 - 148s - 11s/step - accuracy: 0.7612 - loss: 0.5971 - val_accuracy: 0.7418 - val_loss: 0.6074\n",
            "Epoch 99/100\n",
            "14/14 - 183s - 13s/step - accuracy: 0.7187 - loss: 0.6594 - val_accuracy: 0.7637 - val_loss: 0.6078\n",
            "Epoch 100/100\n",
            "14/14 - 147s - 11s/step - accuracy: 0.7636 - loss: 0.5960 - val_accuracy: 0.7418 - val_loss: 0.6209\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model berhasil disimpan: model_split70_lr0.001_ep100_l20.0001.h5\n"
          ]
        }
      ],
      "source": [
        "split_ratio = 0.7\n",
        "split_percent = round(split_ratio * 100)\n",
        "\n",
        "for lr in [0.001]:\n",
        "    for epoch in [100]:\n",
        "        print(f\"\\n📦 Training model dengan split_ratio={split_percent}%, learning_rate={lr}, epochs={epoch}\")\n",
        "\n",
        "        model, history = train_model(\n",
        "            split_ratio=split_ratio,\n",
        "            lr=lr,\n",
        "            epochs=epoch\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "vNtH9V5ZmvpE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNtH9V5ZmvpE",
        "outputId": "31b28b53-0d02-47c1-f569-96f1138927e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📦 Training model dengan split_ratio=70%, learning_rate=0.001, epochs=200\n",
            "Found 423 images belonging to 3 classes.\n",
            "Found 182 images belonging to 3 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "14/14 - 162s - 12s/step - accuracy: 0.3948 - loss: 1.8561 - val_accuracy: 0.4451 - val_loss: 1.1629\n",
            "Epoch 2/200\n",
            "14/14 - 232s - 17s/step - accuracy: 0.3948 - loss: 1.5327 - val_accuracy: 0.5000 - val_loss: 0.9732\n",
            "Epoch 3/200\n",
            "14/14 - 145s - 10s/step - accuracy: 0.4941 - loss: 1.1727 - val_accuracy: 0.5824 - val_loss: 0.9556\n",
            "Epoch 4/200\n",
            "14/14 - 201s - 14s/step - accuracy: 0.5083 - loss: 1.0550 - val_accuracy: 0.5110 - val_loss: 0.9765\n",
            "Epoch 5/200\n",
            "14/14 - 206s - 15s/step - accuracy: 0.5532 - loss: 1.0217 - val_accuracy: 0.5000 - val_loss: 0.9774\n",
            "Epoch 6/200\n",
            "14/14 - 201s - 14s/step - accuracy: 0.5130 - loss: 1.0126 - val_accuracy: 0.5385 - val_loss: 0.9761\n",
            "Epoch 7/200\n",
            "14/14 - 203s - 14s/step - accuracy: 0.5248 - loss: 0.9651 - val_accuracy: 0.5220 - val_loss: 0.9663\n",
            "Epoch 8/200\n",
            "14/14 - 143s - 10s/step - accuracy: 0.5910 - loss: 0.9159 - val_accuracy: 0.5385 - val_loss: 0.9426\n",
            "Epoch 9/200\n",
            "14/14 - 211s - 15s/step - accuracy: 0.5579 - loss: 0.9104 - val_accuracy: 0.5549 - val_loss: 0.9145\n",
            "Epoch 10/200\n",
            "14/14 - 143s - 10s/step - accuracy: 0.5414 - loss: 0.9567 - val_accuracy: 0.5769 - val_loss: 0.9043\n",
            "Epoch 11/200\n",
            "14/14 - 185s - 13s/step - accuracy: 0.5674 - loss: 0.9227 - val_accuracy: 0.5769 - val_loss: 0.9116\n",
            "Epoch 12/200\n",
            "14/14 - 141s - 10s/step - accuracy: 0.5650 - loss: 0.9412 - val_accuracy: 0.5934 - val_loss: 0.9121\n",
            "Epoch 13/200\n",
            "14/14 - 193s - 14s/step - accuracy: 0.5768 - loss: 0.9210 - val_accuracy: 0.5659 - val_loss: 0.8998\n",
            "Epoch 14/200\n",
            "14/14 - 150s - 11s/step - accuracy: 0.5768 - loss: 0.8937 - val_accuracy: 0.5879 - val_loss: 0.8930\n",
            "Epoch 15/200\n",
            "14/14 - 183s - 13s/step - accuracy: 0.5745 - loss: 0.9124 - val_accuracy: 0.5659 - val_loss: 0.8918\n",
            "Epoch 16/200\n",
            "14/14 - 181s - 13s/step - accuracy: 0.5674 - loss: 0.9136 - val_accuracy: 0.5604 - val_loss: 0.8760\n",
            "Epoch 17/200\n",
            "14/14 - 144s - 10s/step - accuracy: 0.6028 - loss: 0.8798 - val_accuracy: 0.5989 - val_loss: 0.8607\n",
            "Epoch 18/200\n",
            "14/14 - 143s - 10s/step - accuracy: 0.5863 - loss: 0.8986 - val_accuracy: 0.6154 - val_loss: 0.8481\n",
            "Epoch 19/200\n",
            "14/14 - 183s - 13s/step - accuracy: 0.6099 - loss: 0.8802 - val_accuracy: 0.6209 - val_loss: 0.8411\n",
            "Epoch 20/200\n",
            "14/14 - 141s - 10s/step - accuracy: 0.5910 - loss: 0.8750 - val_accuracy: 0.6209 - val_loss: 0.8330\n",
            "Epoch 21/200\n",
            "14/14 - 145s - 10s/step - accuracy: 0.6407 - loss: 0.8579 - val_accuracy: 0.6319 - val_loss: 0.8206\n",
            "Epoch 22/200\n",
            "14/14 - 238s - 17s/step - accuracy: 0.6265 - loss: 0.8327 - val_accuracy: 0.6374 - val_loss: 0.8109\n",
            "Epoch 23/200\n",
            "14/14 - 145s - 10s/step - accuracy: 0.6288 - loss: 0.8303 - val_accuracy: 0.6484 - val_loss: 0.7949\n",
            "Epoch 24/200\n",
            "14/14 - 141s - 10s/step - accuracy: 0.6265 - loss: 0.8153 - val_accuracy: 0.6538 - val_loss: 0.7788\n",
            "Epoch 25/200\n",
            "14/14 - 144s - 10s/step - accuracy: 0.6596 - loss: 0.8003 - val_accuracy: 0.6593 - val_loss: 0.7870\n",
            "Epoch 26/200\n",
            "14/14 - 142s - 10s/step - accuracy: 0.6265 - loss: 0.8473 - val_accuracy: 0.6429 - val_loss: 0.7967\n",
            "Epoch 27/200\n",
            "14/14 - 181s - 13s/step - accuracy: 0.6147 - loss: 0.8452 - val_accuracy: 0.6648 - val_loss: 0.7844\n",
            "Epoch 28/200\n",
            "14/14 - 163s - 12s/step - accuracy: 0.6690 - loss: 0.7685 - val_accuracy: 0.6758 - val_loss: 0.7746\n",
            "Epoch 29/200\n",
            "14/14 - 144s - 10s/step - accuracy: 0.6667 - loss: 0.8018 - val_accuracy: 0.6703 - val_loss: 0.7693\n",
            "Epoch 30/200\n",
            "14/14 - 140s - 10s/step - accuracy: 0.6430 - loss: 0.7690 - val_accuracy: 0.6813 - val_loss: 0.7474\n",
            "Epoch 31/200\n",
            "14/14 - 144s - 10s/step - accuracy: 0.6809 - loss: 0.7835 - val_accuracy: 0.7033 - val_loss: 0.7514\n",
            "Epoch 32/200\n",
            "14/14 - 144s - 10s/step - accuracy: 0.6336 - loss: 0.8186 - val_accuracy: 0.6868 - val_loss: 0.7527\n",
            "Epoch 33/200\n",
            "14/14 - 141s - 10s/step - accuracy: 0.6501 - loss: 0.7818 - val_accuracy: 0.6978 - val_loss: 0.7430\n",
            "Epoch 34/200\n",
            "14/14 - 145s - 10s/step - accuracy: 0.6548 - loss: 0.7586 - val_accuracy: 0.7143 - val_loss: 0.7311\n",
            "Epoch 35/200\n",
            "14/14 - 182s - 13s/step - accuracy: 0.6809 - loss: 0.7697 - val_accuracy: 0.6868 - val_loss: 0.7337\n",
            "Epoch 36/200\n",
            "14/14 - 144s - 10s/step - accuracy: 0.6714 - loss: 0.7647 - val_accuracy: 0.7033 - val_loss: 0.7313\n",
            "Epoch 37/200\n",
            "14/14 - 200s - 14s/step - accuracy: 0.6288 - loss: 0.8072 - val_accuracy: 0.7253 - val_loss: 0.7353\n",
            "Epoch 38/200\n",
            "14/14 - 146s - 10s/step - accuracy: 0.6572 - loss: 0.7790 - val_accuracy: 0.7033 - val_loss: 0.7358\n",
            "Epoch 39/200\n",
            "14/14 - 181s - 13s/step - accuracy: 0.6454 - loss: 0.7971 - val_accuracy: 0.6758 - val_loss: 0.7402\n",
            "Epoch 40/200\n",
            "14/14 - 143s - 10s/step - accuracy: 0.6738 - loss: 0.7921 - val_accuracy: 0.7308 - val_loss: 0.7127\n",
            "Epoch 41/200\n",
            "14/14 - 143s - 10s/step - accuracy: 0.7116 - loss: 0.6945 - val_accuracy: 0.7143 - val_loss: 0.7071\n",
            "Epoch 42/200\n",
            "14/14 - 146s - 10s/step - accuracy: 0.6454 - loss: 0.7815 - val_accuracy: 0.7088 - val_loss: 0.6998\n",
            "Epoch 43/200\n",
            "14/14 - 141s - 10s/step - accuracy: 0.6336 - loss: 0.7749 - val_accuracy: 0.7253 - val_loss: 0.7068\n",
            "Epoch 44/200\n",
            "14/14 - 143s - 10s/step - accuracy: 0.6690 - loss: 0.7588 - val_accuracy: 0.7143 - val_loss: 0.7264\n",
            "Epoch 45/200\n",
            "14/14 - 142s - 10s/step - accuracy: 0.7163 - loss: 0.7182 - val_accuracy: 0.7363 - val_loss: 0.7138\n",
            "Epoch 46/200\n",
            "14/14 - 141s - 10s/step - accuracy: 0.6501 - loss: 0.7841 - val_accuracy: 0.7198 - val_loss: 0.7175\n",
            "Epoch 47/200\n",
            "14/14 - 144s - 10s/step - accuracy: 0.6785 - loss: 0.7431 - val_accuracy: 0.7308 - val_loss: 0.7109\n",
            "Epoch 48/200\n",
            "14/14 - 147s - 10s/step - accuracy: 0.7069 - loss: 0.6912 - val_accuracy: 0.7198 - val_loss: 0.6963\n",
            "Epoch 49/200\n",
            "14/14 - 143s - 10s/step - accuracy: 0.6785 - loss: 0.7533 - val_accuracy: 0.7198 - val_loss: 0.6934\n",
            "Epoch 50/200\n",
            "14/14 - 184s - 13s/step - accuracy: 0.6832 - loss: 0.7493 - val_accuracy: 0.7253 - val_loss: 0.7003\n",
            "Epoch 51/200\n",
            "14/14 - 146s - 10s/step - accuracy: 0.6738 - loss: 0.7337 - val_accuracy: 0.7143 - val_loss: 0.6976\n",
            "Epoch 52/200\n",
            "14/14 - 197s - 14s/step - accuracy: 0.7069 - loss: 0.7394 - val_accuracy: 0.7308 - val_loss: 0.6854\n",
            "Epoch 53/200\n",
            "14/14 - 145s - 10s/step - accuracy: 0.6832 - loss: 0.7081 - val_accuracy: 0.7253 - val_loss: 0.6984\n",
            "Epoch 54/200\n",
            "14/14 - 182s - 13s/step - accuracy: 0.6974 - loss: 0.7201 - val_accuracy: 0.7418 - val_loss: 0.6843\n",
            "Epoch 55/200\n",
            "14/14 - 143s - 10s/step - accuracy: 0.7210 - loss: 0.6613 - val_accuracy: 0.7308 - val_loss: 0.6773\n",
            "Epoch 56/200\n",
            "14/14 - 142s - 10s/step - accuracy: 0.6856 - loss: 0.7026 - val_accuracy: 0.7088 - val_loss: 0.6914\n",
            "Epoch 57/200\n",
            "14/14 - 245s - 17s/step - accuracy: 0.7069 - loss: 0.7166 - val_accuracy: 0.7143 - val_loss: 0.6859\n",
            "Epoch 58/200\n",
            "14/14 - 161s - 12s/step - accuracy: 0.7329 - loss: 0.6681 - val_accuracy: 0.7418 - val_loss: 0.6912\n",
            "Epoch 59/200\n",
            "14/14 - 182s - 13s/step - accuracy: 0.6903 - loss: 0.6982 - val_accuracy: 0.7363 - val_loss: 0.6763\n",
            "Epoch 60/200\n",
            "14/14 - 141s - 10s/step - accuracy: 0.7092 - loss: 0.6948 - val_accuracy: 0.7143 - val_loss: 0.6849\n",
            "Epoch 61/200\n",
            "14/14 - 146s - 10s/step - accuracy: 0.6761 - loss: 0.7618 - val_accuracy: 0.7088 - val_loss: 0.7013\n",
            "Epoch 62/200\n",
            "14/14 - 144s - 10s/step - accuracy: 0.7329 - loss: 0.6796 - val_accuracy: 0.7253 - val_loss: 0.6813\n",
            "Epoch 63/200\n",
            "14/14 - 145s - 10s/step - accuracy: 0.7329 - loss: 0.6519 - val_accuracy: 0.7143 - val_loss: 0.6887\n",
            "Epoch 64/200\n",
            "14/14 - 141s - 10s/step - accuracy: 0.7234 - loss: 0.6683 - val_accuracy: 0.7308 - val_loss: 0.6883\n",
            "Epoch 65/200\n",
            "14/14 - 145s - 10s/step - accuracy: 0.7021 - loss: 0.6861 - val_accuracy: 0.7253 - val_loss: 0.6763\n",
            "Epoch 66/200\n",
            "14/14 - 182s - 13s/step - accuracy: 0.6879 - loss: 0.7032 - val_accuracy: 0.7308 - val_loss: 0.6650\n",
            "Epoch 67/200\n",
            "14/14 - 181s - 13s/step - accuracy: 0.7187 - loss: 0.6926 - val_accuracy: 0.7308 - val_loss: 0.6603\n",
            "Epoch 68/200\n",
            "14/14 - 142s - 10s/step - accuracy: 0.6856 - loss: 0.7082 - val_accuracy: 0.7253 - val_loss: 0.6609\n",
            "Epoch 69/200\n",
            "14/14 - 144s - 10s/step - accuracy: 0.6998 - loss: 0.6818 - val_accuracy: 0.7198 - val_loss: 0.6638\n",
            "Epoch 70/200\n",
            "14/14 - 201s - 14s/step - accuracy: 0.7163 - loss: 0.6401 - val_accuracy: 0.7143 - val_loss: 0.6654\n",
            "Epoch 71/200\n",
            "14/14 - 144s - 10s/step - accuracy: 0.6950 - loss: 0.6446 - val_accuracy: 0.7088 - val_loss: 0.6663\n",
            "Epoch 72/200\n",
            "14/14 - 139s - 10s/step - accuracy: 0.7045 - loss: 0.6562 - val_accuracy: 0.7363 - val_loss: 0.6495\n",
            "Epoch 73/200\n",
            "14/14 - 143s - 10s/step - accuracy: 0.7210 - loss: 0.6660 - val_accuracy: 0.7363 - val_loss: 0.6557\n",
            "Epoch 74/200\n",
            "14/14 - 141s - 10s/step - accuracy: 0.7329 - loss: 0.6556 - val_accuracy: 0.7473 - val_loss: 0.6600\n",
            "Epoch 75/200\n",
            "14/14 - 141s - 10s/step - accuracy: 0.7092 - loss: 0.6641 - val_accuracy: 0.7527 - val_loss: 0.6595\n",
            "Epoch 76/200\n",
            "14/14 - 141s - 10s/step - accuracy: 0.7187 - loss: 0.6545 - val_accuracy: 0.7253 - val_loss: 0.6642\n",
            "Epoch 77/200\n",
            "14/14 - 142s - 10s/step - accuracy: 0.7329 - loss: 0.6544 - val_accuracy: 0.7253 - val_loss: 0.6753\n",
            "Epoch 78/200\n",
            "14/14 - 142s - 10s/step - accuracy: 0.6998 - loss: 0.6925 - val_accuracy: 0.7418 - val_loss: 0.6581\n",
            "Epoch 79/200\n",
            "14/14 - 142s - 10s/step - accuracy: 0.7400 - loss: 0.6330 - val_accuracy: 0.7253 - val_loss: 0.6598\n",
            "Epoch 80/200\n",
            "14/14 - 144s - 10s/step - accuracy: 0.7329 - loss: 0.6273 - val_accuracy: 0.7308 - val_loss: 0.6649\n",
            "Epoch 81/200\n",
            "14/14 - 182s - 13s/step - accuracy: 0.7163 - loss: 0.6771 - val_accuracy: 0.7308 - val_loss: 0.6600\n",
            "Epoch 82/200\n",
            "14/14 - 139s - 10s/step - accuracy: 0.7565 - loss: 0.6590 - val_accuracy: 0.7363 - val_loss: 0.6560\n",
            "Epoch 83/200\n",
            "14/14 - 181s - 13s/step - accuracy: 0.7376 - loss: 0.6122 - val_accuracy: 0.7363 - val_loss: 0.6416\n",
            "Epoch 84/200\n",
            "14/14 - 181s - 13s/step - accuracy: 0.7329 - loss: 0.6434 - val_accuracy: 0.7308 - val_loss: 0.6502\n",
            "Epoch 85/200\n",
            "14/14 - 139s - 10s/step - accuracy: 0.7400 - loss: 0.6184 - val_accuracy: 0.7143 - val_loss: 0.6675\n",
            "Epoch 86/200\n",
            "14/14 - 141s - 10s/step - accuracy: 0.7329 - loss: 0.6561 - val_accuracy: 0.7143 - val_loss: 0.6739\n",
            "Epoch 87/200\n",
            "14/14 - 139s - 10s/step - accuracy: 0.7187 - loss: 0.6408 - val_accuracy: 0.7253 - val_loss: 0.6729\n",
            "Epoch 88/200\n",
            "14/14 - 141s - 10s/step - accuracy: 0.7069 - loss: 0.6864 - val_accuracy: 0.7363 - val_loss: 0.6526\n",
            "Epoch 89/200\n",
            "14/14 - 140s - 10s/step - accuracy: 0.7069 - loss: 0.6753 - val_accuracy: 0.7527 - val_loss: 0.6408\n",
            "Epoch 90/200\n",
            "14/14 - 144s - 10s/step - accuracy: 0.7400 - loss: 0.6379 - val_accuracy: 0.7308 - val_loss: 0.6543\n",
            "Epoch 91/200\n",
            "14/14 - 140s - 10s/step - accuracy: 0.7352 - loss: 0.6424 - val_accuracy: 0.7363 - val_loss: 0.6395\n",
            "Epoch 92/200\n",
            "14/14 - 181s - 13s/step - accuracy: 0.7376 - loss: 0.6462 - val_accuracy: 0.7527 - val_loss: 0.6248\n",
            "Epoch 93/200\n",
            "14/14 - 181s - 13s/step - accuracy: 0.7305 - loss: 0.6097 - val_accuracy: 0.7637 - val_loss: 0.6172\n",
            "Epoch 94/200\n",
            "14/14 - 140s - 10s/step - accuracy: 0.7778 - loss: 0.5848 - val_accuracy: 0.7418 - val_loss: 0.6290\n",
            "Epoch 95/200\n",
            "14/14 - 141s - 10s/step - accuracy: 0.7210 - loss: 0.6501 - val_accuracy: 0.7418 - val_loss: 0.6322\n",
            "Epoch 96/200\n",
            "14/14 - 141s - 10s/step - accuracy: 0.7825 - loss: 0.5905 - val_accuracy: 0.7473 - val_loss: 0.6294\n",
            "Epoch 97/200\n",
            "14/14 - 141s - 10s/step - accuracy: 0.7423 - loss: 0.6197 - val_accuracy: 0.7363 - val_loss: 0.6383\n",
            "Epoch 98/200\n",
            "14/14 - 139s - 10s/step - accuracy: 0.7447 - loss: 0.5936 - val_accuracy: 0.7418 - val_loss: 0.6408\n",
            "Epoch 99/200\n",
            "14/14 - 143s - 10s/step - accuracy: 0.7494 - loss: 0.6018 - val_accuracy: 0.7418 - val_loss: 0.6381\n",
            "Epoch 100/200\n",
            "14/14 - 141s - 10s/step - accuracy: 0.7258 - loss: 0.6605 - val_accuracy: 0.7582 - val_loss: 0.6203\n",
            "Epoch 101/200\n",
            "14/14 - 139s - 10s/step - accuracy: 0.7352 - loss: 0.6564 - val_accuracy: 0.7308 - val_loss: 0.6503\n",
            "Epoch 102/200\n",
            "14/14 - 142s - 10s/step - accuracy: 0.7541 - loss: 0.5803 - val_accuracy: 0.7582 - val_loss: 0.6156\n",
            "Epoch 103/200\n",
            "14/14 - 140s - 10s/step - accuracy: 0.7730 - loss: 0.6062 - val_accuracy: 0.7473 - val_loss: 0.6172\n",
            "Epoch 104/200\n",
            "14/14 - 142s - 10s/step - accuracy: 0.7636 - loss: 0.5878 - val_accuracy: 0.7418 - val_loss: 0.6171\n",
            "Epoch 105/200\n",
            "14/14 - 140s - 10s/step - accuracy: 0.7376 - loss: 0.5908 - val_accuracy: 0.7692 - val_loss: 0.6174\n",
            "Epoch 106/200\n",
            "14/14 - 142s - 10s/step - accuracy: 0.7636 - loss: 0.5938 - val_accuracy: 0.7527 - val_loss: 0.6232\n",
            "Epoch 107/200\n",
            "14/14 - 142s - 10s/step - accuracy: 0.7801 - loss: 0.5614 - val_accuracy: 0.7582 - val_loss: 0.6025\n",
            "Epoch 108/200\n",
            "14/14 - 142s - 10s/step - accuracy: 0.7730 - loss: 0.6081 - val_accuracy: 0.7637 - val_loss: 0.6080\n",
            "Epoch 109/200\n",
            "14/14 - 200s - 14s/step - accuracy: 0.7234 - loss: 0.5943 - val_accuracy: 0.7527 - val_loss: 0.6090\n",
            "Epoch 110/200\n",
            "14/14 - 182s - 13s/step - accuracy: 0.7352 - loss: 0.6178 - val_accuracy: 0.7527 - val_loss: 0.6151\n",
            "Epoch 111/200\n",
            "14/14 - 182s - 13s/step - accuracy: 0.7400 - loss: 0.6249 - val_accuracy: 0.7582 - val_loss: 0.6100\n",
            "Epoch 112/200\n",
            "14/14 - 139s - 10s/step - accuracy: 0.7612 - loss: 0.6124 - val_accuracy: 0.7582 - val_loss: 0.6163\n",
            "Epoch 113/200\n",
            "14/14 - 144s - 10s/step - accuracy: 0.7707 - loss: 0.5659 - val_accuracy: 0.7637 - val_loss: 0.6131\n",
            "Epoch 114/200\n",
            "14/14 - 140s - 10s/step - accuracy: 0.7541 - loss: 0.5847 - val_accuracy: 0.7418 - val_loss: 0.6313\n",
            "Epoch 115/200\n",
            "14/14 - 141s - 10s/step - accuracy: 0.7447 - loss: 0.6037 - val_accuracy: 0.7363 - val_loss: 0.6408\n",
            "Epoch 116/200\n",
            "14/14 - 140s - 10s/step - accuracy: 0.7730 - loss: 0.6134 - val_accuracy: 0.7527 - val_loss: 0.6411\n",
            "Epoch 117/200\n",
            "14/14 - 182s - 13s/step - accuracy: 0.7967 - loss: 0.5592 - val_accuracy: 0.7418 - val_loss: 0.6436\n",
            "Epoch 118/200\n",
            "14/14 - 180s - 13s/step - accuracy: 0.7470 - loss: 0.5755 - val_accuracy: 0.7637 - val_loss: 0.6093\n",
            "Epoch 119/200\n",
            "14/14 - 141s - 10s/step - accuracy: 0.7352 - loss: 0.6136 - val_accuracy: 0.7527 - val_loss: 0.6169\n",
            "Epoch 120/200\n",
            "14/14 - 140s - 10s/step - accuracy: 0.7423 - loss: 0.6066 - val_accuracy: 0.7473 - val_loss: 0.6202\n",
            "Epoch 121/200\n",
            "14/14 - 181s - 13s/step - accuracy: 0.7163 - loss: 0.6006 - val_accuracy: 0.7692 - val_loss: 0.5935\n",
            "Epoch 122/200\n",
            "14/14 - 143s - 10s/step - accuracy: 0.7896 - loss: 0.5526 - val_accuracy: 0.7747 - val_loss: 0.5902\n",
            "Epoch 123/200\n",
            "14/14 - 141s - 10s/step - accuracy: 0.7683 - loss: 0.5520 - val_accuracy: 0.7637 - val_loss: 0.5784\n",
            "Epoch 124/200\n",
            "14/14 - 142s - 10s/step - accuracy: 0.7778 - loss: 0.5763 - val_accuracy: 0.7582 - val_loss: 0.5924\n",
            "Epoch 125/200\n",
            "14/14 - 142s - 10s/step - accuracy: 0.7683 - loss: 0.5719 - val_accuracy: 0.7692 - val_loss: 0.5958\n",
            "Epoch 126/200\n",
            "14/14 - 143s - 10s/step - accuracy: 0.7565 - loss: 0.5750 - val_accuracy: 0.7637 - val_loss: 0.5939\n",
            "Epoch 127/200\n",
            "14/14 - 182s - 13s/step - accuracy: 0.7565 - loss: 0.5598 - val_accuracy: 0.7637 - val_loss: 0.5979\n",
            "Epoch 128/200\n",
            "14/14 - 140s - 10s/step - accuracy: 0.7660 - loss: 0.5684 - val_accuracy: 0.7582 - val_loss: 0.5963\n",
            "Epoch 129/200\n",
            "14/14 - 142s - 10s/step - accuracy: 0.7707 - loss: 0.5795 - val_accuracy: 0.7582 - val_loss: 0.6177\n",
            "Epoch 130/200\n",
            "14/14 - 140s - 10s/step - accuracy: 0.7896 - loss: 0.5407 - val_accuracy: 0.7527 - val_loss: 0.6136\n",
            "Epoch 131/200\n",
            "14/14 - 143s - 10s/step - accuracy: 0.7636 - loss: 0.6030 - val_accuracy: 0.7582 - val_loss: 0.6151\n",
            "Epoch 132/200\n",
            "14/14 - 146s - 10s/step - accuracy: 0.7730 - loss: 0.5633 - val_accuracy: 0.7582 - val_loss: 0.6255\n",
            "Epoch 133/200\n",
            "14/14 - 140s - 10s/step - accuracy: 0.7801 - loss: 0.5339 - val_accuracy: 0.7637 - val_loss: 0.5977\n",
            "Epoch 134/200\n",
            "14/14 - 142s - 10s/step - accuracy: 0.7778 - loss: 0.5491 - val_accuracy: 0.7582 - val_loss: 0.5899\n",
            "Epoch 135/200\n",
            "14/14 - 141s - 10s/step - accuracy: 0.7730 - loss: 0.5741 - val_accuracy: 0.7473 - val_loss: 0.6093\n",
            "Epoch 136/200\n",
            "14/14 - 143s - 10s/step - accuracy: 0.7730 - loss: 0.5364 - val_accuracy: 0.7473 - val_loss: 0.6128\n",
            "Epoch 137/200\n",
            "14/14 - 139s - 10s/step - accuracy: 0.7423 - loss: 0.5897 - val_accuracy: 0.7582 - val_loss: 0.6077\n",
            "Epoch 138/200\n",
            "14/14 - 180s - 13s/step - accuracy: 0.7683 - loss: 0.5678 - val_accuracy: 0.7692 - val_loss: 0.5945\n",
            "Epoch 139/200\n",
            "14/14 - 140s - 10s/step - accuracy: 0.7849 - loss: 0.5389 - val_accuracy: 0.7637 - val_loss: 0.6128\n",
            "Epoch 140/200\n",
            "14/14 - 142s - 10s/step - accuracy: 0.7849 - loss: 0.5765 - val_accuracy: 0.7473 - val_loss: 0.5939\n",
            "Epoch 141/200\n",
            "14/14 - 180s - 13s/step - accuracy: 0.7683 - loss: 0.5524 - val_accuracy: 0.7308 - val_loss: 0.5943\n",
            "Epoch 142/200\n",
            "14/14 - 141s - 10s/step - accuracy: 0.7352 - loss: 0.5864 - val_accuracy: 0.7637 - val_loss: 0.5877\n",
            "Epoch 143/200\n",
            "14/14 - 140s - 10s/step - accuracy: 0.7849 - loss: 0.5722 - val_accuracy: 0.7802 - val_loss: 0.5846\n",
            "Epoch 144/200\n",
            "14/14 - 143s - 10s/step - accuracy: 0.7920 - loss: 0.5191 - val_accuracy: 0.7802 - val_loss: 0.5916\n",
            "Epoch 145/200\n",
            "14/14 - 183s - 13s/step - accuracy: 0.7896 - loss: 0.5261 - val_accuracy: 0.7527 - val_loss: 0.5980\n",
            "Epoch 146/200\n",
            "14/14 - 139s - 10s/step - accuracy: 0.7754 - loss: 0.5155 - val_accuracy: 0.7747 - val_loss: 0.5844\n",
            "Epoch 147/200\n",
            "14/14 - 142s - 10s/step - accuracy: 0.8014 - loss: 0.4962 - val_accuracy: 0.7802 - val_loss: 0.5740\n",
            "Epoch 148/200\n",
            "14/14 - 140s - 10s/step - accuracy: 0.7494 - loss: 0.5577 - val_accuracy: 0.7692 - val_loss: 0.5898\n",
            "Epoch 149/200\n",
            "14/14 - 142s - 10s/step - accuracy: 0.7896 - loss: 0.5262 - val_accuracy: 0.7527 - val_loss: 0.5895\n",
            "Epoch 150/200\n",
            "14/14 - 140s - 10s/step - accuracy: 0.7660 - loss: 0.5432 - val_accuracy: 0.7802 - val_loss: 0.5569\n",
            "Epoch 151/200\n",
            "14/14 - 141s - 10s/step - accuracy: 0.7683 - loss: 0.5659 - val_accuracy: 0.7747 - val_loss: 0.5771\n",
            "Epoch 152/200\n",
            "14/14 - 181s - 13s/step - accuracy: 0.7612 - loss: 0.5493 - val_accuracy: 0.7747 - val_loss: 0.5969\n",
            "Epoch 153/200\n",
            "14/14 - 142s - 10s/step - accuracy: 0.7825 - loss: 0.5262 - val_accuracy: 0.7582 - val_loss: 0.5891\n",
            "Epoch 154/200\n",
            "14/14 - 143s - 10s/step - accuracy: 0.7991 - loss: 0.5125 - val_accuracy: 0.7747 - val_loss: 0.5760\n",
            "Epoch 155/200\n",
            "14/14 - 182s - 13s/step - accuracy: 0.8274 - loss: 0.4658 - val_accuracy: 0.7637 - val_loss: 0.5766\n",
            "Epoch 156/200\n",
            "14/14 - 141s - 10s/step - accuracy: 0.7920 - loss: 0.5212 - val_accuracy: 0.7692 - val_loss: 0.5794\n",
            "Epoch 157/200\n",
            "14/14 - 141s - 10s/step - accuracy: 0.7470 - loss: 0.6060 - val_accuracy: 0.7582 - val_loss: 0.5996\n",
            "Epoch 158/200\n",
            "14/14 - 141s - 10s/step - accuracy: 0.7920 - loss: 0.5352 - val_accuracy: 0.7637 - val_loss: 0.5966\n",
            "Epoch 159/200\n",
            "14/14 - 142s - 10s/step - accuracy: 0.7920 - loss: 0.5208 - val_accuracy: 0.7527 - val_loss: 0.5992\n",
            "Epoch 160/200\n",
            "14/14 - 140s - 10s/step - accuracy: 0.7518 - loss: 0.5873 - val_accuracy: 0.7582 - val_loss: 0.5956\n",
            "Epoch 161/200\n",
            "14/14 - 142s - 10s/step - accuracy: 0.7943 - loss: 0.5391 - val_accuracy: 0.7582 - val_loss: 0.5781\n",
            "Epoch 162/200\n",
            "14/14 - 140s - 10s/step - accuracy: 0.7730 - loss: 0.5276 - val_accuracy: 0.7692 - val_loss: 0.5739\n",
            "Epoch 163/200\n",
            "14/14 - 141s - 10s/step - accuracy: 0.7518 - loss: 0.5843 - val_accuracy: 0.7857 - val_loss: 0.5531\n",
            "Epoch 164/200\n",
            "14/14 - 139s - 10s/step - accuracy: 0.7872 - loss: 0.5554 - val_accuracy: 0.7637 - val_loss: 0.5630\n",
            "Epoch 165/200\n",
            "14/14 - 182s - 13s/step - accuracy: 0.8014 - loss: 0.5148 - val_accuracy: 0.7747 - val_loss: 0.5599\n",
            "Epoch 166/200\n",
            "14/14 - 140s - 10s/step - accuracy: 0.7991 - loss: 0.5362 - val_accuracy: 0.7637 - val_loss: 0.5878\n",
            "Epoch 167/200\n",
            "14/14 - 142s - 10s/step - accuracy: 0.7636 - loss: 0.5474 - val_accuracy: 0.7857 - val_loss: 0.5977\n",
            "Epoch 168/200\n",
            "14/14 - 184s - 13s/step - accuracy: 0.7754 - loss: 0.5555 - val_accuracy: 0.7692 - val_loss: 0.5755\n",
            "Epoch 169/200\n",
            "14/14 - 141s - 10s/step - accuracy: 0.7849 - loss: 0.5490 - val_accuracy: 0.7527 - val_loss: 0.6067\n",
            "Epoch 170/200\n",
            "14/14 - 145s - 10s/step - accuracy: 0.8274 - loss: 0.4810 - val_accuracy: 0.7527 - val_loss: 0.6101\n",
            "Epoch 171/200\n",
            "14/14 - 182s - 13s/step - accuracy: 0.8109 - loss: 0.5217 - val_accuracy: 0.7582 - val_loss: 0.5557\n",
            "Epoch 172/200\n",
            "14/14 - 143s - 10s/step - accuracy: 0.7849 - loss: 0.5176 - val_accuracy: 0.7473 - val_loss: 0.5608\n",
            "Epoch 173/200\n",
            "14/14 - 142s - 10s/step - accuracy: 0.7872 - loss: 0.5457 - val_accuracy: 0.7747 - val_loss: 0.5561\n",
            "Epoch 174/200\n",
            "14/14 - 142s - 10s/step - accuracy: 0.7612 - loss: 0.5622 - val_accuracy: 0.7418 - val_loss: 0.5687\n",
            "Epoch 175/200\n",
            "14/14 - 143s - 10s/step - accuracy: 0.7872 - loss: 0.5311 - val_accuracy: 0.7418 - val_loss: 0.5772\n",
            "Epoch 176/200\n",
            "14/14 - 181s - 13s/step - accuracy: 0.7801 - loss: 0.5252 - val_accuracy: 0.7582 - val_loss: 0.5900\n",
            "Epoch 177/200\n",
            "14/14 - 144s - 10s/step - accuracy: 0.7943 - loss: 0.4922 - val_accuracy: 0.7418 - val_loss: 0.5758\n",
            "Epoch 178/200\n",
            "14/14 - 143s - 10s/step - accuracy: 0.7801 - loss: 0.5320 - val_accuracy: 0.7692 - val_loss: 0.5577\n",
            "Epoch 179/200\n",
            "14/14 - 185s - 13s/step - accuracy: 0.7849 - loss: 0.5175 - val_accuracy: 0.7637 - val_loss: 0.5520\n",
            "Epoch 180/200\n",
            "14/14 - 139s - 10s/step - accuracy: 0.7778 - loss: 0.5574 - val_accuracy: 0.7582 - val_loss: 0.5591\n",
            "Epoch 181/200\n",
            "14/14 - 141s - 10s/step - accuracy: 0.7541 - loss: 0.5711 - val_accuracy: 0.7527 - val_loss: 0.5718\n",
            "Epoch 182/200\n",
            "14/14 - 140s - 10s/step - accuracy: 0.7920 - loss: 0.5318 - val_accuracy: 0.7692 - val_loss: 0.5569\n",
            "Epoch 183/200\n",
            "14/14 - 144s - 10s/step - accuracy: 0.8061 - loss: 0.5213 - val_accuracy: 0.7692 - val_loss: 0.5514\n",
            "Epoch 184/200\n",
            "14/14 - 140s - 10s/step - accuracy: 0.7920 - loss: 0.4961 - val_accuracy: 0.7692 - val_loss: 0.5477\n",
            "Epoch 185/200\n",
            "14/14 - 146s - 10s/step - accuracy: 0.7518 - loss: 0.5835 - val_accuracy: 0.7802 - val_loss: 0.5355\n",
            "Epoch 186/200\n",
            "14/14 - 143s - 10s/step - accuracy: 0.7896 - loss: 0.5063 - val_accuracy: 0.7857 - val_loss: 0.5421\n",
            "Epoch 187/200\n",
            "14/14 - 146s - 10s/step - accuracy: 0.7683 - loss: 0.5650 - val_accuracy: 0.7747 - val_loss: 0.5673\n",
            "Epoch 188/200\n",
            "14/14 - 200s - 14s/step - accuracy: 0.7849 - loss: 0.5052 - val_accuracy: 0.7692 - val_loss: 0.5745\n",
            "Epoch 189/200\n",
            "14/14 - 142s - 10s/step - accuracy: 0.7400 - loss: 0.5825 - val_accuracy: 0.7747 - val_loss: 0.5770\n",
            "Epoch 190/200\n",
            "14/14 - 143s - 10s/step - accuracy: 0.7730 - loss: 0.5350 - val_accuracy: 0.7637 - val_loss: 0.5858\n",
            "Epoch 191/200\n",
            "14/14 - 141s - 10s/step - accuracy: 0.7778 - loss: 0.5058 - val_accuracy: 0.7582 - val_loss: 0.5736\n",
            "Epoch 192/200\n",
            "14/14 - 184s - 13s/step - accuracy: 0.7967 - loss: 0.4990 - val_accuracy: 0.7473 - val_loss: 0.5864\n",
            "Epoch 193/200\n",
            "14/14 - 140s - 10s/step - accuracy: 0.7825 - loss: 0.5143 - val_accuracy: 0.7527 - val_loss: 0.5991\n",
            "Epoch 194/200\n",
            "14/14 - 143s - 10s/step - accuracy: 0.8014 - loss: 0.5304 - val_accuracy: 0.7637 - val_loss: 0.5830\n",
            "Epoch 195/200\n",
            "14/14 - 145s - 10s/step - accuracy: 0.8156 - loss: 0.4788 - val_accuracy: 0.7582 - val_loss: 0.5693\n",
            "Epoch 196/200\n",
            "14/14 - 142s - 10s/step - accuracy: 0.8109 - loss: 0.5121 - val_accuracy: 0.7692 - val_loss: 0.5621\n",
            "Epoch 197/200\n",
            "14/14 - 142s - 10s/step - accuracy: 0.7754 - loss: 0.5251 - val_accuracy: 0.7747 - val_loss: 0.5604\n",
            "Epoch 198/200\n",
            "14/14 - 141s - 10s/step - accuracy: 0.7825 - loss: 0.5052 - val_accuracy: 0.7582 - val_loss: 0.5829\n",
            "Epoch 199/200\n",
            "14/14 - 144s - 10s/step - accuracy: 0.7825 - loss: 0.5280 - val_accuracy: 0.7637 - val_loss: 0.5662\n",
            "Epoch 200/200\n",
            "14/14 - 143s - 10s/step - accuracy: 0.7991 - loss: 0.4983 - val_accuracy: 0.7747 - val_loss: 0.5592\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model berhasil disimpan: model_split70_lr0.001_ep200_l20.0001.h5\n"
          ]
        }
      ],
      "source": [
        "split_ratio = 0.7\n",
        "split_percent = round(split_ratio * 100)\n",
        "\n",
        "for lr in [0.001]:\n",
        "    for epoch in [200]:\n",
        "        print(f\"\\n📦 Training model dengan split_ratio={split_percent}%, learning_rate={lr}, epochs={epoch}\")\n",
        "\n",
        "        model, history = train_model(\n",
        "            split_ratio=split_ratio,\n",
        "            lr=lr,\n",
        "            epochs=epoch\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WzGv2R2JmyGF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzGv2R2JmyGF",
        "outputId": "7ec91bc8-a2b4-4078-b5c9-8fb53d45e1ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📦 Training model dengan split_ratio=70%, learning_rate=0.001, epochs=300\n",
            "Found 423 images belonging to 3 classes.\n",
            "Found 182 images belonging to 3 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "14/14 - 168s - 12s/step - accuracy: 0.3239 - loss: 1.8704 - val_accuracy: 0.4505 - val_loss: 1.0731\n",
            "Epoch 2/300\n",
            "14/14 - 232s - 17s/step - accuracy: 0.4350 - loss: 1.3225 - val_accuracy: 0.4945 - val_loss: 1.0078\n",
            "Epoch 3/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.4492 - loss: 1.1942 - val_accuracy: 0.5330 - val_loss: 0.9848\n",
            "Epoch 4/300\n",
            "14/14 - 151s - 11s/step - accuracy: 0.4823 - loss: 1.0962 - val_accuracy: 0.5495 - val_loss: 0.9753\n",
            "Epoch 5/300\n",
            "14/14 - 186s - 13s/step - accuracy: 0.5177 - loss: 0.9767 - val_accuracy: 0.5769 - val_loss: 0.9609\n",
            "Epoch 6/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.5248 - loss: 1.0201 - val_accuracy: 0.5659 - val_loss: 0.9493\n",
            "Epoch 7/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.5863 - loss: 0.9891 - val_accuracy: 0.5989 - val_loss: 0.9360\n",
            "Epoch 8/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.5839 - loss: 0.9600 - val_accuracy: 0.5769 - val_loss: 0.9265\n",
            "Epoch 9/300\n",
            "14/14 - 185s - 13s/step - accuracy: 0.5697 - loss: 0.9436 - val_accuracy: 0.6099 - val_loss: 0.9133\n",
            "Epoch 10/300\n",
            "14/14 - 165s - 12s/step - accuracy: 0.5981 - loss: 0.9288 - val_accuracy: 0.6099 - val_loss: 0.9001\n",
            "Epoch 11/300\n",
            "14/14 - 186s - 13s/step - accuracy: 0.5816 - loss: 0.9277 - val_accuracy: 0.5879 - val_loss: 0.8972\n",
            "Epoch 12/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.5674 - loss: 0.9250 - val_accuracy: 0.6264 - val_loss: 0.8951\n",
            "Epoch 13/300\n",
            "14/14 - 201s - 14s/step - accuracy: 0.5910 - loss: 0.9289 - val_accuracy: 0.6319 - val_loss: 0.8850\n",
            "Epoch 14/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.5910 - loss: 0.8907 - val_accuracy: 0.6648 - val_loss: 0.8781\n",
            "Epoch 15/300\n",
            "14/14 - 147s - 10s/step - accuracy: 0.6241 - loss: 0.8802 - val_accuracy: 0.6429 - val_loss: 0.8662\n",
            "Epoch 16/300\n",
            "14/14 - 182s - 13s/step - accuracy: 0.6170 - loss: 0.8594 - val_accuracy: 0.6758 - val_loss: 0.8353\n",
            "Epoch 17/300\n",
            "14/14 - 147s - 11s/step - accuracy: 0.6052 - loss: 0.9035 - val_accuracy: 0.6484 - val_loss: 0.8281\n",
            "Epoch 18/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.6076 - loss: 0.8887 - val_accuracy: 0.6703 - val_loss: 0.8230\n",
            "Epoch 19/300\n",
            "14/14 - 186s - 13s/step - accuracy: 0.5839 - loss: 0.9077 - val_accuracy: 0.6758 - val_loss: 0.8289\n",
            "Epoch 20/300\n",
            "14/14 - 186s - 13s/step - accuracy: 0.6501 - loss: 0.8278 - val_accuracy: 0.6703 - val_loss: 0.8362\n",
            "Epoch 21/300\n",
            "14/14 - 164s - 12s/step - accuracy: 0.6241 - loss: 0.8754 - val_accuracy: 0.6813 - val_loss: 0.8224\n",
            "Epoch 22/300\n",
            "14/14 - 149s - 11s/step - accuracy: 0.6312 - loss: 0.8079 - val_accuracy: 0.6648 - val_loss: 0.8056\n",
            "Epoch 23/300\n",
            "14/14 - 185s - 13s/step - accuracy: 0.6052 - loss: 0.8834 - val_accuracy: 0.6429 - val_loss: 0.8094\n",
            "Epoch 24/300\n",
            "14/14 - 146s - 10s/step - accuracy: 0.6217 - loss: 0.8775 - val_accuracy: 0.6703 - val_loss: 0.8082\n",
            "Epoch 25/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.6643 - loss: 0.8309 - val_accuracy: 0.6703 - val_loss: 0.7975\n",
            "Epoch 26/300\n",
            "14/14 - 147s - 11s/step - accuracy: 0.6738 - loss: 0.7853 - val_accuracy: 0.6813 - val_loss: 0.7864\n",
            "Epoch 27/300\n",
            "14/14 - 149s - 11s/step - accuracy: 0.6738 - loss: 0.7848 - val_accuracy: 0.6868 - val_loss: 0.7900\n",
            "Epoch 28/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.6738 - loss: 0.7871 - val_accuracy: 0.6648 - val_loss: 0.7818\n",
            "Epoch 29/300\n",
            "14/14 - 150s - 11s/step - accuracy: 0.6383 - loss: 0.8099 - val_accuracy: 0.6868 - val_loss: 0.7752\n",
            "Epoch 30/300\n",
            "14/14 - 149s - 11s/step - accuracy: 0.6265 - loss: 0.8291 - val_accuracy: 0.6923 - val_loss: 0.7633\n",
            "Epoch 31/300\n",
            "14/14 - 185s - 13s/step - accuracy: 0.6454 - loss: 0.7694 - val_accuracy: 0.6978 - val_loss: 0.7600\n",
            "Epoch 32/300\n",
            "14/14 - 187s - 13s/step - accuracy: 0.6738 - loss: 0.7818 - val_accuracy: 0.7088 - val_loss: 0.7495\n",
            "Epoch 33/300\n",
            "14/14 - 186s - 13s/step - accuracy: 0.6738 - loss: 0.7644 - val_accuracy: 0.7143 - val_loss: 0.7472\n",
            "Epoch 34/300\n",
            "14/14 - 201s - 14s/step - accuracy: 0.6690 - loss: 0.8059 - val_accuracy: 0.6923 - val_loss: 0.7560\n",
            "Epoch 35/300\n",
            "14/14 - 187s - 13s/step - accuracy: 0.6761 - loss: 0.7567 - val_accuracy: 0.6868 - val_loss: 0.7565\n",
            "Epoch 36/300\n",
            "14/14 - 186s - 13s/step - accuracy: 0.6785 - loss: 0.7574 - val_accuracy: 0.7033 - val_loss: 0.7419\n",
            "Epoch 37/300\n",
            "14/14 - 201s - 14s/step - accuracy: 0.6856 - loss: 0.7472 - val_accuracy: 0.6758 - val_loss: 0.7392\n",
            "Epoch 38/300\n",
            "14/14 - 165s - 12s/step - accuracy: 0.6525 - loss: 0.7416 - val_accuracy: 0.6868 - val_loss: 0.7310\n",
            "Epoch 39/300\n",
            "14/14 - 187s - 13s/step - accuracy: 0.6667 - loss: 0.7870 - val_accuracy: 0.7143 - val_loss: 0.7183\n",
            "Epoch 40/300\n",
            "14/14 - 186s - 13s/step - accuracy: 0.6761 - loss: 0.7540 - val_accuracy: 0.6978 - val_loss: 0.7123\n",
            "Epoch 41/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.6903 - loss: 0.7562 - val_accuracy: 0.6813 - val_loss: 0.7224\n",
            "Epoch 42/300\n",
            "14/14 - 183s - 13s/step - accuracy: 0.6809 - loss: 0.7751 - val_accuracy: 0.6813 - val_loss: 0.7119\n",
            "Epoch 43/300\n",
            "14/14 - 168s - 12s/step - accuracy: 0.6903 - loss: 0.7450 - val_accuracy: 0.7143 - val_loss: 0.7083\n",
            "Epoch 44/300\n",
            "14/14 - 186s - 13s/step - accuracy: 0.6809 - loss: 0.7503 - val_accuracy: 0.7198 - val_loss: 0.7050\n",
            "Epoch 45/300\n",
            "14/14 - 187s - 13s/step - accuracy: 0.6879 - loss: 0.7277 - val_accuracy: 0.6978 - val_loss: 0.7034\n",
            "Epoch 46/300\n",
            "14/14 - 163s - 12s/step - accuracy: 0.6832 - loss: 0.7516 - val_accuracy: 0.7033 - val_loss: 0.6967\n",
            "Epoch 47/300\n",
            "14/14 - 185s - 13s/step - accuracy: 0.6761 - loss: 0.7415 - val_accuracy: 0.7033 - val_loss: 0.6916\n",
            "Epoch 48/300\n",
            "14/14 - 147s - 10s/step - accuracy: 0.6974 - loss: 0.7047 - val_accuracy: 0.7308 - val_loss: 0.6820\n",
            "Epoch 49/300\n",
            "14/14 - 147s - 10s/step - accuracy: 0.6643 - loss: 0.7821 - val_accuracy: 0.7418 - val_loss: 0.6773\n",
            "Epoch 50/300\n",
            "14/14 - 202s - 14s/step - accuracy: 0.6927 - loss: 0.7352 - val_accuracy: 0.7033 - val_loss: 0.6851\n",
            "Epoch 51/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.7116 - loss: 0.6810 - val_accuracy: 0.7308 - val_loss: 0.6887\n",
            "Epoch 52/300\n",
            "14/14 - 186s - 13s/step - accuracy: 0.6809 - loss: 0.7298 - val_accuracy: 0.7143 - val_loss: 0.6969\n",
            "Epoch 53/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.7116 - loss: 0.6991 - val_accuracy: 0.7033 - val_loss: 0.6899\n",
            "Epoch 54/300\n",
            "14/14 - 149s - 11s/step - accuracy: 0.6998 - loss: 0.7085 - val_accuracy: 0.7088 - val_loss: 0.6840\n",
            "Epoch 55/300\n",
            "14/14 - 202s - 14s/step - accuracy: 0.7139 - loss: 0.7354 - val_accuracy: 0.7363 - val_loss: 0.6763\n",
            "Epoch 56/300\n",
            "14/14 - 186s - 13s/step - accuracy: 0.6832 - loss: 0.6982 - val_accuracy: 0.7418 - val_loss: 0.6620\n",
            "Epoch 57/300\n",
            "14/14 - 185s - 13s/step - accuracy: 0.6950 - loss: 0.6983 - val_accuracy: 0.7253 - val_loss: 0.6783\n",
            "Epoch 58/300\n",
            "14/14 - 186s - 13s/step - accuracy: 0.7210 - loss: 0.6661 - val_accuracy: 0.7308 - val_loss: 0.6654\n",
            "Epoch 59/300\n",
            "14/14 - 183s - 13s/step - accuracy: 0.7069 - loss: 0.6760 - val_accuracy: 0.7308 - val_loss: 0.6686\n",
            "Epoch 60/300\n",
            "14/14 - 167s - 12s/step - accuracy: 0.6525 - loss: 0.7629 - val_accuracy: 0.7473 - val_loss: 0.6763\n",
            "Epoch 61/300\n",
            "14/14 - 149s - 11s/step - accuracy: 0.7139 - loss: 0.7229 - val_accuracy: 0.7473 - val_loss: 0.6740\n",
            "Epoch 62/300\n",
            "14/14 - 201s - 14s/step - accuracy: 0.6927 - loss: 0.7001 - val_accuracy: 0.7198 - val_loss: 0.6632\n",
            "Epoch 63/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.7400 - loss: 0.6530 - val_accuracy: 0.7637 - val_loss: 0.6478\n",
            "Epoch 64/300\n",
            "14/14 - 186s - 13s/step - accuracy: 0.7116 - loss: 0.6943 - val_accuracy: 0.7527 - val_loss: 0.6703\n",
            "Epoch 65/300\n",
            "14/14 - 184s - 13s/step - accuracy: 0.7069 - loss: 0.6816 - val_accuracy: 0.7363 - val_loss: 0.6719\n",
            "Epoch 66/300\n",
            "14/14 - 146s - 10s/step - accuracy: 0.7258 - loss: 0.6717 - val_accuracy: 0.7418 - val_loss: 0.6475\n",
            "Epoch 67/300\n",
            "14/14 - 147s - 10s/step - accuracy: 0.7163 - loss: 0.6605 - val_accuracy: 0.7747 - val_loss: 0.6571\n",
            "Epoch 68/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.6785 - loss: 0.7183 - val_accuracy: 0.7473 - val_loss: 0.6642\n",
            "Epoch 69/300\n",
            "14/14 - 185s - 13s/step - accuracy: 0.7447 - loss: 0.6377 - val_accuracy: 0.7582 - val_loss: 0.6472\n",
            "Epoch 70/300\n",
            "14/14 - 187s - 13s/step - accuracy: 0.7092 - loss: 0.6640 - val_accuracy: 0.7418 - val_loss: 0.6672\n",
            "Epoch 71/300\n",
            "14/14 - 187s - 13s/step - accuracy: 0.7163 - loss: 0.6681 - val_accuracy: 0.7473 - val_loss: 0.6438\n",
            "Epoch 72/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.7234 - loss: 0.6718 - val_accuracy: 0.7582 - val_loss: 0.6437\n",
            "Epoch 73/300\n",
            "14/14 - 183s - 13s/step - accuracy: 0.7565 - loss: 0.6422 - val_accuracy: 0.7582 - val_loss: 0.6483\n",
            "Epoch 74/300\n",
            "14/14 - 167s - 12s/step - accuracy: 0.6998 - loss: 0.6817 - val_accuracy: 0.7692 - val_loss: 0.6351\n",
            "Epoch 75/300\n",
            "14/14 - 185s - 13s/step - accuracy: 0.7045 - loss: 0.6953 - val_accuracy: 0.7527 - val_loss: 0.6512\n",
            "Epoch 76/300\n",
            "14/14 - 187s - 13s/step - accuracy: 0.7423 - loss: 0.6458 - val_accuracy: 0.7692 - val_loss: 0.6524\n",
            "Epoch 77/300\n",
            "14/14 - 184s - 13s/step - accuracy: 0.7281 - loss: 0.6392 - val_accuracy: 0.7473 - val_loss: 0.6626\n",
            "Epoch 78/300\n",
            "14/14 - 183s - 13s/step - accuracy: 0.7565 - loss: 0.6063 - val_accuracy: 0.7418 - val_loss: 0.6521\n",
            "Epoch 79/300\n",
            "14/14 - 166s - 12s/step - accuracy: 0.7352 - loss: 0.6602 - val_accuracy: 0.7308 - val_loss: 0.6368\n",
            "Epoch 80/300\n",
            "14/14 - 185s - 13s/step - accuracy: 0.7281 - loss: 0.6653 - val_accuracy: 0.7473 - val_loss: 0.6540\n",
            "Epoch 81/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.7139 - loss: 0.6643 - val_accuracy: 0.7747 - val_loss: 0.6347\n",
            "Epoch 82/300\n",
            "14/14 - 145s - 10s/step - accuracy: 0.7660 - loss: 0.6230 - val_accuracy: 0.7473 - val_loss: 0.6372\n",
            "Epoch 83/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.7376 - loss: 0.6443 - val_accuracy: 0.7692 - val_loss: 0.6406\n",
            "Epoch 84/300\n",
            "14/14 - 149s - 11s/step - accuracy: 0.7258 - loss: 0.6760 - val_accuracy: 0.7582 - val_loss: 0.6350\n",
            "Epoch 85/300\n",
            "14/14 - 147s - 11s/step - accuracy: 0.7565 - loss: 0.6293 - val_accuracy: 0.7582 - val_loss: 0.6216\n",
            "Epoch 86/300\n",
            "14/14 - 146s - 10s/step - accuracy: 0.7400 - loss: 0.6343 - val_accuracy: 0.7692 - val_loss: 0.6228\n",
            "Epoch 87/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.7565 - loss: 0.6176 - val_accuracy: 0.7473 - val_loss: 0.6476\n",
            "Epoch 88/300\n",
            "14/14 - 149s - 11s/step - accuracy: 0.7612 - loss: 0.6206 - val_accuracy: 0.7473 - val_loss: 0.6430\n",
            "Epoch 89/300\n",
            "14/14 - 186s - 13s/step - accuracy: 0.7470 - loss: 0.6037 - val_accuracy: 0.7527 - val_loss: 0.6280\n",
            "Epoch 90/300\n",
            "14/14 - 145s - 10s/step - accuracy: 0.7589 - loss: 0.6362 - val_accuracy: 0.7582 - val_loss: 0.6309\n",
            "Epoch 91/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.7518 - loss: 0.6217 - val_accuracy: 0.7637 - val_loss: 0.6317\n",
            "Epoch 92/300\n",
            "14/14 - 186s - 13s/step - accuracy: 0.7258 - loss: 0.6688 - val_accuracy: 0.7473 - val_loss: 0.6380\n",
            "Epoch 93/300\n",
            "14/14 - 187s - 13s/step - accuracy: 0.7352 - loss: 0.6170 - val_accuracy: 0.7637 - val_loss: 0.6151\n",
            "Epoch 94/300\n",
            "14/14 - 186s - 13s/step - accuracy: 0.7400 - loss: 0.6210 - val_accuracy: 0.7637 - val_loss: 0.6047\n",
            "Epoch 95/300\n",
            "14/14 - 164s - 12s/step - accuracy: 0.7352 - loss: 0.6237 - val_accuracy: 0.7637 - val_loss: 0.6204\n",
            "Epoch 96/300\n",
            "14/14 - 194s - 14s/step - accuracy: 0.7494 - loss: 0.6140 - val_accuracy: 0.7637 - val_loss: 0.6106\n",
            "Epoch 97/300\n",
            "14/14 - 233s - 17s/step - accuracy: 0.7683 - loss: 0.5767 - val_accuracy: 0.7747 - val_loss: 0.6045\n",
            "Epoch 98/300\n",
            "14/14 - 184s - 13s/step - accuracy: 0.7565 - loss: 0.5801 - val_accuracy: 0.7582 - val_loss: 0.6089\n",
            "Epoch 99/300\n",
            "14/14 - 166s - 12s/step - accuracy: 0.7470 - loss: 0.6420 - val_accuracy: 0.7527 - val_loss: 0.5991\n",
            "Epoch 100/300\n",
            "14/14 - 183s - 13s/step - accuracy: 0.7423 - loss: 0.5985 - val_accuracy: 0.7418 - val_loss: 0.6091\n",
            "Epoch 101/300\n",
            "14/14 - 168s - 12s/step - accuracy: 0.7423 - loss: 0.6076 - val_accuracy: 0.7582 - val_loss: 0.6058\n",
            "Epoch 102/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.7258 - loss: 0.6717 - val_accuracy: 0.7692 - val_loss: 0.6181\n",
            "Epoch 103/300\n",
            "14/14 - 146s - 10s/step - accuracy: 0.7541 - loss: 0.5825 - val_accuracy: 0.7692 - val_loss: 0.5947\n",
            "Epoch 104/300\n",
            "14/14 - 205s - 15s/step - accuracy: 0.7825 - loss: 0.5716 - val_accuracy: 0.7747 - val_loss: 0.6000\n",
            "Epoch 105/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.7352 - loss: 0.5957 - val_accuracy: 0.7692 - val_loss: 0.5952\n",
            "Epoch 106/300\n",
            "14/14 - 185s - 13s/step - accuracy: 0.7470 - loss: 0.6134 - val_accuracy: 0.7747 - val_loss: 0.5894\n",
            "Epoch 107/300\n",
            "14/14 - 186s - 13s/step - accuracy: 0.7541 - loss: 0.5751 - val_accuracy: 0.7637 - val_loss: 0.6046\n",
            "Epoch 108/300\n",
            "14/14 - 202s - 14s/step - accuracy: 0.7565 - loss: 0.6261 - val_accuracy: 0.7582 - val_loss: 0.5924\n",
            "Epoch 109/300\n",
            "14/14 - 202s - 14s/step - accuracy: 0.7660 - loss: 0.5996 - val_accuracy: 0.7692 - val_loss: 0.5900\n",
            "Epoch 110/300\n",
            "14/14 - 146s - 10s/step - accuracy: 0.7636 - loss: 0.6036 - val_accuracy: 0.7802 - val_loss: 0.5895\n",
            "Epoch 111/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.7258 - loss: 0.6036 - val_accuracy: 0.7747 - val_loss: 0.5830\n",
            "Epoch 112/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.7754 - loss: 0.6022 - val_accuracy: 0.7692 - val_loss: 0.6030\n",
            "Epoch 113/300\n",
            "14/14 - 149s - 11s/step - accuracy: 0.7730 - loss: 0.5722 - val_accuracy: 0.7637 - val_loss: 0.6040\n",
            "Epoch 114/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.7589 - loss: 0.5870 - val_accuracy: 0.7308 - val_loss: 0.6240\n",
            "Epoch 115/300\n",
            "14/14 - 186s - 13s/step - accuracy: 0.6998 - loss: 0.6400 - val_accuracy: 0.7198 - val_loss: 0.6425\n",
            "Epoch 116/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.7518 - loss: 0.5905 - val_accuracy: 0.7582 - val_loss: 0.5869\n",
            "Epoch 117/300\n",
            "14/14 - 145s - 10s/step - accuracy: 0.7565 - loss: 0.6263 - val_accuracy: 0.7747 - val_loss: 0.5978\n",
            "Epoch 118/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.7683 - loss: 0.5830 - val_accuracy: 0.7857 - val_loss: 0.5870\n",
            "Epoch 119/300\n",
            "14/14 - 149s - 11s/step - accuracy: 0.7494 - loss: 0.6288 - val_accuracy: 0.7692 - val_loss: 0.5801\n",
            "Epoch 120/300\n",
            "14/14 - 239s - 17s/step - accuracy: 0.7447 - loss: 0.5810 - val_accuracy: 0.7747 - val_loss: 0.5832\n",
            "Epoch 121/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.7612 - loss: 0.5760 - val_accuracy: 0.7747 - val_loss: 0.5904\n",
            "Epoch 122/300\n",
            "14/14 - 201s - 14s/step - accuracy: 0.7494 - loss: 0.6271 - val_accuracy: 0.7747 - val_loss: 0.5920\n",
            "Epoch 123/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.7423 - loss: 0.6170 - val_accuracy: 0.7692 - val_loss: 0.6022\n",
            "Epoch 124/300\n",
            "14/14 - 149s - 11s/step - accuracy: 0.7541 - loss: 0.5832 - val_accuracy: 0.7747 - val_loss: 0.6103\n",
            "Epoch 125/300\n",
            "14/14 - 145s - 10s/step - accuracy: 0.7589 - loss: 0.5860 - val_accuracy: 0.7912 - val_loss: 0.5867\n",
            "Epoch 126/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.7589 - loss: 0.6252 - val_accuracy: 0.7912 - val_loss: 0.5982\n",
            "Epoch 127/300\n",
            "14/14 - 149s - 11s/step - accuracy: 0.7943 - loss: 0.5558 - val_accuracy: 0.7802 - val_loss: 0.5776\n",
            "Epoch 128/300\n",
            "14/14 - 147s - 11s/step - accuracy: 0.7400 - loss: 0.5711 - val_accuracy: 0.7912 - val_loss: 0.5824\n",
            "Epoch 129/300\n",
            "14/14 - 149s - 11s/step - accuracy: 0.7541 - loss: 0.5794 - val_accuracy: 0.7692 - val_loss: 0.6120\n",
            "Epoch 130/300\n",
            "14/14 - 188s - 13s/step - accuracy: 0.7589 - loss: 0.5968 - val_accuracy: 0.7473 - val_loss: 0.6010\n",
            "Epoch 131/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.7447 - loss: 0.6211 - val_accuracy: 0.7747 - val_loss: 0.5957\n",
            "Epoch 132/300\n",
            "14/14 - 203s - 15s/step - accuracy: 0.7565 - loss: 0.5785 - val_accuracy: 0.7802 - val_loss: 0.5802\n",
            "Epoch 133/300\n",
            "14/14 - 206s - 15s/step - accuracy: 0.7730 - loss: 0.5831 - val_accuracy: 0.7692 - val_loss: 0.5771\n",
            "Epoch 134/300\n",
            "14/14 - 150s - 11s/step - accuracy: 0.7447 - loss: 0.6056 - val_accuracy: 0.7473 - val_loss: 0.5983\n",
            "Epoch 135/300\n",
            "14/14 - 151s - 11s/step - accuracy: 0.7541 - loss: 0.5758 - val_accuracy: 0.7967 - val_loss: 0.5744\n",
            "Epoch 136/300\n",
            "14/14 - 150s - 11s/step - accuracy: 0.7518 - loss: 0.5869 - val_accuracy: 0.7582 - val_loss: 0.5889\n",
            "Epoch 137/300\n",
            "14/14 - 189s - 14s/step - accuracy: 0.7683 - loss: 0.6029 - val_accuracy: 0.7802 - val_loss: 0.5825\n",
            "Epoch 138/300\n",
            "14/14 - 150s - 11s/step - accuracy: 0.7612 - loss: 0.5852 - val_accuracy: 0.8022 - val_loss: 0.5724\n",
            "Epoch 139/300\n",
            "14/14 - 149s - 11s/step - accuracy: 0.7683 - loss: 0.5880 - val_accuracy: 0.7802 - val_loss: 0.5873\n",
            "Epoch 140/300\n",
            "14/14 - 149s - 11s/step - accuracy: 0.7589 - loss: 0.5637 - val_accuracy: 0.7802 - val_loss: 0.5890\n",
            "Epoch 141/300\n",
            "14/14 - 149s - 11s/step - accuracy: 0.7896 - loss: 0.5538 - val_accuracy: 0.7692 - val_loss: 0.5808\n",
            "Epoch 142/300\n",
            "14/14 - 184s - 13s/step - accuracy: 0.7825 - loss: 0.5731 - val_accuracy: 0.8022 - val_loss: 0.5583\n",
            "Epoch 143/300\n",
            "14/14 - 167s - 12s/step - accuracy: 0.7660 - loss: 0.5865 - val_accuracy: 0.7912 - val_loss: 0.5621\n",
            "Epoch 144/300\n",
            "14/14 - 149s - 11s/step - accuracy: 0.7423 - loss: 0.6093 - val_accuracy: 0.7747 - val_loss: 0.5868\n",
            "Epoch 145/300\n",
            "14/14 - 186s - 13s/step - accuracy: 0.7636 - loss: 0.5658 - val_accuracy: 0.7802 - val_loss: 0.5716\n",
            "Epoch 146/300\n",
            "14/14 - 147s - 10s/step - accuracy: 0.7612 - loss: 0.5905 - val_accuracy: 0.7747 - val_loss: 0.5859\n",
            "Epoch 147/300\n",
            "14/14 - 187s - 13s/step - accuracy: 0.7660 - loss: 0.5749 - val_accuracy: 0.7637 - val_loss: 0.5998\n",
            "Epoch 148/300\n",
            "14/14 - 185s - 13s/step - accuracy: 0.7920 - loss: 0.5556 - val_accuracy: 0.7802 - val_loss: 0.5974\n",
            "Epoch 149/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.7541 - loss: 0.5698 - val_accuracy: 0.7582 - val_loss: 0.6107\n",
            "Epoch 150/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.7541 - loss: 0.5876 - val_accuracy: 0.7637 - val_loss: 0.6024\n",
            "Epoch 151/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.7943 - loss: 0.5536 - val_accuracy: 0.7637 - val_loss: 0.5894\n",
            "Epoch 152/300\n",
            "14/14 - 202s - 14s/step - accuracy: 0.8061 - loss: 0.5405 - val_accuracy: 0.7363 - val_loss: 0.6191\n",
            "Epoch 153/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.7683 - loss: 0.5426 - val_accuracy: 0.7692 - val_loss: 0.5905\n",
            "Epoch 154/300\n",
            "14/14 - 146s - 10s/step - accuracy: 0.7754 - loss: 0.5654 - val_accuracy: 0.7637 - val_loss: 0.5887\n",
            "Epoch 155/300\n",
            "14/14 - 145s - 10s/step - accuracy: 0.7849 - loss: 0.5099 - val_accuracy: 0.7692 - val_loss: 0.5824\n",
            "Epoch 156/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.7849 - loss: 0.5364 - val_accuracy: 0.7857 - val_loss: 0.5583\n",
            "Epoch 157/300\n",
            "14/14 - 147s - 11s/step - accuracy: 0.7967 - loss: 0.5382 - val_accuracy: 0.7857 - val_loss: 0.5519\n",
            "Epoch 158/300\n",
            "14/14 - 147s - 11s/step - accuracy: 0.7991 - loss: 0.5107 - val_accuracy: 0.7582 - val_loss: 0.5875\n",
            "Epoch 159/300\n",
            "14/14 - 183s - 13s/step - accuracy: 0.7660 - loss: 0.5656 - val_accuracy: 0.7418 - val_loss: 0.5811\n",
            "Epoch 160/300\n",
            "14/14 - 144s - 10s/step - accuracy: 0.7754 - loss: 0.5040 - val_accuracy: 0.7582 - val_loss: 0.5725\n",
            "Epoch 161/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.7541 - loss: 0.5877 - val_accuracy: 0.7418 - val_loss: 0.5737\n",
            "Epoch 162/300\n",
            "14/14 - 186s - 13s/step - accuracy: 0.7541 - loss: 0.5499 - val_accuracy: 0.7473 - val_loss: 0.5895\n",
            "Epoch 163/300\n",
            "14/14 - 146s - 10s/step - accuracy: 0.7967 - loss: 0.5400 - val_accuracy: 0.7527 - val_loss: 0.6017\n",
            "Epoch 164/300\n",
            "14/14 - 242s - 17s/step - accuracy: 0.7778 - loss: 0.5387 - val_accuracy: 0.7692 - val_loss: 0.5677\n",
            "Epoch 165/300\n",
            "14/14 - 187s - 13s/step - accuracy: 0.7730 - loss: 0.5508 - val_accuracy: 0.7802 - val_loss: 0.5613\n",
            "Epoch 166/300\n",
            "14/14 - 187s - 13s/step - accuracy: 0.7872 - loss: 0.5476 - val_accuracy: 0.7692 - val_loss: 0.5734\n",
            "Epoch 167/300\n",
            "14/14 - 147s - 11s/step - accuracy: 0.7778 - loss: 0.5379 - val_accuracy: 0.7637 - val_loss: 0.5649\n",
            "Epoch 168/300\n",
            "14/14 - 241s - 17s/step - accuracy: 0.8203 - loss: 0.4840 - val_accuracy: 0.7527 - val_loss: 0.5684\n",
            "Epoch 169/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.8061 - loss: 0.5072 - val_accuracy: 0.7637 - val_loss: 0.5677\n",
            "Epoch 170/300\n",
            "14/14 - 201s - 14s/step - accuracy: 0.7801 - loss: 0.5451 - val_accuracy: 0.8022 - val_loss: 0.5397\n",
            "Epoch 171/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.7754 - loss: 0.5285 - val_accuracy: 0.7967 - val_loss: 0.5457\n",
            "Epoch 172/300\n",
            "14/14 - 147s - 11s/step - accuracy: 0.7518 - loss: 0.5411 - val_accuracy: 0.7637 - val_loss: 0.5699\n",
            "Epoch 173/300\n",
            "14/14 - 203s - 15s/step - accuracy: 0.7565 - loss: 0.5604 - val_accuracy: 0.7692 - val_loss: 0.5763\n",
            "Epoch 174/300\n",
            "14/14 - 149s - 11s/step - accuracy: 0.7920 - loss: 0.5264 - val_accuracy: 0.7802 - val_loss: 0.5759\n",
            "Epoch 175/300\n",
            "14/14 - 146s - 10s/step - accuracy: 0.7943 - loss: 0.5094 - val_accuracy: 0.7747 - val_loss: 0.5763\n",
            "Epoch 176/300\n",
            "14/14 - 185s - 13s/step - accuracy: 0.7967 - loss: 0.4961 - val_accuracy: 0.7637 - val_loss: 0.5899\n",
            "Epoch 177/300\n",
            "14/14 - 147s - 10s/step - accuracy: 0.7872 - loss: 0.5270 - val_accuracy: 0.7747 - val_loss: 0.5669\n",
            "Epoch 178/300\n",
            "14/14 - 186s - 13s/step - accuracy: 0.7967 - loss: 0.5267 - val_accuracy: 0.7802 - val_loss: 0.5453\n",
            "Epoch 179/300\n",
            "14/14 - 187s - 13s/step - accuracy: 0.7612 - loss: 0.5714 - val_accuracy: 0.7527 - val_loss: 0.5652\n",
            "Epoch 180/300\n",
            "14/14 - 150s - 11s/step - accuracy: 0.7967 - loss: 0.5295 - val_accuracy: 0.7747 - val_loss: 0.5549\n",
            "Epoch 181/300\n",
            "14/14 - 187s - 13s/step - accuracy: 0.7636 - loss: 0.5746 - val_accuracy: 0.7802 - val_loss: 0.5660\n",
            "Epoch 182/300\n",
            "14/14 - 163s - 12s/step - accuracy: 0.7565 - loss: 0.5537 - val_accuracy: 0.7692 - val_loss: 0.5683\n",
            "Epoch 183/300\n",
            "14/14 - 187s - 13s/step - accuracy: 0.8014 - loss: 0.5233 - val_accuracy: 0.7802 - val_loss: 0.5639\n",
            "Epoch 184/300\n",
            "14/14 - 147s - 11s/step - accuracy: 0.8180 - loss: 0.4952 - val_accuracy: 0.7857 - val_loss: 0.5523\n",
            "Epoch 185/300\n",
            "14/14 - 203s - 14s/step - accuracy: 0.7920 - loss: 0.5358 - val_accuracy: 0.7747 - val_loss: 0.5605\n",
            "Epoch 186/300\n",
            "14/14 - 145s - 10s/step - accuracy: 0.7896 - loss: 0.5541 - val_accuracy: 0.7527 - val_loss: 0.5843\n",
            "Epoch 187/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.7636 - loss: 0.5290 - val_accuracy: 0.7857 - val_loss: 0.5658\n",
            "Epoch 188/300\n",
            "14/14 - 146s - 10s/step - accuracy: 0.7943 - loss: 0.5198 - val_accuracy: 0.7802 - val_loss: 0.5619\n",
            "Epoch 189/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.8061 - loss: 0.5020 - val_accuracy: 0.7637 - val_loss: 0.5800\n",
            "Epoch 190/300\n",
            "14/14 - 186s - 13s/step - accuracy: 0.7967 - loss: 0.4957 - val_accuracy: 0.7967 - val_loss: 0.5548\n",
            "Epoch 191/300\n",
            "14/14 - 186s - 13s/step - accuracy: 0.7896 - loss: 0.5350 - val_accuracy: 0.7967 - val_loss: 0.5472\n",
            "Epoch 192/300\n",
            "14/14 - 187s - 13s/step - accuracy: 0.7683 - loss: 0.5244 - val_accuracy: 0.7857 - val_loss: 0.5553\n",
            "Epoch 193/300\n",
            "14/14 - 202s - 14s/step - accuracy: 0.8061 - loss: 0.5158 - val_accuracy: 0.7418 - val_loss: 0.5749\n",
            "Epoch 194/300\n",
            "14/14 - 150s - 11s/step - accuracy: 0.7849 - loss: 0.5139 - val_accuracy: 0.7802 - val_loss: 0.5666\n",
            "Epoch 195/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.7730 - loss: 0.5390 - val_accuracy: 0.7967 - val_loss: 0.5520\n",
            "Epoch 196/300\n",
            "14/14 - 184s - 13s/step - accuracy: 0.8085 - loss: 0.5101 - val_accuracy: 0.7802 - val_loss: 0.5647\n",
            "Epoch 197/300\n",
            "14/14 - 167s - 12s/step - accuracy: 0.7849 - loss: 0.5089 - val_accuracy: 0.7912 - val_loss: 0.5594\n",
            "Epoch 198/300\n",
            "14/14 - 149s - 11s/step - accuracy: 0.7801 - loss: 0.5415 - val_accuracy: 0.8022 - val_loss: 0.5695\n",
            "Epoch 199/300\n",
            "14/14 - 144s - 10s/step - accuracy: 0.8038 - loss: 0.5097 - val_accuracy: 0.7912 - val_loss: 0.5627\n",
            "Epoch 200/300\n",
            "14/14 - 149s - 11s/step - accuracy: 0.7801 - loss: 0.5257 - val_accuracy: 0.7253 - val_loss: 0.6532\n",
            "Epoch 201/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.7801 - loss: 0.5701 - val_accuracy: 0.7637 - val_loss: 0.6183\n",
            "Epoch 202/300\n",
            "14/14 - 150s - 11s/step - accuracy: 0.7896 - loss: 0.5015 - val_accuracy: 0.7582 - val_loss: 0.5732\n",
            "Epoch 203/300\n",
            "14/14 - 150s - 11s/step - accuracy: 0.7872 - loss: 0.5090 - val_accuracy: 0.7527 - val_loss: 0.5928\n",
            "Epoch 204/300\n",
            "14/14 - 184s - 13s/step - accuracy: 0.8061 - loss: 0.5224 - val_accuracy: 0.7637 - val_loss: 0.5971\n",
            "Epoch 205/300\n",
            "14/14 - 167s - 12s/step - accuracy: 0.8085 - loss: 0.5217 - val_accuracy: 0.7802 - val_loss: 0.5633\n",
            "Epoch 206/300\n",
            "14/14 - 201s - 14s/step - accuracy: 0.8061 - loss: 0.4883 - val_accuracy: 0.7802 - val_loss: 0.5830\n",
            "Epoch 207/300\n",
            "14/14 - 149s - 11s/step - accuracy: 0.7683 - loss: 0.5564 - val_accuracy: 0.7582 - val_loss: 0.5760\n",
            "Epoch 208/300\n",
            "14/14 - 185s - 13s/step - accuracy: 0.7991 - loss: 0.5017 - val_accuracy: 0.7473 - val_loss: 0.5922\n",
            "Epoch 209/300\n",
            "14/14 - 146s - 10s/step - accuracy: 0.8061 - loss: 0.5074 - val_accuracy: 0.7692 - val_loss: 0.5743\n",
            "Epoch 210/300\n",
            "14/14 - 146s - 10s/step - accuracy: 0.8109 - loss: 0.4938 - val_accuracy: 0.7857 - val_loss: 0.5609\n",
            "Epoch 211/300\n",
            "14/14 - 149s - 11s/step - accuracy: 0.7967 - loss: 0.4898 - val_accuracy: 0.7692 - val_loss: 0.5798\n",
            "Epoch 212/300\n",
            "14/14 - 147s - 10s/step - accuracy: 0.8298 - loss: 0.4748 - val_accuracy: 0.7857 - val_loss: 0.5637\n",
            "Epoch 213/300\n",
            "14/14 - 242s - 17s/step - accuracy: 0.8109 - loss: 0.4937 - val_accuracy: 0.7912 - val_loss: 0.5732\n",
            "Epoch 214/300\n",
            "14/14 - 145s - 10s/step - accuracy: 0.7991 - loss: 0.4998 - val_accuracy: 0.8132 - val_loss: 0.5494\n",
            "Epoch 215/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.7825 - loss: 0.4976 - val_accuracy: 0.8077 - val_loss: 0.5383\n",
            "Epoch 216/300\n",
            "14/14 - 149s - 11s/step - accuracy: 0.8203 - loss: 0.4954 - val_accuracy: 0.8022 - val_loss: 0.5528\n",
            "Epoch 217/300\n",
            "14/14 - 149s - 11s/step - accuracy: 0.7683 - loss: 0.5450 - val_accuracy: 0.7637 - val_loss: 0.5614\n",
            "Epoch 218/300\n",
            "14/14 - 149s - 11s/step - accuracy: 0.7872 - loss: 0.5284 - val_accuracy: 0.7857 - val_loss: 0.5694\n",
            "Epoch 219/300\n",
            "14/14 - 184s - 13s/step - accuracy: 0.7849 - loss: 0.5400 - val_accuracy: 0.7912 - val_loss: 0.5398\n",
            "Epoch 220/300\n",
            "14/14 - 166s - 12s/step - accuracy: 0.7825 - loss: 0.5314 - val_accuracy: 0.7692 - val_loss: 0.5551\n",
            "Epoch 221/300\n",
            "14/14 - 185s - 13s/step - accuracy: 0.8298 - loss: 0.4579 - val_accuracy: 0.7967 - val_loss: 0.5376\n",
            "Epoch 222/300\n",
            "14/14 - 185s - 13s/step - accuracy: 0.7612 - loss: 0.5272 - val_accuracy: 0.7692 - val_loss: 0.5629\n",
            "Epoch 223/300\n",
            "14/14 - 184s - 13s/step - accuracy: 0.7920 - loss: 0.4805 - val_accuracy: 0.7527 - val_loss: 0.6021\n",
            "Epoch 224/300\n",
            "14/14 - 184s - 13s/step - accuracy: 0.7778 - loss: 0.5178 - val_accuracy: 0.7637 - val_loss: 0.5543\n",
            "Epoch 225/300\n",
            "14/14 - 186s - 13s/step - accuracy: 0.7896 - loss: 0.5609 - val_accuracy: 0.7692 - val_loss: 0.5810\n",
            "Epoch 226/300\n",
            "14/14 - 184s - 13s/step - accuracy: 0.8061 - loss: 0.4850 - val_accuracy: 0.7802 - val_loss: 0.5511\n",
            "Epoch 227/300\n",
            "14/14 - 183s - 13s/step - accuracy: 0.7991 - loss: 0.4664 - val_accuracy: 0.7692 - val_loss: 0.5604\n",
            "Epoch 228/300\n",
            "14/14 - 145s - 10s/step - accuracy: 0.8061 - loss: 0.4697 - val_accuracy: 0.7747 - val_loss: 0.5827\n",
            "Epoch 229/300\n",
            "14/14 - 146s - 10s/step - accuracy: 0.8061 - loss: 0.4902 - val_accuracy: 0.7637 - val_loss: 0.5853\n",
            "Epoch 230/300\n",
            "14/14 - 144s - 10s/step - accuracy: 0.8085 - loss: 0.4905 - val_accuracy: 0.7637 - val_loss: 0.5788\n",
            "Epoch 231/300\n",
            "14/14 - 243s - 17s/step - accuracy: 0.8085 - loss: 0.4774 - val_accuracy: 0.7747 - val_loss: 0.5734\n",
            "Epoch 232/300\n",
            "14/14 - 146s - 10s/step - accuracy: 0.8085 - loss: 0.4937 - val_accuracy: 0.7637 - val_loss: 0.5977\n",
            "Epoch 233/300\n",
            "14/14 - 147s - 10s/step - accuracy: 0.8038 - loss: 0.5121 - val_accuracy: 0.7527 - val_loss: 0.5938\n",
            "Epoch 234/300\n",
            "14/14 - 203s - 14s/step - accuracy: 0.7825 - loss: 0.5028 - val_accuracy: 0.7582 - val_loss: 0.5750\n",
            "Epoch 235/300\n",
            "14/14 - 186s - 13s/step - accuracy: 0.7943 - loss: 0.5010 - val_accuracy: 0.7582 - val_loss: 0.5736\n",
            "Epoch 236/300\n",
            "14/14 - 147s - 10s/step - accuracy: 0.8203 - loss: 0.4929 - val_accuracy: 0.7692 - val_loss: 0.5969\n",
            "Epoch 237/300\n",
            "14/14 - 145s - 10s/step - accuracy: 0.8180 - loss: 0.4562 - val_accuracy: 0.7802 - val_loss: 0.5704\n",
            "Epoch 238/300\n",
            "14/14 - 147s - 10s/step - accuracy: 0.8132 - loss: 0.4687 - val_accuracy: 0.7747 - val_loss: 0.5485\n",
            "Epoch 239/300\n",
            "14/14 - 147s - 11s/step - accuracy: 0.7967 - loss: 0.5023 - val_accuracy: 0.7747 - val_loss: 0.5423\n",
            "Epoch 240/300\n",
            "14/14 - 146s - 10s/step - accuracy: 0.8014 - loss: 0.4706 - val_accuracy: 0.7857 - val_loss: 0.5373\n",
            "Epoch 241/300\n",
            "14/14 - 184s - 13s/step - accuracy: 0.7872 - loss: 0.4979 - val_accuracy: 0.7582 - val_loss: 0.5530\n",
            "Epoch 242/300\n",
            "14/14 - 164s - 12s/step - accuracy: 0.7778 - loss: 0.5080 - val_accuracy: 0.7802 - val_loss: 0.5378\n",
            "Epoch 243/300\n",
            "14/14 - 184s - 13s/step - accuracy: 0.7967 - loss: 0.5079 - val_accuracy: 0.7802 - val_loss: 0.5383\n",
            "Epoch 244/300\n",
            "14/14 - 183s - 13s/step - accuracy: 0.8345 - loss: 0.4568 - val_accuracy: 0.7637 - val_loss: 0.5541\n",
            "Epoch 245/300\n",
            "14/14 - 165s - 12s/step - accuracy: 0.7683 - loss: 0.5233 - val_accuracy: 0.7637 - val_loss: 0.6027\n",
            "Epoch 246/300\n",
            "14/14 - 147s - 10s/step - accuracy: 0.8227 - loss: 0.4756 - val_accuracy: 0.7747 - val_loss: 0.5439\n",
            "Epoch 247/300\n",
            "14/14 - 143s - 10s/step - accuracy: 0.8203 - loss: 0.4867 - val_accuracy: 0.7802 - val_loss: 0.5633\n",
            "Epoch 248/300\n",
            "14/14 - 145s - 10s/step - accuracy: 0.7967 - loss: 0.5070 - val_accuracy: 0.7637 - val_loss: 0.5809\n",
            "Epoch 249/300\n",
            "14/14 - 146s - 10s/step - accuracy: 0.8132 - loss: 0.4740 - val_accuracy: 0.7692 - val_loss: 0.5477\n",
            "Epoch 250/300\n",
            "14/14 - 146s - 10s/step - accuracy: 0.8203 - loss: 0.5194 - val_accuracy: 0.8022 - val_loss: 0.5253\n",
            "Epoch 251/300\n",
            "14/14 - 145s - 10s/step - accuracy: 0.8180 - loss: 0.4596 - val_accuracy: 0.7912 - val_loss: 0.5424\n",
            "Epoch 252/300\n",
            "14/14 - 146s - 10s/step - accuracy: 0.8085 - loss: 0.4864 - val_accuracy: 0.7747 - val_loss: 0.5467\n",
            "Epoch 253/300\n",
            "14/14 - 147s - 11s/step - accuracy: 0.7754 - loss: 0.5153 - val_accuracy: 0.7802 - val_loss: 0.5405\n",
            "Epoch 254/300\n",
            "14/14 - 145s - 10s/step - accuracy: 0.8109 - loss: 0.4743 - val_accuracy: 0.7747 - val_loss: 0.5496\n",
            "Epoch 255/300\n",
            "14/14 - 145s - 10s/step - accuracy: 0.8180 - loss: 0.4659 - val_accuracy: 0.7912 - val_loss: 0.5380\n",
            "Epoch 256/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.8038 - loss: 0.4511 - val_accuracy: 0.7912 - val_loss: 0.5597\n",
            "Epoch 257/300\n",
            "14/14 - 147s - 10s/step - accuracy: 0.8227 - loss: 0.4561 - val_accuracy: 0.7967 - val_loss: 0.5453\n",
            "Epoch 258/300\n",
            "14/14 - 202s - 14s/step - accuracy: 0.8345 - loss: 0.4721 - val_accuracy: 0.7692 - val_loss: 0.5522\n",
            "Epoch 259/300\n"
          ]
        }
      ],
      "source": [
        "split_ratio = 0.7\n",
        "split_percent = round(split_ratio * 100)\n",
        "\n",
        "for lr in [0.001]:\n",
        "    for epoch in [300]:\n",
        "        print(f\"\\n📦 Training model dengan split_ratio={split_percent}%, learning_rate={lr}, epochs={epoch}\")\n",
        "\n",
        "        model, history = train_model(\n",
        "            split_ratio=split_ratio,\n",
        "            lr=lr,\n",
        "            epochs=epoch\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vZ6PXm-smxKy",
      "metadata": {
        "id": "vZ6PXm-smxKy"
      },
      "source": [
        "### split ratio 0.7 Learning rate 0.0001\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YGK2cOX8nDxm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGK2cOX8nDxm",
        "outputId": "dc42dd72-e3e7-41a7-eb59-1d789fad9ef6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📦 Training model dengan split_ratio=70%, learning_rate=0.0001, epochs=50\n",
            "Found 423 images belonging to 3 classes.\n",
            "Found 182 images belonging to 3 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "14/14 - 78s - 6s/step - accuracy: 0.3262 - loss: 2.2561 - val_accuracy: 0.3297 - val_loss: 1.2654\n",
            "Epoch 2/50\n",
            "14/14 - 48s - 3s/step - accuracy: 0.3522 - loss: 1.9954 - val_accuracy: 0.3626 - val_loss: 1.1818\n",
            "Epoch 3/50\n",
            "14/14 - 40s - 3s/step - accuracy: 0.3688 - loss: 1.8762 - val_accuracy: 0.4066 - val_loss: 1.1348\n",
            "Epoch 4/50\n",
            "14/14 - 40s - 3s/step - accuracy: 0.3475 - loss: 1.7872 - val_accuracy: 0.4505 - val_loss: 1.1024\n",
            "Epoch 5/50\n",
            "14/14 - 40s - 3s/step - accuracy: 0.3830 - loss: 1.6268 - val_accuracy: 0.4560 - val_loss: 1.0798\n",
            "Epoch 6/50\n",
            "14/14 - 41s - 3s/step - accuracy: 0.3735 - loss: 1.4813 - val_accuracy: 0.4780 - val_loss: 1.0582\n",
            "Epoch 7/50\n",
            "14/14 - 39s - 3s/step - accuracy: 0.3617 - loss: 1.5977 - val_accuracy: 0.4780 - val_loss: 1.0407\n",
            "Epoch 8/50\n",
            "14/14 - 39s - 3s/step - accuracy: 0.4208 - loss: 1.4279 - val_accuracy: 0.4780 - val_loss: 1.0330\n",
            "Epoch 9/50\n",
            "14/14 - 39s - 3s/step - accuracy: 0.3901 - loss: 1.4270 - val_accuracy: 0.4945 - val_loss: 1.0103\n",
            "Epoch 10/50\n",
            "14/14 - 47s - 3s/step - accuracy: 0.4326 - loss: 1.3321 - val_accuracy: 0.4835 - val_loss: 0.9988\n",
            "Epoch 11/50\n",
            "14/14 - 73s - 5s/step - accuracy: 0.4208 - loss: 1.4008 - val_accuracy: 0.5110 - val_loss: 0.9907\n",
            "Epoch 12/50\n",
            "14/14 - 39s - 3s/step - accuracy: 0.4444 - loss: 1.3255 - val_accuracy: 0.5000 - val_loss: 0.9879\n",
            "Epoch 13/50\n",
            "14/14 - 40s - 3s/step - accuracy: 0.4255 - loss: 1.3395 - val_accuracy: 0.5055 - val_loss: 0.9887\n",
            "Epoch 14/50\n",
            "14/14 - 40s - 3s/step - accuracy: 0.3853 - loss: 1.3306 - val_accuracy: 0.4945 - val_loss: 0.9790\n",
            "Epoch 15/50\n",
            "14/14 - 39s - 3s/step - accuracy: 0.4255 - loss: 1.2875 - val_accuracy: 0.5220 - val_loss: 0.9741\n",
            "Epoch 16/50\n",
            "14/14 - 39s - 3s/step - accuracy: 0.4539 - loss: 1.2244 - val_accuracy: 0.5220 - val_loss: 0.9694\n",
            "Epoch 17/50\n",
            "14/14 - 48s - 3s/step - accuracy: 0.4681 - loss: 1.1930 - val_accuracy: 0.5165 - val_loss: 0.9650\n",
            "Epoch 18/50\n",
            "14/14 - 41s - 3s/step - accuracy: 0.4563 - loss: 1.1782 - val_accuracy: 0.5055 - val_loss: 0.9631\n",
            "Epoch 19/50\n",
            "14/14 - 39s - 3s/step - accuracy: 0.4255 - loss: 1.2639 - val_accuracy: 0.5165 - val_loss: 0.9590\n",
            "Epoch 20/50\n",
            "14/14 - 40s - 3s/step - accuracy: 0.4255 - loss: 1.1832 - val_accuracy: 0.5330 - val_loss: 0.9524\n",
            "Epoch 21/50\n",
            "14/14 - 39s - 3s/step - accuracy: 0.4870 - loss: 1.1155 - val_accuracy: 0.5440 - val_loss: 0.9484\n",
            "Epoch 22/50\n",
            "14/14 - 47s - 3s/step - accuracy: 0.4326 - loss: 1.2320 - val_accuracy: 0.5495 - val_loss: 0.9480\n",
            "Epoch 23/50\n",
            "14/14 - 38s - 3s/step - accuracy: 0.5296 - loss: 1.1206 - val_accuracy: 0.5440 - val_loss: 0.9472\n",
            "Epoch 24/50\n",
            "14/14 - 39s - 3s/step - accuracy: 0.4610 - loss: 1.1110 - val_accuracy: 0.5440 - val_loss: 0.9463\n",
            "Epoch 25/50\n",
            "14/14 - 39s - 3s/step - accuracy: 0.4917 - loss: 1.0800 - val_accuracy: 0.5495 - val_loss: 0.9464\n",
            "Epoch 26/50\n",
            "14/14 - 41s - 3s/step - accuracy: 0.4752 - loss: 1.1007 - val_accuracy: 0.5495 - val_loss: 0.9422\n",
            "Epoch 27/50\n",
            "14/14 - 38s - 3s/step - accuracy: 0.4775 - loss: 1.1286 - val_accuracy: 0.5549 - val_loss: 0.9389\n",
            "Epoch 28/50\n",
            "14/14 - 39s - 3s/step - accuracy: 0.4988 - loss: 1.0877 - val_accuracy: 0.5714 - val_loss: 0.9341\n",
            "Epoch 29/50\n",
            "14/14 - 39s - 3s/step - accuracy: 0.4704 - loss: 1.1201 - val_accuracy: 0.5714 - val_loss: 0.9303\n",
            "Epoch 30/50\n",
            "14/14 - 39s - 3s/step - accuracy: 0.4988 - loss: 1.0998 - val_accuracy: 0.5824 - val_loss: 0.9278\n",
            "Epoch 31/50\n",
            "14/14 - 40s - 3s/step - accuracy: 0.4870 - loss: 1.0938 - val_accuracy: 0.5934 - val_loss: 0.9265\n",
            "Epoch 32/50\n",
            "14/14 - 40s - 3s/step - accuracy: 0.5154 - loss: 1.0573 - val_accuracy: 0.5934 - val_loss: 0.9252\n",
            "Epoch 33/50\n",
            "14/14 - 39s - 3s/step - accuracy: 0.4823 - loss: 1.1052 - val_accuracy: 0.6044 - val_loss: 0.9232\n",
            "Epoch 34/50\n",
            "14/14 - 39s - 3s/step - accuracy: 0.5461 - loss: 1.0478 - val_accuracy: 0.5934 - val_loss: 0.9234\n",
            "Epoch 35/50\n",
            "14/14 - 49s - 4s/step - accuracy: 0.5154 - loss: 1.0116 - val_accuracy: 0.5989 - val_loss: 0.9227\n",
            "Epoch 36/50\n",
            "14/14 - 39s - 3s/step - accuracy: 0.5059 - loss: 1.0724 - val_accuracy: 0.5934 - val_loss: 0.9219\n",
            "Epoch 37/50\n",
            "14/14 - 39s - 3s/step - accuracy: 0.5012 - loss: 1.0263 - val_accuracy: 0.5934 - val_loss: 0.9194\n",
            "Epoch 38/50\n",
            "14/14 - 39s - 3s/step - accuracy: 0.5059 - loss: 1.0178 - val_accuracy: 0.6154 - val_loss: 0.9180\n",
            "Epoch 39/50\n",
            "14/14 - 39s - 3s/step - accuracy: 0.5012 - loss: 1.0476 - val_accuracy: 0.6044 - val_loss: 0.9170\n",
            "Epoch 40/50\n",
            "14/14 - 39s - 3s/step - accuracy: 0.4988 - loss: 1.0550 - val_accuracy: 0.6044 - val_loss: 0.9150\n",
            "Epoch 41/50\n",
            "14/14 - 40s - 3s/step - accuracy: 0.4894 - loss: 1.0312 - val_accuracy: 0.6154 - val_loss: 0.9153\n",
            "Epoch 42/50\n",
            "14/14 - 39s - 3s/step - accuracy: 0.5083 - loss: 1.0526 - val_accuracy: 0.6154 - val_loss: 0.9133\n",
            "Epoch 43/50\n",
            "14/14 - 39s - 3s/step - accuracy: 0.4988 - loss: 1.0173 - val_accuracy: 0.6264 - val_loss: 0.9136\n",
            "Epoch 44/50\n",
            "14/14 - 39s - 3s/step - accuracy: 0.5792 - loss: 0.9451 - val_accuracy: 0.6209 - val_loss: 0.9130\n",
            "Epoch 45/50\n",
            "14/14 - 40s - 3s/step - accuracy: 0.5603 - loss: 0.9904 - val_accuracy: 0.6209 - val_loss: 0.9129\n",
            "Epoch 46/50\n",
            "14/14 - 39s - 3s/step - accuracy: 0.5059 - loss: 1.0334 - val_accuracy: 0.6154 - val_loss: 0.9116\n",
            "Epoch 47/50\n",
            "14/14 - 39s - 3s/step - accuracy: 0.5366 - loss: 0.9890 - val_accuracy: 0.6209 - val_loss: 0.9116\n",
            "Epoch 48/50\n",
            "14/14 - 39s - 3s/step - accuracy: 0.5177 - loss: 1.0447 - val_accuracy: 0.6264 - val_loss: 0.9101\n",
            "Epoch 49/50\n",
            "14/14 - 41s - 3s/step - accuracy: 0.5083 - loss: 1.0597 - val_accuracy: 0.6209 - val_loss: 0.9079\n",
            "Epoch 50/50\n",
            "14/14 - 39s - 3s/step - accuracy: 0.5485 - loss: 1.0463 - val_accuracy: 0.6209 - val_loss: 0.9055\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model berhasil disimpan: model_split70_lr0.0001_ep50_l20.0001.h5\n"
          ]
        }
      ],
      "source": [
        "split_ratio = 0.7\n",
        "split_percent = round(split_ratio * 100)\n",
        "\n",
        "for lr in [0.0001]:\n",
        "    for epoch in [50]:\n",
        "        print(f\"\\n📦 Training model dengan split_ratio={split_percent}%, learning_rate={lr}, epochs={epoch}\")\n",
        "\n",
        "        model, history = train_model(\n",
        "            split_ratio=split_ratio,\n",
        "            lr=lr,\n",
        "            epochs=epoch\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YUit7Wuk3bj3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUit7Wuk3bj3",
        "outputId": "550303dc-6452-46df-8ec7-3be91af1cd01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📦 Training model dengan split_ratio=70%, learning_rate=0.0001, epochs=100\n",
            "Found 423 images belonging to 3 classes.\n",
            "Found 182 images belonging to 3 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "14/14 - 76s - 5s/step - accuracy: 0.2861 - loss: 2.0562 - val_accuracy: 0.3791 - val_loss: 1.3503\n",
            "Epoch 2/100\n",
            "14/14 - 40s - 3s/step - accuracy: 0.3617 - loss: 1.8019 - val_accuracy: 0.3352 - val_loss: 1.2022\n",
            "Epoch 3/100\n",
            "14/14 - 39s - 3s/step - accuracy: 0.3475 - loss: 1.6957 - val_accuracy: 0.3846 - val_loss: 1.1584\n",
            "Epoch 4/100\n",
            "14/14 - 39s - 3s/step - accuracy: 0.3215 - loss: 1.6964 - val_accuracy: 0.3571 - val_loss: 1.1355\n",
            "Epoch 5/100\n",
            "14/14 - 37s - 3s/step - accuracy: 0.3499 - loss: 1.5530 - val_accuracy: 0.3846 - val_loss: 1.1087\n",
            "Epoch 6/100\n",
            "14/14 - 42s - 3s/step - accuracy: 0.3972 - loss: 1.5224 - val_accuracy: 0.4286 - val_loss: 1.0905\n",
            "Epoch 7/100\n",
            "14/14 - 40s - 3s/step - accuracy: 0.3924 - loss: 1.4114 - val_accuracy: 0.4066 - val_loss: 1.0793\n",
            "Epoch 8/100\n",
            "14/14 - 39s - 3s/step - accuracy: 0.3924 - loss: 1.4300 - val_accuracy: 0.4396 - val_loss: 1.0707\n",
            "Epoch 9/100\n",
            "14/14 - 47s - 3s/step - accuracy: 0.4492 - loss: 1.3044 - val_accuracy: 0.4396 - val_loss: 1.0630\n",
            "Epoch 10/100\n",
            "14/14 - 38s - 3s/step - accuracy: 0.4019 - loss: 1.3559 - val_accuracy: 0.4341 - val_loss: 1.0578\n",
            "Epoch 11/100\n",
            "14/14 - 40s - 3s/step - accuracy: 0.4090 - loss: 1.3060 - val_accuracy: 0.4396 - val_loss: 1.0508\n",
            "Epoch 12/100\n",
            "14/14 - 39s - 3s/step - accuracy: 0.3995 - loss: 1.3252 - val_accuracy: 0.4835 - val_loss: 1.0419\n",
            "Epoch 13/100\n",
            "14/14 - 39s - 3s/step - accuracy: 0.3948 - loss: 1.3646 - val_accuracy: 0.4780 - val_loss: 1.0360\n",
            "Epoch 14/100\n",
            "14/14 - 38s - 3s/step - accuracy: 0.4232 - loss: 1.2391 - val_accuracy: 0.4615 - val_loss: 1.0289\n",
            "Epoch 15/100\n",
            "14/14 - 41s - 3s/step - accuracy: 0.4350 - loss: 1.1954 - val_accuracy: 0.4615 - val_loss: 1.0253\n",
            "Epoch 16/100\n",
            "14/14 - 39s - 3s/step - accuracy: 0.4279 - loss: 1.2807 - val_accuracy: 0.4670 - val_loss: 1.0199\n",
            "Epoch 17/100\n",
            "14/14 - 47s - 3s/step - accuracy: 0.4468 - loss: 1.2020 - val_accuracy: 0.4780 - val_loss: 1.0154\n",
            "Epoch 18/100\n",
            "14/14 - 39s - 3s/step - accuracy: 0.4232 - loss: 1.2173 - val_accuracy: 0.4835 - val_loss: 1.0117\n",
            "Epoch 19/100\n",
            "14/14 - 52s - 4s/step - accuracy: 0.4374 - loss: 1.2242 - val_accuracy: 0.4670 - val_loss: 1.0102\n",
            "Epoch 20/100\n",
            "14/14 - 39s - 3s/step - accuracy: 0.4539 - loss: 1.2011 - val_accuracy: 0.4835 - val_loss: 1.0066\n",
            "Epoch 21/100\n",
            "14/14 - 38s - 3s/step - accuracy: 0.4586 - loss: 1.1787 - val_accuracy: 0.5000 - val_loss: 1.0054\n",
            "Epoch 22/100\n",
            "14/14 - 39s - 3s/step - accuracy: 0.4681 - loss: 1.1069 - val_accuracy: 0.5110 - val_loss: 1.0009\n",
            "Epoch 23/100\n",
            "14/14 - 40s - 3s/step - accuracy: 0.4397 - loss: 1.1330 - val_accuracy: 0.5165 - val_loss: 0.9986\n",
            "Epoch 24/100\n",
            "14/14 - 38s - 3s/step - accuracy: 0.4444 - loss: 1.1394 - val_accuracy: 0.5110 - val_loss: 0.9958\n",
            "Epoch 25/100\n",
            "14/14 - 39s - 3s/step - accuracy: 0.4634 - loss: 1.1560 - val_accuracy: 0.5220 - val_loss: 0.9943\n",
            "Epoch 26/100\n",
            "14/14 - 38s - 3s/step - accuracy: 0.4799 - loss: 1.1137 - val_accuracy: 0.5275 - val_loss: 0.9920\n",
            "Epoch 27/100\n",
            "14/14 - 40s - 3s/step - accuracy: 0.4681 - loss: 1.1463 - val_accuracy: 0.5330 - val_loss: 0.9896\n",
            "Epoch 28/100\n",
            "14/14 - 38s - 3s/step - accuracy: 0.4728 - loss: 1.1067 - val_accuracy: 0.5220 - val_loss: 0.9860\n",
            "Epoch 29/100\n",
            "14/14 - 40s - 3s/step - accuracy: 0.4610 - loss: 1.1042 - val_accuracy: 0.5220 - val_loss: 0.9860\n",
            "Epoch 30/100\n",
            "14/14 - 39s - 3s/step - accuracy: 0.4941 - loss: 1.0544 - val_accuracy: 0.5275 - val_loss: 0.9850\n",
            "Epoch 31/100\n",
            "14/14 - 38s - 3s/step - accuracy: 0.4279 - loss: 1.1196 - val_accuracy: 0.5275 - val_loss: 0.9837\n",
            "Epoch 32/100\n",
            "14/14 - 43s - 3s/step - accuracy: 0.4374 - loss: 1.1434 - val_accuracy: 0.5330 - val_loss: 0.9815\n",
            "Epoch 33/100\n",
            "14/14 - 38s - 3s/step - accuracy: 0.4444 - loss: 1.0824 - val_accuracy: 0.5330 - val_loss: 0.9792\n",
            "Epoch 34/100\n",
            "14/14 - 39s - 3s/step - accuracy: 0.4965 - loss: 1.0677 - val_accuracy: 0.5330 - val_loss: 0.9764\n",
            "Epoch 35/100\n",
            "14/14 - 49s - 4s/step - accuracy: 0.4586 - loss: 1.0649 - val_accuracy: 0.5385 - val_loss: 0.9741\n",
            "Epoch 36/100\n",
            "14/14 - 39s - 3s/step - accuracy: 0.4681 - loss: 1.1079 - val_accuracy: 0.5440 - val_loss: 0.9727\n",
            "Epoch 37/100\n",
            "14/14 - 38s - 3s/step - accuracy: 0.4823 - loss: 1.0621 - val_accuracy: 0.5495 - val_loss: 0.9708\n",
            "Epoch 38/100\n",
            "14/14 - 40s - 3s/step - accuracy: 0.4775 - loss: 1.0675 - val_accuracy: 0.5495 - val_loss: 0.9687\n",
            "Epoch 39/100\n",
            "14/14 - 47s - 3s/step - accuracy: 0.5035 - loss: 1.0389 - val_accuracy: 0.5440 - val_loss: 0.9686\n",
            "Epoch 40/100\n",
            "14/14 - 37s - 3s/step - accuracy: 0.4846 - loss: 1.0729 - val_accuracy: 0.5549 - val_loss: 0.9681\n",
            "Epoch 41/100\n",
            "14/14 - 51s - 4s/step - accuracy: 0.4634 - loss: 1.1037 - val_accuracy: 0.5769 - val_loss: 0.9696\n",
            "Epoch 42/100\n",
            "14/14 - 39s - 3s/step - accuracy: 0.4965 - loss: 1.0641 - val_accuracy: 0.5769 - val_loss: 0.9702\n",
            "Epoch 43/100\n",
            "14/14 - 38s - 3s/step - accuracy: 0.5083 - loss: 0.9832 - val_accuracy: 0.5604 - val_loss: 0.9685\n",
            "Epoch 44/100\n",
            "14/14 - 39s - 3s/step - accuracy: 0.4894 - loss: 1.0297 - val_accuracy: 0.5604 - val_loss: 0.9673\n",
            "Epoch 45/100\n",
            "14/14 - 37s - 3s/step - accuracy: 0.5035 - loss: 1.0451 - val_accuracy: 0.5659 - val_loss: 0.9649\n",
            "Epoch 46/100\n",
            "14/14 - 38s - 3s/step - accuracy: 0.4634 - loss: 1.0773 - val_accuracy: 0.5604 - val_loss: 0.9631\n",
            "Epoch 47/100\n",
            "14/14 - 39s - 3s/step - accuracy: 0.5154 - loss: 0.9965 - val_accuracy: 0.5714 - val_loss: 0.9614\n",
            "Epoch 48/100\n",
            "14/14 - 38s - 3s/step - accuracy: 0.5437 - loss: 0.9918 - val_accuracy: 0.5549 - val_loss: 0.9587\n",
            "Epoch 49/100\n",
            "14/14 - 38s - 3s/step - accuracy: 0.5177 - loss: 1.0532 - val_accuracy: 0.5604 - val_loss: 0.9567\n",
            "Epoch 50/100\n",
            "14/14 - 50s - 4s/step - accuracy: 0.5035 - loss: 1.0134 - val_accuracy: 0.5659 - val_loss: 0.9550\n",
            "Epoch 51/100\n",
            "14/14 - 38s - 3s/step - accuracy: 0.5414 - loss: 1.0142 - val_accuracy: 0.5714 - val_loss: 0.9535\n",
            "Epoch 52/100\n",
            "14/14 - 39s - 3s/step - accuracy: 0.4894 - loss: 1.0108 - val_accuracy: 0.5659 - val_loss: 0.9524\n",
            "Epoch 53/100\n",
            "14/14 - 39s - 3s/step - accuracy: 0.5059 - loss: 1.0303 - val_accuracy: 0.5769 - val_loss: 0.9504\n",
            "Epoch 54/100\n",
            "14/14 - 39s - 3s/step - accuracy: 0.5296 - loss: 1.0376 - val_accuracy: 0.5824 - val_loss: 0.9509\n",
            "Epoch 55/100\n",
            "14/14 - 39s - 3s/step - accuracy: 0.5319 - loss: 0.9840 - val_accuracy: 0.5879 - val_loss: 0.9499\n",
            "Epoch 56/100\n",
            "14/14 - 40s - 3s/step - accuracy: 0.5485 - loss: 0.9676 - val_accuracy: 0.5934 - val_loss: 0.9481\n",
            "Epoch 57/100\n",
            "14/14 - 39s - 3s/step - accuracy: 0.5130 - loss: 0.9906 - val_accuracy: 0.5989 - val_loss: 0.9461\n",
            "Epoch 58/100\n",
            "14/14 - 39s - 3s/step - accuracy: 0.4965 - loss: 1.0429 - val_accuracy: 0.6044 - val_loss: 0.9445\n",
            "Epoch 59/100\n",
            "14/14 - 39s - 3s/step - accuracy: 0.5414 - loss: 0.9846 - val_accuracy: 0.6044 - val_loss: 0.9439\n",
            "Epoch 60/100\n",
            "14/14 - 48s - 3s/step - accuracy: 0.5248 - loss: 0.9745 - val_accuracy: 0.6154 - val_loss: 0.9424\n",
            "Epoch 61/100\n",
            "14/14 - 38s - 3s/step - accuracy: 0.5556 - loss: 0.9860 - val_accuracy: 0.6099 - val_loss: 0.9413\n",
            "Epoch 62/100\n",
            "14/14 - 47s - 3s/step - accuracy: 0.5626 - loss: 0.9583 - val_accuracy: 0.6099 - val_loss: 0.9400\n",
            "Epoch 63/100\n",
            "14/14 - 39s - 3s/step - accuracy: 0.5035 - loss: 1.0347 - val_accuracy: 0.6209 - val_loss: 0.9388\n",
            "Epoch 64/100\n",
            "14/14 - 39s - 3s/step - accuracy: 0.5556 - loss: 0.9753 - val_accuracy: 0.6209 - val_loss: 0.9372\n",
            "Epoch 65/100\n",
            "14/14 - 38s - 3s/step - accuracy: 0.5697 - loss: 0.9545 - val_accuracy: 0.6209 - val_loss: 0.9354\n",
            "Epoch 66/100\n",
            "14/14 - 40s - 3s/step - accuracy: 0.5603 - loss: 0.9177 - val_accuracy: 0.6044 - val_loss: 0.9342\n",
            "Epoch 67/100\n",
            "14/14 - 47s - 3s/step - accuracy: 0.5130 - loss: 0.9901 - val_accuracy: 0.6099 - val_loss: 0.9339\n",
            "Epoch 68/100\n",
            "14/14 - 40s - 3s/step - accuracy: 0.5934 - loss: 0.9460 - val_accuracy: 0.5989 - val_loss: 0.9327\n",
            "Epoch 69/100\n",
            "14/14 - 39s - 3s/step - accuracy: 0.5272 - loss: 0.9882 - val_accuracy: 0.6209 - val_loss: 0.9313\n",
            "Epoch 70/100\n",
            "14/14 - 38s - 3s/step - accuracy: 0.5532 - loss: 0.9877 - val_accuracy: 0.6264 - val_loss: 0.9308\n",
            "Epoch 71/100\n",
            "14/14 - 38s - 3s/step - accuracy: 0.5603 - loss: 0.9563 - val_accuracy: 0.6154 - val_loss: 0.9289\n",
            "Epoch 72/100\n",
            "14/14 - 38s - 3s/step - accuracy: 0.5650 - loss: 0.9797 - val_accuracy: 0.6209 - val_loss: 0.9275\n",
            "Epoch 73/100\n",
            "14/14 - 38s - 3s/step - accuracy: 0.5390 - loss: 0.9842 - val_accuracy: 0.6209 - val_loss: 0.9261\n",
            "Epoch 74/100\n",
            "14/14 - 48s - 3s/step - accuracy: 0.5201 - loss: 1.0044 - val_accuracy: 0.6154 - val_loss: 0.9251\n",
            "Epoch 75/100\n",
            "14/14 - 47s - 3s/step - accuracy: 0.5390 - loss: 0.9792 - val_accuracy: 0.6319 - val_loss: 0.9237\n",
            "Epoch 76/100\n",
            "14/14 - 39s - 3s/step - accuracy: 0.5816 - loss: 0.9367 - val_accuracy: 0.6209 - val_loss: 0.9224\n",
            "Epoch 77/100\n",
            "14/14 - 38s - 3s/step - accuracy: 0.5556 - loss: 0.9320 - val_accuracy: 0.6264 - val_loss: 0.9205\n",
            "Epoch 78/100\n",
            "14/14 - 38s - 3s/step - accuracy: 0.5225 - loss: 0.9971 - val_accuracy: 0.6044 - val_loss: 0.9193\n",
            "Epoch 79/100\n",
            "14/14 - 39s - 3s/step - accuracy: 0.5437 - loss: 0.9752 - val_accuracy: 0.6154 - val_loss: 0.9182\n",
            "Epoch 80/100\n",
            "14/14 - 39s - 3s/step - accuracy: 0.4965 - loss: 0.9897 - val_accuracy: 0.6209 - val_loss: 0.9173\n",
            "Epoch 81/100\n",
            "14/14 - 37s - 3s/step - accuracy: 0.5319 - loss: 0.9876 - val_accuracy: 0.6264 - val_loss: 0.9163\n",
            "Epoch 82/100\n",
            "14/14 - 40s - 3s/step - accuracy: 0.5603 - loss: 0.9196 - val_accuracy: 0.6374 - val_loss: 0.9149\n",
            "Epoch 83/100\n",
            "14/14 - 39s - 3s/step - accuracy: 0.5626 - loss: 0.9479 - val_accuracy: 0.6374 - val_loss: 0.9130\n",
            "Epoch 84/100\n",
            "14/14 - 39s - 3s/step - accuracy: 0.5792 - loss: 0.9355 - val_accuracy: 0.6429 - val_loss: 0.9105\n",
            "Epoch 85/100\n",
            "14/14 - 39s - 3s/step - accuracy: 0.5461 - loss: 0.9793 - val_accuracy: 0.6374 - val_loss: 0.9097\n",
            "Epoch 86/100\n",
            "14/14 - 38s - 3s/step - accuracy: 0.5556 - loss: 0.9222 - val_accuracy: 0.6264 - val_loss: 0.9087\n",
            "Epoch 87/100\n",
            "14/14 - 39s - 3s/step - accuracy: 0.5437 - loss: 0.9773 - val_accuracy: 0.6209 - val_loss: 0.9073\n",
            "Epoch 88/100\n",
            "14/14 - 38s - 3s/step - accuracy: 0.5768 - loss: 0.9423 - val_accuracy: 0.6209 - val_loss: 0.9070\n",
            "Epoch 89/100\n",
            "14/14 - 39s - 3s/step - accuracy: 0.5485 - loss: 0.9363 - val_accuracy: 0.6154 - val_loss: 0.9066\n",
            "Epoch 90/100\n",
            "14/14 - 40s - 3s/step - accuracy: 0.5485 - loss: 0.9318 - val_accuracy: 0.6099 - val_loss: 0.9052\n",
            "Epoch 91/100\n",
            "14/14 - 39s - 3s/step - accuracy: 0.5201 - loss: 0.9825 - val_accuracy: 0.6209 - val_loss: 0.9028\n",
            "Epoch 92/100\n",
            "14/14 - 40s - 3s/step - accuracy: 0.5579 - loss: 0.9604 - val_accuracy: 0.6264 - val_loss: 0.9009\n",
            "Epoch 93/100\n",
            "14/14 - 42s - 3s/step - accuracy: 0.5863 - loss: 0.8973 - val_accuracy: 0.6319 - val_loss: 0.8998\n",
            "Epoch 94/100\n",
            "14/14 - 39s - 3s/step - accuracy: 0.5650 - loss: 0.9266 - val_accuracy: 0.6264 - val_loss: 0.8983\n",
            "Epoch 95/100\n",
            "14/14 - 40s - 3s/step - accuracy: 0.5792 - loss: 0.9226 - val_accuracy: 0.6319 - val_loss: 0.8961\n",
            "Epoch 96/100\n",
            "14/14 - 38s - 3s/step - accuracy: 0.5556 - loss: 0.9767 - val_accuracy: 0.6319 - val_loss: 0.8955\n",
            "Epoch 97/100\n",
            "14/14 - 41s - 3s/step - accuracy: 0.5603 - loss: 0.9501 - val_accuracy: 0.6319 - val_loss: 0.8946\n",
            "Epoch 98/100\n",
            "14/14 - 39s - 3s/step - accuracy: 0.5626 - loss: 0.9342 - val_accuracy: 0.6374 - val_loss: 0.8933\n",
            "Epoch 99/100\n",
            "14/14 - 47s - 3s/step - accuracy: 0.5910 - loss: 0.9233 - val_accuracy: 0.6429 - val_loss: 0.8918\n",
            "Epoch 100/100\n",
            "14/14 - 38s - 3s/step - accuracy: 0.5650 - loss: 0.9637 - val_accuracy: 0.6484 - val_loss: 0.8897\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model berhasil disimpan: model_split70_lr0.0001_ep100_l20.0001.h5\n"
          ]
        }
      ],
      "source": [
        "split_ratio = 0.7\n",
        "split_percent = round(split_ratio * 100)\n",
        "\n",
        "for lr in [0.0001]:\n",
        "    for epoch in [100]:\n",
        "        print(f\"\\n📦 Training model dengan split_ratio={split_percent}%, learning_rate={lr}, epochs={epoch}\")\n",
        "\n",
        "        model, history = train_model(\n",
        "            split_ratio=split_ratio,\n",
        "            lr=lr,\n",
        "            epochs=epoch\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_64tQI79iW-v",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_64tQI79iW-v",
        "outputId": "76bf6a18-0b37-43a9-87e5-8760be5d33f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📦 Training model dengan split_ratio=70%, learning_rate=0.0001, epochs=200\n",
            "Found 423 images belonging to 3 classes.\n",
            "Found 182 images belonging to 3 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "14/14 - 171s - 12s/step - accuracy: 0.3404 - loss: 2.4378 - val_accuracy: 0.3516 - val_loss: 1.3224\n",
            "Epoch 2/200\n",
            "14/14 - 159s - 11s/step - accuracy: 0.3522 - loss: 1.8417 - val_accuracy: 0.3791 - val_loss: 1.1697\n",
            "Epoch 3/200\n",
            "14/14 - 153s - 11s/step - accuracy: 0.3735 - loss: 1.7831 - val_accuracy: 0.4231 - val_loss: 1.1117\n",
            "Epoch 4/200\n",
            "14/14 - 154s - 11s/step - accuracy: 0.3499 - loss: 1.6683 - val_accuracy: 0.4451 - val_loss: 1.0724\n",
            "Epoch 5/200\n",
            "14/14 - 156s - 11s/step - accuracy: 0.4184 - loss: 1.5324 - val_accuracy: 0.4780 - val_loss: 1.0425\n",
            "Epoch 6/200\n",
            "14/14 - 160s - 11s/step - accuracy: 0.3688 - loss: 1.5294 - val_accuracy: 0.5055 - val_loss: 1.0269\n",
            "Epoch 7/200\n",
            "14/14 - 152s - 11s/step - accuracy: 0.4255 - loss: 1.4647 - val_accuracy: 0.5110 - val_loss: 1.0220\n",
            "Epoch 8/200\n",
            "14/14 - 150s - 11s/step - accuracy: 0.4350 - loss: 1.3259 - val_accuracy: 0.5110 - val_loss: 1.0100\n",
            "Epoch 9/200\n",
            "14/14 - 150s - 11s/step - accuracy: 0.4303 - loss: 1.3666 - val_accuracy: 0.5275 - val_loss: 0.9929\n",
            "Epoch 10/200\n",
            "14/14 - 156s - 11s/step - accuracy: 0.4397 - loss: 1.3232 - val_accuracy: 0.5165 - val_loss: 0.9849\n",
            "Epoch 11/200\n",
            "14/14 - 151s - 11s/step - accuracy: 0.4634 - loss: 1.2532 - val_accuracy: 0.5220 - val_loss: 0.9805\n",
            "Epoch 12/200\n",
            "14/14 - 188s - 13s/step - accuracy: 0.4586 - loss: 1.2419 - val_accuracy: 0.5440 - val_loss: 0.9726\n",
            "Epoch 13/200\n",
            "14/14 - 151s - 11s/step - accuracy: 0.4634 - loss: 1.2059 - val_accuracy: 0.5549 - val_loss: 0.9667\n",
            "Epoch 14/200\n",
            "14/14 - 195s - 14s/step - accuracy: 0.4421 - loss: 1.2923 - val_accuracy: 0.5604 - val_loss: 0.9607\n",
            "Epoch 15/200\n",
            "14/14 - 158s - 11s/step - accuracy: 0.4728 - loss: 1.1697 - val_accuracy: 0.5769 - val_loss: 0.9560\n",
            "Epoch 16/200\n",
            "14/14 - 151s - 11s/step - accuracy: 0.4161 - loss: 1.2652 - val_accuracy: 0.5659 - val_loss: 0.9531\n",
            "Epoch 17/200\n",
            "14/14 - 150s - 11s/step - accuracy: 0.4681 - loss: 1.2050 - val_accuracy: 0.5824 - val_loss: 0.9482\n",
            "Epoch 18/200\n",
            "14/14 - 157s - 11s/step - accuracy: 0.4681 - loss: 1.2009 - val_accuracy: 0.5879 - val_loss: 0.9464\n",
            "Epoch 19/200\n",
            "14/14 - 151s - 11s/step - accuracy: 0.4870 - loss: 1.1823 - val_accuracy: 0.6154 - val_loss: 0.9431\n",
            "Epoch 20/200\n",
            "14/14 - 150s - 11s/step - accuracy: 0.4397 - loss: 1.2047 - val_accuracy: 0.5989 - val_loss: 0.9407\n",
            "Epoch 21/200\n",
            "14/14 - 150s - 11s/step - accuracy: 0.4444 - loss: 1.2173 - val_accuracy: 0.6099 - val_loss: 0.9388\n",
            "Epoch 22/200\n",
            "14/14 - 150s - 11s/step - accuracy: 0.4681 - loss: 1.1279 - val_accuracy: 0.6154 - val_loss: 0.9353\n",
            "Epoch 23/200\n",
            "14/14 - 149s - 11s/step - accuracy: 0.4657 - loss: 1.1627 - val_accuracy: 0.6099 - val_loss: 0.9339\n",
            "Epoch 24/200\n",
            "14/14 - 242s - 17s/step - accuracy: 0.4917 - loss: 1.1322 - val_accuracy: 0.6154 - val_loss: 0.9322\n",
            "Epoch 25/200\n",
            "14/14 - 152s - 11s/step - accuracy: 0.4350 - loss: 1.1879 - val_accuracy: 0.6099 - val_loss: 0.9309\n",
            "Epoch 26/200\n",
            "14/14 - 150s - 11s/step - accuracy: 0.5012 - loss: 1.1114 - val_accuracy: 0.6099 - val_loss: 0.9301\n",
            "Epoch 27/200\n",
            "14/14 - 188s - 13s/step - accuracy: 0.5130 - loss: 1.1192 - val_accuracy: 0.6154 - val_loss: 0.9283\n",
            "Epoch 28/200\n",
            "14/14 - 188s - 13s/step - accuracy: 0.5177 - loss: 1.0727 - val_accuracy: 0.6209 - val_loss: 0.9269\n",
            "Epoch 29/200\n",
            "14/14 - 148s - 11s/step - accuracy: 0.4988 - loss: 1.0823 - val_accuracy: 0.6209 - val_loss: 0.9279\n",
            "Epoch 30/200\n",
            "14/14 - 187s - 13s/step - accuracy: 0.4704 - loss: 1.1414 - val_accuracy: 0.6264 - val_loss: 0.9286\n",
            "Epoch 31/200\n",
            "14/14 - 188s - 13s/step - accuracy: 0.4681 - loss: 1.0728 - val_accuracy: 0.6154 - val_loss: 0.9281\n",
            "Epoch 32/200\n",
            "14/14 - 150s - 11s/step - accuracy: 0.5225 - loss: 0.9860 - val_accuracy: 0.6209 - val_loss: 0.9284\n",
            "Epoch 33/200\n",
            "14/14 - 150s - 11s/step - accuracy: 0.5177 - loss: 1.0064 - val_accuracy: 0.6044 - val_loss: 0.9289\n",
            "Epoch 34/200\n",
            "14/14 - 150s - 11s/step - accuracy: 0.5556 - loss: 1.0005 - val_accuracy: 0.6044 - val_loss: 0.9289\n",
            "Epoch 35/200\n",
            "14/14 - 151s - 11s/step - accuracy: 0.5035 - loss: 1.0930 - val_accuracy: 0.6099 - val_loss: 0.9286\n",
            "Epoch 36/200\n",
            "14/14 - 150s - 11s/step - accuracy: 0.5390 - loss: 1.0486 - val_accuracy: 0.6154 - val_loss: 0.9276\n",
            "Epoch 37/200\n",
            "14/14 - 185s - 13s/step - accuracy: 0.4610 - loss: 1.1213 - val_accuracy: 0.6044 - val_loss: 0.9270\n",
            "Epoch 38/200\n",
            "14/14 - 150s - 11s/step - accuracy: 0.5130 - loss: 1.0370 - val_accuracy: 0.6099 - val_loss: 0.9241\n",
            "Epoch 39/200\n",
            "14/14 - 200s - 14s/step - accuracy: 0.5414 - loss: 1.0322 - val_accuracy: 0.5989 - val_loss: 0.9217\n",
            "Epoch 40/200\n",
            "14/14 - 149s - 11s/step - accuracy: 0.5059 - loss: 1.0638 - val_accuracy: 0.5989 - val_loss: 0.9203\n",
            "Epoch 41/200\n",
            "14/14 - 150s - 11s/step - accuracy: 0.5035 - loss: 1.0320 - val_accuracy: 0.5989 - val_loss: 0.9208\n",
            "Epoch 42/200\n",
            "14/14 - 151s - 11s/step - accuracy: 0.4965 - loss: 1.0446 - val_accuracy: 0.5989 - val_loss: 0.9182\n",
            "Epoch 43/200\n",
            "14/14 - 186s - 13s/step - accuracy: 0.5296 - loss: 1.0309 - val_accuracy: 0.5934 - val_loss: 0.9166\n",
            "Epoch 44/200\n",
            "14/14 - 150s - 11s/step - accuracy: 0.5272 - loss: 1.0244 - val_accuracy: 0.5934 - val_loss: 0.9180\n",
            "Epoch 45/200\n",
            "14/14 - 202s - 14s/step - accuracy: 0.5508 - loss: 1.0158 - val_accuracy: 0.5934 - val_loss: 0.9181\n",
            "Epoch 46/200\n",
            "14/14 - 150s - 11s/step - accuracy: 0.5556 - loss: 0.9630 - val_accuracy: 0.5989 - val_loss: 0.9189\n",
            "Epoch 47/200\n",
            "14/14 - 240s - 17s/step - accuracy: 0.5390 - loss: 0.9589 - val_accuracy: 0.6099 - val_loss: 0.9178\n",
            "Epoch 48/200\n",
            "14/14 - 201s - 14s/step - accuracy: 0.5248 - loss: 1.0539 - val_accuracy: 0.6099 - val_loss: 0.9169\n",
            "Epoch 49/200\n",
            "14/14 - 185s - 13s/step - accuracy: 0.5579 - loss: 1.0077 - val_accuracy: 0.6099 - val_loss: 0.9161\n",
            "Epoch 50/200\n",
            "14/14 - 150s - 11s/step - accuracy: 0.5106 - loss: 1.0096 - val_accuracy: 0.6099 - val_loss: 0.9145\n",
            "Epoch 51/200\n",
            "14/14 - 150s - 11s/step - accuracy: 0.5390 - loss: 1.0013 - val_accuracy: 0.6044 - val_loss: 0.9136\n",
            "Epoch 52/200\n",
            "14/14 - 150s - 11s/step - accuracy: 0.5461 - loss: 1.0187 - val_accuracy: 0.6264 - val_loss: 0.9108\n",
            "Epoch 53/200\n",
            "14/14 - 151s - 11s/step - accuracy: 0.5697 - loss: 0.9485 - val_accuracy: 0.6209 - val_loss: 0.9092\n",
            "Epoch 54/200\n",
            "14/14 - 186s - 13s/step - accuracy: 0.5366 - loss: 0.9633 - val_accuracy: 0.6154 - val_loss: 0.9060\n",
            "Epoch 55/200\n",
            "14/14 - 154s - 11s/step - accuracy: 0.5721 - loss: 0.9757 - val_accuracy: 0.5989 - val_loss: 0.9035\n",
            "Epoch 56/200\n",
            "14/14 - 151s - 11s/step - accuracy: 0.5296 - loss: 0.9907 - val_accuracy: 0.6154 - val_loss: 0.9019\n",
            "Epoch 57/200\n",
            "14/14 - 149s - 11s/step - accuracy: 0.5603 - loss: 1.0117 - val_accuracy: 0.6154 - val_loss: 0.9000\n",
            "Epoch 58/200\n",
            "14/14 - 189s - 13s/step - accuracy: 0.5319 - loss: 1.0119 - val_accuracy: 0.6099 - val_loss: 0.8994\n",
            "Epoch 59/200\n",
            "14/14 - 186s - 13s/step - accuracy: 0.5485 - loss: 0.9809 - val_accuracy: 0.6154 - val_loss: 0.8982\n",
            "Epoch 60/200\n",
            "14/14 - 186s - 13s/step - accuracy: 0.5035 - loss: 1.0276 - val_accuracy: 0.6209 - val_loss: 0.8978\n",
            "Epoch 61/200\n",
            "14/14 - 203s - 15s/step - accuracy: 0.5296 - loss: 0.9629 - val_accuracy: 0.6099 - val_loss: 0.8974\n",
            "Epoch 62/200\n",
            "14/14 - 187s - 13s/step - accuracy: 0.5697 - loss: 0.9673 - val_accuracy: 0.6154 - val_loss: 0.8975\n",
            "Epoch 63/200\n",
            "14/14 - 203s - 14s/step - accuracy: 0.5343 - loss: 0.9881 - val_accuracy: 0.6099 - val_loss: 0.8965\n",
            "Epoch 64/200\n",
            "14/14 - 150s - 11s/step - accuracy: 0.5626 - loss: 0.9510 - val_accuracy: 0.6209 - val_loss: 0.8941\n",
            "Epoch 65/200\n",
            "14/14 - 148s - 11s/step - accuracy: 0.5154 - loss: 0.9891 - val_accuracy: 0.6209 - val_loss: 0.8933\n",
            "Epoch 66/200\n",
            "14/14 - 151s - 11s/step - accuracy: 0.5130 - loss: 0.9772 - val_accuracy: 0.6209 - val_loss: 0.8918\n",
            "Epoch 67/200\n",
            "14/14 - 151s - 11s/step - accuracy: 0.5225 - loss: 0.9819 - val_accuracy: 0.6264 - val_loss: 0.8912\n",
            "Epoch 68/200\n",
            "14/14 - 152s - 11s/step - accuracy: 0.5934 - loss: 0.9033 - val_accuracy: 0.6209 - val_loss: 0.8914\n",
            "Epoch 69/200\n",
            "14/14 - 149s - 11s/step - accuracy: 0.5248 - loss: 1.0397 - val_accuracy: 0.6319 - val_loss: 0.8917\n",
            "Epoch 70/200\n",
            "14/14 - 151s - 11s/step - accuracy: 0.5201 - loss: 0.9994 - val_accuracy: 0.6374 - val_loss: 0.8913\n",
            "Epoch 71/200\n",
            "14/14 - 151s - 11s/step - accuracy: 0.5343 - loss: 1.0079 - val_accuracy: 0.6484 - val_loss: 0.8905\n",
            "Epoch 72/200\n",
            "14/14 - 151s - 11s/step - accuracy: 0.5650 - loss: 0.9704 - val_accuracy: 0.6429 - val_loss: 0.8891\n",
            "Epoch 73/200\n",
            "14/14 - 189s - 13s/step - accuracy: 0.5910 - loss: 0.9285 - val_accuracy: 0.6484 - val_loss: 0.8867\n",
            "Epoch 74/200\n",
            "14/14 - 151s - 11s/step - accuracy: 0.5366 - loss: 0.9504 - val_accuracy: 0.6484 - val_loss: 0.8847\n",
            "Epoch 75/200\n",
            "14/14 - 150s - 11s/step - accuracy: 0.5556 - loss: 0.9575 - val_accuracy: 0.6484 - val_loss: 0.8824\n",
            "Epoch 76/200\n",
            "14/14 - 149s - 11s/step - accuracy: 0.5721 - loss: 0.9524 - val_accuracy: 0.6264 - val_loss: 0.8817\n",
            "Epoch 77/200\n",
            "14/14 - 147s - 11s/step - accuracy: 0.5863 - loss: 0.9466 - val_accuracy: 0.6429 - val_loss: 0.8803\n",
            "Epoch 78/200\n",
            "14/14 - 151s - 11s/step - accuracy: 0.5721 - loss: 0.9424 - val_accuracy: 0.6429 - val_loss: 0.8776\n",
            "Epoch 79/200\n",
            "14/14 - 187s - 13s/step - accuracy: 0.5556 - loss: 0.9479 - val_accuracy: 0.6484 - val_loss: 0.8763\n",
            "Epoch 80/200\n",
            "14/14 - 188s - 13s/step - accuracy: 0.5626 - loss: 0.9086 - val_accuracy: 0.6593 - val_loss: 0.8750\n",
            "Epoch 81/200\n",
            "14/14 - 188s - 13s/step - accuracy: 0.5745 - loss: 0.9388 - val_accuracy: 0.6538 - val_loss: 0.8732\n",
            "Epoch 82/200\n",
            "14/14 - 185s - 13s/step - accuracy: 0.5910 - loss: 0.9224 - val_accuracy: 0.6484 - val_loss: 0.8722\n",
            "Epoch 83/200\n",
            "14/14 - 187s - 13s/step - accuracy: 0.5508 - loss: 0.9354 - val_accuracy: 0.6484 - val_loss: 0.8704\n",
            "Epoch 84/200\n",
            "14/14 - 165s - 12s/step - accuracy: 0.6241 - loss: 0.8718 - val_accuracy: 0.6593 - val_loss: 0.8687\n",
            "Epoch 85/200\n",
            "14/14 - 148s - 11s/step - accuracy: 0.5556 - loss: 0.9260 - val_accuracy: 0.6429 - val_loss: 0.8668\n",
            "Epoch 86/200\n",
            "14/14 - 204s - 15s/step - accuracy: 0.5556 - loss: 0.9683 - val_accuracy: 0.6538 - val_loss: 0.8664\n",
            "Epoch 87/200\n",
            "14/14 - 150s - 11s/step - accuracy: 0.5650 - loss: 0.9494 - val_accuracy: 0.6429 - val_loss: 0.8664\n",
            "Epoch 88/200\n",
            "14/14 - 186s - 13s/step - accuracy: 0.5981 - loss: 0.9156 - val_accuracy: 0.6484 - val_loss: 0.8658\n",
            "Epoch 89/200\n",
            "14/14 - 202s - 14s/step - accuracy: 0.5887 - loss: 0.9210 - val_accuracy: 0.6374 - val_loss: 0.8666\n",
            "Epoch 90/200\n",
            "14/14 - 166s - 12s/step - accuracy: 0.5603 - loss: 0.9451 - val_accuracy: 0.6484 - val_loss: 0.8669\n",
            "Epoch 91/200\n",
            "14/14 - 151s - 11s/step - accuracy: 0.5816 - loss: 0.8897 - val_accuracy: 0.6538 - val_loss: 0.8662\n",
            "Epoch 92/200\n",
            "14/14 - 148s - 11s/step - accuracy: 0.5296 - loss: 0.9459 - val_accuracy: 0.6374 - val_loss: 0.8666\n",
            "Epoch 93/200\n",
            "14/14 - 202s - 14s/step - accuracy: 0.5745 - loss: 0.9469 - val_accuracy: 0.6374 - val_loss: 0.8645\n",
            "Epoch 94/200\n",
            "14/14 - 189s - 13s/step - accuracy: 0.5721 - loss: 0.9198 - val_accuracy: 0.6429 - val_loss: 0.8638\n",
            "Epoch 95/200\n",
            "14/14 - 188s - 13s/step - accuracy: 0.6099 - loss: 0.8740 - val_accuracy: 0.6429 - val_loss: 0.8628\n",
            "Epoch 96/200\n",
            "14/14 - 186s - 13s/step - accuracy: 0.5721 - loss: 0.9180 - val_accuracy: 0.6484 - val_loss: 0.8607\n",
            "Epoch 97/200\n",
            "14/14 - 149s - 11s/step - accuracy: 0.6005 - loss: 0.8690 - val_accuracy: 0.6429 - val_loss: 0.8584\n",
            "Epoch 98/200\n",
            "14/14 - 149s - 11s/step - accuracy: 0.5981 - loss: 0.8919 - val_accuracy: 0.6593 - val_loss: 0.8569\n",
            "Epoch 99/200\n",
            "14/14 - 149s - 11s/step - accuracy: 0.5816 - loss: 0.9234 - val_accuracy: 0.6593 - val_loss: 0.8558\n",
            "Epoch 100/200\n",
            "14/14 - 152s - 11s/step - accuracy: 0.6123 - loss: 0.8974 - val_accuracy: 0.6758 - val_loss: 0.8553\n",
            "Epoch 101/200\n",
            "14/14 - 236s - 17s/step - accuracy: 0.5461 - loss: 0.9375 - val_accuracy: 0.6813 - val_loss: 0.8559\n",
            "Epoch 102/200\n",
            "14/14 - 167s - 12s/step - accuracy: 0.6005 - loss: 0.8528 - val_accuracy: 0.6813 - val_loss: 0.8545\n",
            "Epoch 103/200\n",
            "14/14 - 186s - 13s/step - accuracy: 0.6194 - loss: 0.8731 - val_accuracy: 0.6703 - val_loss: 0.8513\n",
            "Epoch 104/200\n",
            "14/14 - 184s - 13s/step - accuracy: 0.6241 - loss: 0.8686 - val_accuracy: 0.6648 - val_loss: 0.8490\n",
            "Epoch 105/200\n",
            "14/14 - 167s - 12s/step - accuracy: 0.5461 - loss: 0.9630 - val_accuracy: 0.6648 - val_loss: 0.8477\n",
            "Epoch 106/200\n",
            "14/14 - 150s - 11s/step - accuracy: 0.5934 - loss: 0.9010 - val_accuracy: 0.6648 - val_loss: 0.8470\n",
            "Epoch 107/200\n",
            "14/14 - 150s - 11s/step - accuracy: 0.5957 - loss: 0.9118 - val_accuracy: 0.6703 - val_loss: 0.8457\n",
            "Epoch 108/200\n",
            "14/14 - 203s - 15s/step - accuracy: 0.5910 - loss: 0.9288 - val_accuracy: 0.6758 - val_loss: 0.8467\n",
            "Epoch 109/200\n",
            "14/14 - 151s - 11s/step - accuracy: 0.5863 - loss: 0.9186 - val_accuracy: 0.6593 - val_loss: 0.8463\n",
            "Epoch 110/200\n",
            "14/14 - 187s - 13s/step - accuracy: 0.6028 - loss: 0.9029 - val_accuracy: 0.6593 - val_loss: 0.8416\n",
            "Epoch 111/200\n",
            "14/14 - 188s - 13s/step - accuracy: 0.5887 - loss: 0.8963 - val_accuracy: 0.6648 - val_loss: 0.8390\n",
            "Epoch 112/200\n",
            "14/14 - 165s - 12s/step - accuracy: 0.6147 - loss: 0.8977 - val_accuracy: 0.6648 - val_loss: 0.8381\n",
            "Epoch 113/200\n",
            "14/14 - 188s - 13s/step - accuracy: 0.6265 - loss: 0.9051 - val_accuracy: 0.6648 - val_loss: 0.8392\n",
            "Epoch 114/200\n",
            "14/14 - 189s - 13s/step - accuracy: 0.6052 - loss: 0.8702 - val_accuracy: 0.6648 - val_loss: 0.8383\n",
            "Epoch 115/200\n",
            "14/14 - 186s - 13s/step - accuracy: 0.6076 - loss: 0.8815 - val_accuracy: 0.6758 - val_loss: 0.8377\n",
            "Epoch 116/200\n",
            "14/14 - 168s - 12s/step - accuracy: 0.5910 - loss: 0.9000 - val_accuracy: 0.6648 - val_loss: 0.8378\n",
            "Epoch 117/200\n",
            "14/14 - 185s - 13s/step - accuracy: 0.5887 - loss: 0.8977 - val_accuracy: 0.6648 - val_loss: 0.8374\n",
            "Epoch 118/200\n",
            "14/14 - 189s - 14s/step - accuracy: 0.5508 - loss: 0.9348 - val_accuracy: 0.6703 - val_loss: 0.8376\n",
            "Epoch 119/200\n",
            "14/14 - 151s - 11s/step - accuracy: 0.6076 - loss: 0.8758 - val_accuracy: 0.6758 - val_loss: 0.8375\n",
            "Epoch 120/200\n",
            "14/14 - 148s - 11s/step - accuracy: 0.6170 - loss: 0.8576 - val_accuracy: 0.6758 - val_loss: 0.8359\n",
            "Epoch 121/200\n",
            "14/14 - 205s - 15s/step - accuracy: 0.6147 - loss: 0.9057 - val_accuracy: 0.6813 - val_loss: 0.8355\n",
            "Epoch 122/200\n",
            "14/14 - 187s - 13s/step - accuracy: 0.6572 - loss: 0.8080 - val_accuracy: 0.6813 - val_loss: 0.8341\n",
            "Epoch 123/200\n",
            "14/14 - 165s - 12s/step - accuracy: 0.6147 - loss: 0.8724 - val_accuracy: 0.6758 - val_loss: 0.8333\n",
            "Epoch 124/200\n",
            "14/14 - 152s - 11s/step - accuracy: 0.6265 - loss: 0.8516 - val_accuracy: 0.6703 - val_loss: 0.8339\n",
            "Epoch 125/200\n",
            "14/14 - 151s - 11s/step - accuracy: 0.5863 - loss: 0.8778 - val_accuracy: 0.6758 - val_loss: 0.8321\n",
            "Epoch 126/200\n",
            "14/14 - 148s - 11s/step - accuracy: 0.5910 - loss: 0.9087 - val_accuracy: 0.6758 - val_loss: 0.8322\n",
            "Epoch 127/200\n",
            "14/14 - 240s - 17s/step - accuracy: 0.6572 - loss: 0.8147 - val_accuracy: 0.6758 - val_loss: 0.8299\n",
            "Epoch 128/200\n",
            "14/14 - 151s - 11s/step - accuracy: 0.5816 - loss: 0.8915 - val_accuracy: 0.6758 - val_loss: 0.8273\n",
            "Epoch 129/200\n",
            "14/14 - 150s - 11s/step - accuracy: 0.5910 - loss: 0.8798 - val_accuracy: 0.6703 - val_loss: 0.8261\n",
            "Epoch 130/200\n",
            "14/14 - 151s - 11s/step - accuracy: 0.5934 - loss: 0.8592 - val_accuracy: 0.6758 - val_loss: 0.8239\n",
            "Epoch 131/200\n",
            "14/14 - 240s - 17s/step - accuracy: 0.5839 - loss: 0.9173 - val_accuracy: 0.6703 - val_loss: 0.8221\n",
            "Epoch 132/200\n",
            "14/14 - 188s - 13s/step - accuracy: 0.5887 - loss: 0.9010 - val_accuracy: 0.6758 - val_loss: 0.8227\n",
            "Epoch 133/200\n",
            "14/14 - 187s - 13s/step - accuracy: 0.6194 - loss: 0.8543 - val_accuracy: 0.6703 - val_loss: 0.8193\n",
            "Epoch 134/200\n",
            "14/14 - 166s - 12s/step - accuracy: 0.5697 - loss: 0.8782 - val_accuracy: 0.6703 - val_loss: 0.8184\n",
            "Epoch 135/200\n",
            "14/14 - 185s - 13s/step - accuracy: 0.5981 - loss: 0.8737 - val_accuracy: 0.6703 - val_loss: 0.8185\n",
            "Epoch 136/200\n",
            "14/14 - 151s - 11s/step - accuracy: 0.6099 - loss: 0.8866 - val_accuracy: 0.6703 - val_loss: 0.8175\n",
            "Epoch 137/200\n",
            "14/14 - 185s - 13s/step - accuracy: 0.6028 - loss: 0.8790 - val_accuracy: 0.6758 - val_loss: 0.8170\n",
            "Epoch 138/200\n",
            "14/14 - 148s - 11s/step - accuracy: 0.6170 - loss: 0.8733 - val_accuracy: 0.6758 - val_loss: 0.8176\n",
            "Epoch 139/200\n",
            "14/14 - 151s - 11s/step - accuracy: 0.6028 - loss: 0.8701 - val_accuracy: 0.6758 - val_loss: 0.8165\n",
            "Epoch 140/200\n",
            "14/14 - 151s - 11s/step - accuracy: 0.5910 - loss: 0.8779 - val_accuracy: 0.6703 - val_loss: 0.8166\n",
            "Epoch 141/200\n",
            "14/14 - 186s - 13s/step - accuracy: 0.6407 - loss: 0.8095 - val_accuracy: 0.6758 - val_loss: 0.8147\n",
            "Epoch 142/200\n",
            "14/14 - 165s - 12s/step - accuracy: 0.6312 - loss: 0.8514 - val_accuracy: 0.6703 - val_loss: 0.8117\n",
            "Epoch 143/200\n",
            "14/14 - 189s - 13s/step - accuracy: 0.6525 - loss: 0.8220 - val_accuracy: 0.6703 - val_loss: 0.8093\n",
            "Epoch 144/200\n",
            "14/14 - 187s - 13s/step - accuracy: 0.6383 - loss: 0.8425 - val_accuracy: 0.6813 - val_loss: 0.8072\n",
            "Epoch 145/200\n",
            "14/14 - 201s - 14s/step - accuracy: 0.5981 - loss: 0.8635 - val_accuracy: 0.6868 - val_loss: 0.8066\n",
            "Epoch 146/200\n",
            "14/14 - 187s - 13s/step - accuracy: 0.6076 - loss: 0.8917 - val_accuracy: 0.6813 - val_loss: 0.8073\n",
            "Epoch 147/200\n",
            "14/14 - 167s - 12s/step - accuracy: 0.6028 - loss: 0.8724 - val_accuracy: 0.6758 - val_loss: 0.8076\n",
            "Epoch 148/200\n",
            "14/14 - 151s - 11s/step - accuracy: 0.6005 - loss: 0.8670 - val_accuracy: 0.6813 - val_loss: 0.8067\n",
            "Epoch 149/200\n",
            "14/14 - 148s - 11s/step - accuracy: 0.6123 - loss: 0.8524 - val_accuracy: 0.6813 - val_loss: 0.8066\n",
            "Epoch 150/200\n",
            "14/14 - 188s - 13s/step - accuracy: 0.6028 - loss: 0.8669 - val_accuracy: 0.6758 - val_loss: 0.8070\n",
            "Epoch 151/200\n",
            "14/14 - 152s - 11s/step - accuracy: 0.6170 - loss: 0.8555 - val_accuracy: 0.6758 - val_loss: 0.8063\n",
            "Epoch 152/200\n",
            "14/14 - 149s - 11s/step - accuracy: 0.6265 - loss: 0.8390 - val_accuracy: 0.6703 - val_loss: 0.8040\n",
            "Epoch 153/200\n",
            "14/14 - 202s - 14s/step - accuracy: 0.6052 - loss: 0.8780 - val_accuracy: 0.6813 - val_loss: 0.8058\n",
            "Epoch 154/200\n",
            "14/14 - 150s - 11s/step - accuracy: 0.5910 - loss: 0.8888 - val_accuracy: 0.6758 - val_loss: 0.8058\n",
            "Epoch 155/200\n",
            "14/14 - 186s - 13s/step - accuracy: 0.6052 - loss: 0.8555 - val_accuracy: 0.6813 - val_loss: 0.8032\n",
            "Epoch 156/200\n",
            "14/14 - 189s - 13s/step - accuracy: 0.6359 - loss: 0.8142 - val_accuracy: 0.6868 - val_loss: 0.7996\n",
            "Epoch 157/200\n",
            "14/14 - 151s - 11s/step - accuracy: 0.6241 - loss: 0.8552 - val_accuracy: 0.6813 - val_loss: 0.7976\n",
            "Epoch 158/200\n",
            "14/14 - 187s - 13s/step - accuracy: 0.6028 - loss: 0.8610 - val_accuracy: 0.6868 - val_loss: 0.7975\n",
            "Epoch 159/200\n",
            "14/14 - 165s - 12s/step - accuracy: 0.6099 - loss: 0.8571 - val_accuracy: 0.6758 - val_loss: 0.7979\n",
            "Epoch 160/200\n",
            "14/14 - 151s - 11s/step - accuracy: 0.6430 - loss: 0.8402 - val_accuracy: 0.6758 - val_loss: 0.7979\n",
            "Epoch 161/200\n",
            "14/14 - 150s - 11s/step - accuracy: 0.5934 - loss: 0.9142 - val_accuracy: 0.6703 - val_loss: 0.7976\n",
            "Epoch 162/200\n",
            "14/14 - 152s - 11s/step - accuracy: 0.6123 - loss: 0.8371 - val_accuracy: 0.6758 - val_loss: 0.7968\n",
            "Epoch 163/200\n",
            "14/14 - 151s - 11s/step - accuracy: 0.6052 - loss: 0.8751 - val_accuracy: 0.6813 - val_loss: 0.7966\n",
            "Epoch 164/200\n",
            "14/14 - 186s - 13s/step - accuracy: 0.6147 - loss: 0.8973 - val_accuracy: 0.6758 - val_loss: 0.7980\n",
            "Epoch 165/200\n",
            "14/14 - 188s - 13s/step - accuracy: 0.6312 - loss: 0.8170 - val_accuracy: 0.6758 - val_loss: 0.7966\n",
            "Epoch 166/200\n",
            "14/14 - 152s - 11s/step - accuracy: 0.6005 - loss: 0.8520 - val_accuracy: 0.6758 - val_loss: 0.7959\n",
            "Epoch 167/200\n",
            "14/14 - 148s - 11s/step - accuracy: 0.6478 - loss: 0.8511 - val_accuracy: 0.6868 - val_loss: 0.7956\n",
            "Epoch 168/200\n",
            "14/14 - 204s - 15s/step - accuracy: 0.6714 - loss: 0.7991 - val_accuracy: 0.6758 - val_loss: 0.7936\n",
            "Epoch 169/200\n",
            "14/14 - 151s - 11s/step - accuracy: 0.6478 - loss: 0.8252 - val_accuracy: 0.6813 - val_loss: 0.7923\n",
            "Epoch 170/200\n",
            "14/14 - 188s - 13s/step - accuracy: 0.5887 - loss: 0.8831 - val_accuracy: 0.6868 - val_loss: 0.7914\n",
            "Epoch 171/200\n",
            "14/14 - 151s - 11s/step - accuracy: 0.6147 - loss: 0.8360 - val_accuracy: 0.6813 - val_loss: 0.7918\n",
            "Epoch 172/200\n",
            "14/14 - 151s - 11s/step - accuracy: 0.6288 - loss: 0.8403 - val_accuracy: 0.6868 - val_loss: 0.7924\n",
            "Epoch 173/200\n",
            "14/14 - 187s - 13s/step - accuracy: 0.6359 - loss: 0.8273 - val_accuracy: 0.6758 - val_loss: 0.7924\n",
            "Epoch 174/200\n",
            "14/14 - 188s - 13s/step - accuracy: 0.6123 - loss: 0.8302 - val_accuracy: 0.6813 - val_loss: 0.7896\n",
            "Epoch 175/200\n",
            "14/14 - 151s - 11s/step - accuracy: 0.6383 - loss: 0.8660 - val_accuracy: 0.6758 - val_loss: 0.7883\n",
            "Epoch 176/200\n",
            "14/14 - 186s - 13s/step - accuracy: 0.6596 - loss: 0.7994 - val_accuracy: 0.6813 - val_loss: 0.7884\n",
            "Epoch 177/200\n",
            "14/14 - 149s - 11s/step - accuracy: 0.6359 - loss: 0.7847 - val_accuracy: 0.6868 - val_loss: 0.7883\n",
            "Epoch 178/200\n",
            "14/14 - 238s - 17s/step - accuracy: 0.6217 - loss: 0.8477 - val_accuracy: 0.6758 - val_loss: 0.7868\n",
            "Epoch 179/200\n",
            "14/14 - 148s - 11s/step - accuracy: 0.6241 - loss: 0.8271 - val_accuracy: 0.6703 - val_loss: 0.7867\n",
            "Epoch 180/200\n",
            "14/14 - 189s - 14s/step - accuracy: 0.6241 - loss: 0.8505 - val_accuracy: 0.6758 - val_loss: 0.7858\n",
            "Epoch 181/200\n",
            "14/14 - 201s - 14s/step - accuracy: 0.6596 - loss: 0.7935 - val_accuracy: 0.6593 - val_loss: 0.7839\n",
            "Epoch 182/200\n",
            "14/14 - 187s - 13s/step - accuracy: 0.6123 - loss: 0.8337 - val_accuracy: 0.6648 - val_loss: 0.7838\n",
            "Epoch 183/200\n",
            "14/14 - 149s - 11s/step - accuracy: 0.6170 - loss: 0.8338 - val_accuracy: 0.6648 - val_loss: 0.7832\n",
            "Epoch 184/200\n",
            "14/14 - 188s - 13s/step - accuracy: 0.6525 - loss: 0.7772 - val_accuracy: 0.6648 - val_loss: 0.7827\n",
            "Epoch 185/200\n",
            "14/14 - 151s - 11s/step - accuracy: 0.6478 - loss: 0.8008 - val_accuracy: 0.6648 - val_loss: 0.7807\n",
            "Epoch 186/200\n",
            "14/14 - 188s - 13s/step - accuracy: 0.6572 - loss: 0.8076 - val_accuracy: 0.6593 - val_loss: 0.7795\n",
            "Epoch 187/200\n",
            "14/14 - 188s - 13s/step - accuracy: 0.6738 - loss: 0.8388 - val_accuracy: 0.6703 - val_loss: 0.7803\n",
            "Epoch 188/200\n",
            "14/14 - 187s - 13s/step - accuracy: 0.6359 - loss: 0.8719 - val_accuracy: 0.6703 - val_loss: 0.7785\n",
            "Epoch 189/200\n",
            "14/14 - 201s - 14s/step - accuracy: 0.6265 - loss: 0.8544 - val_accuracy: 0.6758 - val_loss: 0.7787\n",
            "Epoch 190/200\n",
            "14/14 - 187s - 13s/step - accuracy: 0.6312 - loss: 0.8164 - val_accuracy: 0.6868 - val_loss: 0.7787\n",
            "Epoch 191/200\n",
            "14/14 - 188s - 13s/step - accuracy: 0.6076 - loss: 0.8558 - val_accuracy: 0.6868 - val_loss: 0.7780\n",
            "Epoch 192/200\n",
            "14/14 - 165s - 12s/step - accuracy: 0.6407 - loss: 0.8332 - val_accuracy: 0.6758 - val_loss: 0.7755\n",
            "Epoch 193/200\n",
            "14/14 - 187s - 13s/step - accuracy: 0.6856 - loss: 0.7760 - val_accuracy: 0.6758 - val_loss: 0.7741\n",
            "Epoch 194/200\n",
            "14/14 - 189s - 13s/step - accuracy: 0.6170 - loss: 0.8302 - val_accuracy: 0.6703 - val_loss: 0.7728\n",
            "Epoch 195/200\n",
            "14/14 - 151s - 11s/step - accuracy: 0.6548 - loss: 0.7953 - val_accuracy: 0.6703 - val_loss: 0.7714\n",
            "Epoch 196/200\n",
            "14/14 - 148s - 11s/step - accuracy: 0.6430 - loss: 0.8148 - val_accuracy: 0.6758 - val_loss: 0.7704\n",
            "Epoch 197/200\n",
            "14/14 - 189s - 13s/step - accuracy: 0.6478 - loss: 0.8451 - val_accuracy: 0.6758 - val_loss: 0.7700\n",
            "Epoch 198/200\n",
            "14/14 - 150s - 11s/step - accuracy: 0.6265 - loss: 0.8247 - val_accuracy: 0.6758 - val_loss: 0.7685\n",
            "Epoch 199/200\n",
            "14/14 - 184s - 13s/step - accuracy: 0.6572 - loss: 0.7956 - val_accuracy: 0.6758 - val_loss: 0.7679\n",
            "Epoch 200/200\n",
            "14/14 - 150s - 11s/step - accuracy: 0.6359 - loss: 0.8170 - val_accuracy: 0.6758 - val_loss: 0.7683\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model berhasil disimpan: model_split70_lr0.0001_ep200_l20.0001.h5\n"
          ]
        }
      ],
      "source": [
        "split_ratio = 0.7\n",
        "split_percent = round(split_ratio * 100)\n",
        "\n",
        "for lr in [0.0001]:\n",
        "    for epoch in [200]:\n",
        "        print(f\"\\n📦 Training model dengan split_ratio={split_percent}%, learning_rate={lr}, epochs={epoch}\")\n",
        "\n",
        "        model, history = train_model(\n",
        "            split_ratio=split_ratio,\n",
        "            lr=lr,\n",
        "            epochs=epoch\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HKfQic3_vekl",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKfQic3_vekl",
        "outputId": "ac20c437-ad66-4918-ded7-588dc074d8f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📦 Training model dengan split_ratio=70%, learning_rate=0.0001, epochs=300\n",
            "Found 423 images belonging to 3 classes.\n",
            "Found 182 images belonging to 3 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "14/14 - 207s - 15s/step - accuracy: 0.3310 - loss: 1.9454 - val_accuracy: 0.3297 - val_loss: 1.2351\n",
            "Epoch 2/300\n",
            "14/14 - 154s - 11s/step - accuracy: 0.3357 - loss: 1.7637 - val_accuracy: 0.3901 - val_loss: 1.1685\n",
            "Epoch 3/300\n",
            "14/14 - 147s - 10s/step - accuracy: 0.3333 - loss: 1.6245 - val_accuracy: 0.4176 - val_loss: 1.1275\n",
            "Epoch 4/300\n",
            "14/14 - 185s - 13s/step - accuracy: 0.3995 - loss: 1.4229 - val_accuracy: 0.4615 - val_loss: 1.0810\n",
            "Epoch 5/300\n",
            "14/14 - 154s - 11s/step - accuracy: 0.3641 - loss: 1.5569 - val_accuracy: 0.4670 - val_loss: 1.0561\n",
            "Epoch 6/300\n",
            "14/14 - 193s - 14s/step - accuracy: 0.3735 - loss: 1.3800 - val_accuracy: 0.4615 - val_loss: 1.0419\n",
            "Epoch 7/300\n",
            "14/14 - 201s - 14s/step - accuracy: 0.4184 - loss: 1.3473 - val_accuracy: 0.4780 - val_loss: 1.0326\n",
            "Epoch 8/300\n",
            "14/14 - 137s - 10s/step - accuracy: 0.4350 - loss: 1.3768 - val_accuracy: 0.4615 - val_loss: 1.0226\n",
            "Epoch 9/300\n",
            "14/14 - 143s - 10s/step - accuracy: 0.4279 - loss: 1.2512 - val_accuracy: 0.4670 - val_loss: 1.0148\n",
            "Epoch 10/300\n",
            "14/14 - 141s - 10s/step - accuracy: 0.4279 - loss: 1.2504 - val_accuracy: 0.4780 - val_loss: 1.0121\n",
            "Epoch 11/300\n",
            "14/14 - 138s - 10s/step - accuracy: 0.4421 - loss: 1.3119 - val_accuracy: 0.4670 - val_loss: 1.0041\n",
            "Epoch 12/300\n",
            "14/14 - 144s - 10s/step - accuracy: 0.4492 - loss: 1.2819 - val_accuracy: 0.4670 - val_loss: 0.9977\n",
            "Epoch 13/300\n",
            "14/14 - 185s - 13s/step - accuracy: 0.4539 - loss: 1.2109 - val_accuracy: 0.4725 - val_loss: 0.9929\n",
            "Epoch 14/300\n",
            "14/14 - 164s - 12s/step - accuracy: 0.4515 - loss: 1.1686 - val_accuracy: 0.4725 - val_loss: 0.9907\n",
            "Epoch 15/300\n",
            "14/14 - 186s - 13s/step - accuracy: 0.4492 - loss: 1.2001 - val_accuracy: 0.4725 - val_loss: 0.9858\n",
            "Epoch 16/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.4704 - loss: 1.1780 - val_accuracy: 0.4945 - val_loss: 0.9802\n",
            "Epoch 17/300\n",
            "14/14 - 186s - 13s/step - accuracy: 0.4421 - loss: 1.1631 - val_accuracy: 0.4945 - val_loss: 0.9756\n",
            "Epoch 18/300\n",
            "14/14 - 145s - 10s/step - accuracy: 0.4492 - loss: 1.1874 - val_accuracy: 0.5000 - val_loss: 0.9710\n",
            "Epoch 19/300\n",
            "14/14 - 242s - 17s/step - accuracy: 0.4752 - loss: 1.1414 - val_accuracy: 0.5110 - val_loss: 0.9650\n",
            "Epoch 20/300\n",
            "14/14 - 185s - 13s/step - accuracy: 0.5059 - loss: 1.0972 - val_accuracy: 0.4945 - val_loss: 0.9605\n",
            "Epoch 21/300\n",
            "14/14 - 186s - 13s/step - accuracy: 0.5225 - loss: 1.0639 - val_accuracy: 0.5110 - val_loss: 0.9594\n",
            "Epoch 22/300\n",
            "14/14 - 184s - 13s/step - accuracy: 0.4799 - loss: 1.1243 - val_accuracy: 0.5330 - val_loss: 0.9590\n",
            "Epoch 23/300\n",
            "14/14 - 163s - 12s/step - accuracy: 0.4728 - loss: 1.0989 - val_accuracy: 0.5385 - val_loss: 0.9558\n",
            "Epoch 24/300\n",
            "14/14 - 144s - 10s/step - accuracy: 0.5059 - loss: 1.0625 - val_accuracy: 0.5220 - val_loss: 0.9536\n",
            "Epoch 25/300\n",
            "14/14 - 202s - 14s/step - accuracy: 0.4704 - loss: 1.1057 - val_accuracy: 0.5385 - val_loss: 0.9527\n",
            "Epoch 26/300\n",
            "14/14 - 184s - 13s/step - accuracy: 0.4563 - loss: 1.1310 - val_accuracy: 0.5440 - val_loss: 0.9509\n",
            "Epoch 27/300\n",
            "14/14 - 185s - 13s/step - accuracy: 0.5414 - loss: 1.0203 - val_accuracy: 0.5549 - val_loss: 0.9488\n",
            "Epoch 28/300\n",
            "14/14 - 166s - 12s/step - accuracy: 0.5319 - loss: 1.0443 - val_accuracy: 0.5440 - val_loss: 0.9473\n",
            "Epoch 29/300\n",
            "14/14 - 183s - 13s/step - accuracy: 0.5177 - loss: 1.0654 - val_accuracy: 0.5549 - val_loss: 0.9457\n",
            "Epoch 30/300\n",
            "14/14 - 182s - 13s/step - accuracy: 0.5130 - loss: 1.0308 - val_accuracy: 0.5495 - val_loss: 0.9452\n",
            "Epoch 31/300\n",
            "14/14 - 167s - 12s/step - accuracy: 0.5248 - loss: 0.9875 - val_accuracy: 0.5549 - val_loss: 0.9451\n",
            "Epoch 32/300\n",
            "14/14 - 185s - 13s/step - accuracy: 0.4870 - loss: 1.0877 - val_accuracy: 0.5549 - val_loss: 0.9439\n",
            "Epoch 33/300\n",
            "14/14 - 185s - 13s/step - accuracy: 0.5177 - loss: 1.0392 - val_accuracy: 0.5714 - val_loss: 0.9405\n",
            "Epoch 34/300\n",
            "14/14 - 185s - 13s/step - accuracy: 0.5319 - loss: 1.0438 - val_accuracy: 0.5714 - val_loss: 0.9386\n",
            "Epoch 35/300\n",
            "14/14 - 146s - 10s/step - accuracy: 0.5248 - loss: 1.0239 - val_accuracy: 0.5714 - val_loss: 0.9374\n",
            "Epoch 36/300\n",
            "14/14 - 241s - 17s/step - accuracy: 0.5225 - loss: 1.0361 - val_accuracy: 0.5769 - val_loss: 0.9359\n",
            "Epoch 37/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.5201 - loss: 0.9954 - val_accuracy: 0.5769 - val_loss: 0.9362\n",
            "Epoch 38/300\n",
            "14/14 - 185s - 13s/step - accuracy: 0.5059 - loss: 1.0477 - val_accuracy: 0.5714 - val_loss: 0.9359\n",
            "Epoch 39/300\n",
            "14/14 - 183s - 13s/step - accuracy: 0.5083 - loss: 1.0292 - val_accuracy: 0.5659 - val_loss: 0.9337\n",
            "Epoch 40/300\n",
            "14/14 - 147s - 11s/step - accuracy: 0.5485 - loss: 0.9603 - val_accuracy: 0.5604 - val_loss: 0.9326\n",
            "Epoch 41/300\n",
            "14/14 - 147s - 11s/step - accuracy: 0.5319 - loss: 1.0028 - val_accuracy: 0.5659 - val_loss: 0.9314\n",
            "Epoch 42/300\n",
            "14/14 - 146s - 10s/step - accuracy: 0.5154 - loss: 0.9918 - val_accuracy: 0.5659 - val_loss: 0.9301\n",
            "Epoch 43/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.5414 - loss: 0.9936 - val_accuracy: 0.5659 - val_loss: 0.9293\n",
            "Epoch 44/300\n",
            "14/14 - 185s - 13s/step - accuracy: 0.5390 - loss: 1.0041 - val_accuracy: 0.5824 - val_loss: 0.9283\n",
            "Epoch 45/300\n",
            "14/14 - 164s - 12s/step - accuracy: 0.4988 - loss: 1.0219 - val_accuracy: 0.5824 - val_loss: 0.9278\n",
            "Epoch 46/300\n",
            "14/14 - 147s - 11s/step - accuracy: 0.5485 - loss: 0.9614 - val_accuracy: 0.5824 - val_loss: 0.9252\n",
            "Epoch 47/300\n",
            "14/14 - 144s - 10s/step - accuracy: 0.5414 - loss: 0.9923 - val_accuracy: 0.5824 - val_loss: 0.9233\n",
            "Epoch 48/300\n",
            "14/14 - 240s - 17s/step - accuracy: 0.5437 - loss: 0.9830 - val_accuracy: 0.5824 - val_loss: 0.9221\n",
            "Epoch 49/300\n",
            "14/14 - 139s - 10s/step - accuracy: 0.5366 - loss: 0.9909 - val_accuracy: 0.5934 - val_loss: 0.9207\n",
            "Epoch 50/300\n",
            "14/14 - 143s - 10s/step - accuracy: 0.5626 - loss: 0.9472 - val_accuracy: 0.5934 - val_loss: 0.9194\n",
            "Epoch 51/300\n",
            "14/14 - 182s - 13s/step - accuracy: 0.5721 - loss: 0.9202 - val_accuracy: 0.5989 - val_loss: 0.9170\n",
            "Epoch 52/300\n",
            "14/14 - 185s - 13s/step - accuracy: 0.5225 - loss: 1.0036 - val_accuracy: 0.5934 - val_loss: 0.9154\n",
            "Epoch 53/300\n",
            "14/14 - 202s - 14s/step - accuracy: 0.5319 - loss: 0.9614 - val_accuracy: 0.5989 - val_loss: 0.9135\n",
            "Epoch 54/300\n",
            "14/14 - 186s - 13s/step - accuracy: 0.5697 - loss: 0.9472 - val_accuracy: 0.5934 - val_loss: 0.9112\n",
            "Epoch 55/300\n",
            "14/14 - 164s - 12s/step - accuracy: 0.5437 - loss: 0.9688 - val_accuracy: 0.5934 - val_loss: 0.9095\n",
            "Epoch 56/300\n",
            "14/14 - 186s - 13s/step - accuracy: 0.5532 - loss: 0.9462 - val_accuracy: 0.5989 - val_loss: 0.9084\n",
            "Epoch 57/300\n",
            "14/14 - 165s - 12s/step - accuracy: 0.5532 - loss: 0.9573 - val_accuracy: 0.5989 - val_loss: 0.9069\n",
            "Epoch 58/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.5177 - loss: 1.0030 - val_accuracy: 0.5934 - val_loss: 0.9060\n",
            "Epoch 59/300\n",
            "14/14 - 185s - 13s/step - accuracy: 0.5461 - loss: 0.9554 - val_accuracy: 0.5824 - val_loss: 0.9058\n",
            "Epoch 60/300\n",
            "14/14 - 203s - 14s/step - accuracy: 0.5674 - loss: 0.9501 - val_accuracy: 0.5934 - val_loss: 0.9046\n",
            "Epoch 61/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.5674 - loss: 0.9362 - val_accuracy: 0.5989 - val_loss: 0.9038\n",
            "Epoch 62/300\n",
            "14/14 - 185s - 13s/step - accuracy: 0.5579 - loss: 0.9263 - val_accuracy: 0.5934 - val_loss: 0.9019\n",
            "Epoch 63/300\n",
            "14/14 - 145s - 10s/step - accuracy: 0.5863 - loss: 0.9000 - val_accuracy: 0.5989 - val_loss: 0.8984\n",
            "Epoch 64/300\n",
            "14/14 - 185s - 13s/step - accuracy: 0.5437 - loss: 0.9475 - val_accuracy: 0.5989 - val_loss: 0.8967\n",
            "Epoch 65/300\n",
            "14/14 - 201s - 14s/step - accuracy: 0.4870 - loss: 1.0424 - val_accuracy: 0.5989 - val_loss: 0.8967\n",
            "Epoch 66/300\n",
            "14/14 - 144s - 10s/step - accuracy: 0.5556 - loss: 0.9391 - val_accuracy: 0.5879 - val_loss: 0.8960\n",
            "Epoch 67/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.5910 - loss: 0.9293 - val_accuracy: 0.6154 - val_loss: 0.8935\n",
            "Epoch 68/300\n",
            "14/14 - 146s - 10s/step - accuracy: 0.5296 - loss: 0.9266 - val_accuracy: 0.6264 - val_loss: 0.8930\n",
            "Epoch 69/300\n",
            "14/14 - 142s - 10s/step - accuracy: 0.5768 - loss: 0.9366 - val_accuracy: 0.6209 - val_loss: 0.8922\n",
            "Epoch 70/300\n",
            "14/14 - 146s - 10s/step - accuracy: 0.5697 - loss: 0.9046 - val_accuracy: 0.6154 - val_loss: 0.8900\n",
            "Epoch 71/300\n",
            "14/14 - 200s - 14s/step - accuracy: 0.5934 - loss: 0.8955 - val_accuracy: 0.6154 - val_loss: 0.8880\n",
            "Epoch 72/300\n",
            "14/14 - 147s - 11s/step - accuracy: 0.5508 - loss: 0.9632 - val_accuracy: 0.6154 - val_loss: 0.8866\n",
            "Epoch 73/300\n",
            "14/14 - 146s - 10s/step - accuracy: 0.5414 - loss: 0.9678 - val_accuracy: 0.6209 - val_loss: 0.8866\n",
            "Epoch 74/300\n",
            "14/14 - 149s - 11s/step - accuracy: 0.5934 - loss: 0.8802 - val_accuracy: 0.6154 - val_loss: 0.8863\n",
            "Epoch 75/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.5390 - loss: 0.9362 - val_accuracy: 0.5989 - val_loss: 0.8851\n",
            "Epoch 76/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.5532 - loss: 0.9127 - val_accuracy: 0.5934 - val_loss: 0.8842\n",
            "Epoch 77/300\n",
            "14/14 - 147s - 11s/step - accuracy: 0.5674 - loss: 0.9213 - val_accuracy: 0.5989 - val_loss: 0.8827\n",
            "Epoch 78/300\n",
            "14/14 - 241s - 17s/step - accuracy: 0.5816 - loss: 0.9206 - val_accuracy: 0.6044 - val_loss: 0.8807\n",
            "Epoch 79/300\n",
            "14/14 - 147s - 11s/step - accuracy: 0.5697 - loss: 0.9151 - val_accuracy: 0.6099 - val_loss: 0.8792\n",
            "Epoch 80/300\n",
            "14/14 - 184s - 13s/step - accuracy: 0.5910 - loss: 0.8858 - val_accuracy: 0.6044 - val_loss: 0.8772\n",
            "Epoch 81/300\n",
            "14/14 - 203s - 15s/step - accuracy: 0.5626 - loss: 0.9190 - val_accuracy: 0.6044 - val_loss: 0.8747\n",
            "Epoch 82/300\n",
            "14/14 - 186s - 13s/step - accuracy: 0.5768 - loss: 0.9944 - val_accuracy: 0.5989 - val_loss: 0.8733\n",
            "Epoch 83/300\n",
            "14/14 - 145s - 10s/step - accuracy: 0.5887 - loss: 0.9528 - val_accuracy: 0.6099 - val_loss: 0.8742\n",
            "Epoch 84/300\n",
            "14/14 - 204s - 15s/step - accuracy: 0.5768 - loss: 0.9046 - val_accuracy: 0.6099 - val_loss: 0.8744\n",
            "Epoch 85/300\n",
            "14/14 - 141s - 10s/step - accuracy: 0.5437 - loss: 0.9479 - val_accuracy: 0.6099 - val_loss: 0.8738\n",
            "Epoch 86/300\n",
            "14/14 - 187s - 13s/step - accuracy: 0.5721 - loss: 0.9314 - val_accuracy: 0.6099 - val_loss: 0.8741\n",
            "Epoch 87/300\n",
            "14/14 - 142s - 10s/step - accuracy: 0.5674 - loss: 0.9575 - val_accuracy: 0.6099 - val_loss: 0.8723\n",
            "Epoch 88/300\n",
            "14/14 - 144s - 10s/step - accuracy: 0.5650 - loss: 0.9742 - val_accuracy: 0.6154 - val_loss: 0.8715\n",
            "Epoch 89/300\n",
            "14/14 - 185s - 13s/step - accuracy: 0.5248 - loss: 0.9542 - val_accuracy: 0.6099 - val_loss: 0.8707\n",
            "Epoch 90/300\n",
            "14/14 - 141s - 10s/step - accuracy: 0.6076 - loss: 0.9109 - val_accuracy: 0.6099 - val_loss: 0.8704\n",
            "Epoch 91/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.5532 - loss: 0.9695 - val_accuracy: 0.6154 - val_loss: 0.8692\n",
            "Epoch 92/300\n",
            "14/14 - 148s - 11s/step - accuracy: 0.6052 - loss: 0.8984 - val_accuracy: 0.6209 - val_loss: 0.8685\n",
            "Epoch 93/300\n",
            "14/14 - 185s - 13s/step - accuracy: 0.5934 - loss: 0.8829 - val_accuracy: 0.6264 - val_loss: 0.8669\n",
            "Epoch 94/300\n",
            "14/14 - 184s - 13s/step - accuracy: 0.6028 - loss: 0.9105 - val_accuracy: 0.6209 - val_loss: 0.8649\n",
            "Epoch 95/300\n",
            "14/14 - 164s - 12s/step - accuracy: 0.5887 - loss: 0.8655 - val_accuracy: 0.6209 - val_loss: 0.8633\n",
            "Epoch 96/300\n",
            "14/14 - 142s - 10s/step - accuracy: 0.6005 - loss: 0.8546 - val_accuracy: 0.6319 - val_loss: 0.8611\n",
            "Epoch 97/300\n",
            "14/14 - 201s - 14s/step - accuracy: 0.5603 - loss: 0.9122 - val_accuracy: 0.6374 - val_loss: 0.8598\n",
            "Epoch 98/300\n",
            "14/14 - 140s - 10s/step - accuracy: 0.6028 - loss: 0.8987 - val_accuracy: 0.6319 - val_loss: 0.8582\n",
            "Epoch 99/300\n",
            "14/14 - 180s - 13s/step - accuracy: 0.5934 - loss: 0.8923 - val_accuracy: 0.6374 - val_loss: 0.8577\n",
            "Epoch 100/300\n",
            "14/14 - 140s - 10s/step - accuracy: 0.5839 - loss: 0.9063 - val_accuracy: 0.6374 - val_loss: 0.8576\n",
            "Epoch 101/300\n",
            "14/14 - 142s - 10s/step - accuracy: 0.6170 - loss: 0.8622 - val_accuracy: 0.6264 - val_loss: 0.8560\n",
            "Epoch 102/300\n",
            "14/14 - 140s - 10s/step - accuracy: 0.5816 - loss: 0.9216 - val_accuracy: 0.6374 - val_loss: 0.8558\n",
            "Epoch 103/300\n",
            "14/14 - 143s - 10s/step - accuracy: 0.5839 - loss: 0.8967 - val_accuracy: 0.6319 - val_loss: 0.8560\n",
            "Epoch 104/300\n",
            "14/14 - 139s - 10s/step - accuracy: 0.5910 - loss: 0.8931 - val_accuracy: 0.6319 - val_loss: 0.8551\n",
            "Epoch 105/300\n",
            "14/14 - 181s - 13s/step - accuracy: 0.5674 - loss: 0.9168 - val_accuracy: 0.6319 - val_loss: 0.8552\n",
            "Epoch 106/300\n",
            "14/14 - 141s - 10s/step - accuracy: 0.6052 - loss: 0.8672 - val_accuracy: 0.6374 - val_loss: 0.8546\n",
            "Epoch 107/300\n",
            "14/14 - 141s - 10s/step - accuracy: 0.5697 - loss: 0.9269 - val_accuracy: 0.6484 - val_loss: 0.8540\n",
            "Epoch 108/300\n",
            "14/14 - 183s - 13s/step - accuracy: 0.5981 - loss: 0.8800 - val_accuracy: 0.6374 - val_loss: 0.8535\n",
            "Epoch 109/300\n",
            "14/14 - 139s - 10s/step - accuracy: 0.5934 - loss: 0.8929 - val_accuracy: 0.6484 - val_loss: 0.8526\n",
            "Epoch 110/300\n",
            "14/14 - 144s - 10s/step - accuracy: 0.5981 - loss: 0.8864 - val_accuracy: 0.6538 - val_loss: 0.8528\n",
            "Epoch 111/300\n",
            "14/14 - 140s - 10s/step - accuracy: 0.6099 - loss: 0.8766 - val_accuracy: 0.6593 - val_loss: 0.8506\n",
            "Epoch 112/300\n",
            "14/14 - 140s - 10s/step - accuracy: 0.6359 - loss: 0.8304 - val_accuracy: 0.6429 - val_loss: 0.8490\n",
            "Epoch 113/300\n",
            "14/14 - 145s - 10s/step - accuracy: 0.6217 - loss: 0.8560 - val_accuracy: 0.6484 - val_loss: 0.8470\n",
            "Epoch 114/300\n",
            "14/14 - 139s - 10s/step - accuracy: 0.6478 - loss: 0.8555 - val_accuracy: 0.6374 - val_loss: 0.8453\n",
            "Epoch 115/300\n",
            "14/14 - 143s - 10s/step - accuracy: 0.6099 - loss: 0.8621 - val_accuracy: 0.6484 - val_loss: 0.8442\n",
            "Epoch 116/300\n",
            "14/14 - 141s - 10s/step - accuracy: 0.5792 - loss: 0.8845 - val_accuracy: 0.6538 - val_loss: 0.8440\n",
            "Epoch 117/300\n",
            "14/14 - 143s - 10s/step - accuracy: 0.5910 - loss: 0.8729 - val_accuracy: 0.6593 - val_loss: 0.8433\n",
            "Epoch 118/300\n",
            "14/14 - 140s - 10s/step - accuracy: 0.6147 - loss: 0.8902 - val_accuracy: 0.6648 - val_loss: 0.8424\n",
            "Epoch 119/300\n",
            "14/14 - 140s - 10s/step - accuracy: 0.5910 - loss: 0.8756 - val_accuracy: 0.6538 - val_loss: 0.8407\n",
            "Epoch 120/300\n",
            "14/14 - 140s - 10s/step - accuracy: 0.5626 - loss: 0.8923 - val_accuracy: 0.6593 - val_loss: 0.8397\n",
            "Epoch 121/300\n",
            "14/14 - 142s - 10s/step - accuracy: 0.6099 - loss: 0.8492 - val_accuracy: 0.6538 - val_loss: 0.8388\n",
            "Epoch 122/300\n",
            "14/14 - 182s - 13s/step - accuracy: 0.6454 - loss: 0.8352 - val_accuracy: 0.6538 - val_loss: 0.8367\n",
            "Epoch 123/300\n",
            "14/14 - 143s - 10s/step - accuracy: 0.6194 - loss: 0.8556 - val_accuracy: 0.6593 - val_loss: 0.8347\n",
            "Epoch 124/300\n",
            "14/14 - 201s - 14s/step - accuracy: 0.6123 - loss: 0.8659 - val_accuracy: 0.6538 - val_loss: 0.8343\n",
            "Epoch 125/300\n",
            "14/14 - 142s - 10s/step - accuracy: 0.6028 - loss: 0.8798 - val_accuracy: 0.6538 - val_loss: 0.8341\n",
            "Epoch 126/300\n",
            "14/14 - 142s - 10s/step - accuracy: 0.6170 - loss: 0.8672 - val_accuracy: 0.6593 - val_loss: 0.8336\n",
            "Epoch 127/300\n",
            "14/14 - 179s - 13s/step - accuracy: 0.6123 - loss: 0.9037 - val_accuracy: 0.6538 - val_loss: 0.8337\n",
            "Epoch 128/300\n",
            "14/14 - 181s - 13s/step - accuracy: 0.6028 - loss: 0.8802 - val_accuracy: 0.6429 - val_loss: 0.8342\n",
            "Epoch 129/300\n",
            "14/14 - 139s - 10s/step - accuracy: 0.5792 - loss: 0.9219 - val_accuracy: 0.6319 - val_loss: 0.8338\n",
            "Epoch 130/300\n",
            "14/14 - 142s - 10s/step - accuracy: 0.5887 - loss: 0.8787 - val_accuracy: 0.6429 - val_loss: 0.8321\n",
            "Epoch 131/300\n",
            "14/14 - 184s - 13s/step - accuracy: 0.5981 - loss: 0.8604 - val_accuracy: 0.6319 - val_loss: 0.8309\n",
            "Epoch 132/300\n",
            "14/14 - 142s - 10s/step - accuracy: 0.5981 - loss: 0.8664 - val_accuracy: 0.6374 - val_loss: 0.8297\n",
            "Epoch 133/300\n",
            "14/14 - 182s - 13s/step - accuracy: 0.6076 - loss: 0.8500 - val_accuracy: 0.6484 - val_loss: 0.8300\n",
            "Epoch 134/300\n",
            "14/14 - 141s - 10s/step - accuracy: 0.5863 - loss: 0.8782 - val_accuracy: 0.6484 - val_loss: 0.8288\n",
            "Epoch 135/300\n",
            "14/14 - 142s - 10s/step - accuracy: 0.6217 - loss: 0.8358 - val_accuracy: 0.6484 - val_loss: 0.8276\n",
            "Epoch 136/300\n",
            "14/14 - 139s - 10s/step - accuracy: 0.6170 - loss: 0.8301 - val_accuracy: 0.6538 - val_loss: 0.8245\n",
            "Epoch 137/300\n",
            "14/14 - 142s - 10s/step - accuracy: 0.6147 - loss: 0.8239 - val_accuracy: 0.6538 - val_loss: 0.8236\n",
            "Epoch 138/300\n",
            "14/14 - 139s - 10s/step - accuracy: 0.6407 - loss: 0.8427 - val_accuracy: 0.6593 - val_loss: 0.8223\n",
            "Epoch 139/300\n",
            "14/14 - 143s - 10s/step - accuracy: 0.6265 - loss: 0.8513 - val_accuracy: 0.6593 - val_loss: 0.8202\n",
            "Epoch 140/300\n",
            "14/14 - 182s - 13s/step - accuracy: 0.6147 - loss: 0.8402 - val_accuracy: 0.6758 - val_loss: 0.8173\n",
            "Epoch 141/300\n",
            "14/14 - 141s - 10s/step - accuracy: 0.5674 - loss: 0.9115 - val_accuracy: 0.6758 - val_loss: 0.8154\n",
            "Epoch 142/300\n",
            "14/14 - 143s - 10s/step - accuracy: 0.6052 - loss: 0.8606 - val_accuracy: 0.6813 - val_loss: 0.8135\n",
            "Epoch 143/300\n",
            "14/14 - 141s - 10s/step - accuracy: 0.6147 - loss: 0.8212 - val_accuracy: 0.6758 - val_loss: 0.8102\n",
            "Epoch 144/300\n",
            "14/14 - 140s - 10s/step - accuracy: 0.6028 - loss: 0.8761 - val_accuracy: 0.6758 - val_loss: 0.8089\n",
            "Epoch 145/300\n",
            "14/14 - 140s - 10s/step - accuracy: 0.6076 - loss: 0.8614 - val_accuracy: 0.6648 - val_loss: 0.8073\n",
            "Epoch 146/300\n",
            "14/14 - 182s - 13s/step - accuracy: 0.6147 - loss: 0.8155 - val_accuracy: 0.6648 - val_loss: 0.8076\n",
            "Epoch 147/300\n",
            "14/14 - 140s - 10s/step - accuracy: 0.6170 - loss: 0.8706 - val_accuracy: 0.6758 - val_loss: 0.8071\n",
            "Epoch 148/300\n",
            "14/14 - 139s - 10s/step - accuracy: 0.5957 - loss: 0.8609 - val_accuracy: 0.6703 - val_loss: 0.8076\n",
            "Epoch 149/300\n",
            "14/14 - 140s - 10s/step - accuracy: 0.6170 - loss: 0.8427 - val_accuracy: 0.6703 - val_loss: 0.8067\n",
            "Epoch 150/300\n",
            "14/14 - 182s - 13s/step - accuracy: 0.6454 - loss: 0.8464 - val_accuracy: 0.6703 - val_loss: 0.8056\n",
            "Epoch 151/300\n",
            "14/14 - 164s - 12s/step - accuracy: 0.6005 - loss: 0.8648 - val_accuracy: 0.6813 - val_loss: 0.8053\n",
            "Epoch 152/300\n",
            "14/14 - 139s - 10s/step - accuracy: 0.5934 - loss: 0.8696 - val_accuracy: 0.6868 - val_loss: 0.8054\n",
            "Epoch 153/300\n",
            "14/14 - 142s - 10s/step - accuracy: 0.6170 - loss: 0.8445 - val_accuracy: 0.6868 - val_loss: 0.8048\n",
            "Epoch 154/300\n",
            "14/14 - 140s - 10s/step - accuracy: 0.6288 - loss: 0.8164 - val_accuracy: 0.6923 - val_loss: 0.8046\n",
            "Epoch 155/300\n",
            "14/14 - 142s - 10s/step - accuracy: 0.6407 - loss: 0.8119 - val_accuracy: 0.6868 - val_loss: 0.8044\n",
            "Epoch 156/300\n",
            "14/14 - 140s - 10s/step - accuracy: 0.6076 - loss: 0.8407 - val_accuracy: 0.6923 - val_loss: 0.8041\n",
            "Epoch 157/300\n",
            "14/14 - 143s - 10s/step - accuracy: 0.6643 - loss: 0.8263 - val_accuracy: 0.6868 - val_loss: 0.8029\n",
            "Epoch 158/300\n",
            "14/14 - 199s - 14s/step - accuracy: 0.5887 - loss: 0.8528 - val_accuracy: 0.6813 - val_loss: 0.8025\n",
            "Epoch 159/300\n",
            "14/14 - 143s - 10s/step - accuracy: 0.6478 - loss: 0.7995 - val_accuracy: 0.6813 - val_loss: 0.8016\n",
            "Epoch 160/300\n",
            "14/14 - 141s - 10s/step - accuracy: 0.6217 - loss: 0.8595 - val_accuracy: 0.6813 - val_loss: 0.7996\n",
            "Epoch 161/300\n",
            "14/14 - 182s - 13s/step - accuracy: 0.6407 - loss: 0.7894 - val_accuracy: 0.6868 - val_loss: 0.7994\n",
            "Epoch 162/300\n",
            "14/14 - 139s - 10s/step - accuracy: 0.6643 - loss: 0.7890 - val_accuracy: 0.6813 - val_loss: 0.7978\n",
            "Epoch 163/300\n",
            "14/14 - 140s - 10s/step - accuracy: 0.5887 - loss: 0.8609 - val_accuracy: 0.6923 - val_loss: 0.7961\n",
            "Epoch 164/300\n",
            "14/14 - 141s - 10s/step - accuracy: 0.6123 - loss: 0.8568 - val_accuracy: 0.6923 - val_loss: 0.7942\n",
            "Epoch 165/300\n",
            "14/14 - 142s - 10s/step - accuracy: 0.6359 - loss: 0.8435 - val_accuracy: 0.6923 - val_loss: 0.7919\n",
            "Epoch 166/300\n",
            "14/14 - 140s - 10s/step - accuracy: 0.6501 - loss: 0.8076 - val_accuracy: 0.6868 - val_loss: 0.7909\n",
            "Epoch 167/300\n",
            "14/14 - 142s - 10s/step - accuracy: 0.6194 - loss: 0.8283 - val_accuracy: 0.6758 - val_loss: 0.7917\n",
            "Epoch 168/300\n",
            "14/14 - 181s - 13s/step - accuracy: 0.6478 - loss: 0.8406 - val_accuracy: 0.6813 - val_loss: 0.7902\n",
            "Epoch 169/300\n",
            "14/14 - 139s - 10s/step - accuracy: 0.6147 - loss: 0.8570 - val_accuracy: 0.6813 - val_loss: 0.7904\n",
            "Epoch 170/300\n",
            "14/14 - 145s - 10s/step - accuracy: 0.6714 - loss: 0.7798 - val_accuracy: 0.6923 - val_loss: 0.7897\n",
            "Epoch 171/300\n",
            "14/14 - 142s - 10s/step - accuracy: 0.6217 - loss: 0.8173 - val_accuracy: 0.6923 - val_loss: 0.7877\n",
            "Epoch 172/300\n",
            "14/14 - 140s - 10s/step - accuracy: 0.6076 - loss: 0.8566 - val_accuracy: 0.6758 - val_loss: 0.7863\n",
            "Epoch 173/300\n",
            "14/14 - 141s - 10s/step - accuracy: 0.6123 - loss: 0.8330 - val_accuracy: 0.6758 - val_loss: 0.7855\n",
            "Epoch 174/300\n",
            "14/14 - 182s - 13s/step - accuracy: 0.6359 - loss: 0.8334 - val_accuracy: 0.6758 - val_loss: 0.7841\n",
            "Epoch 175/300\n",
            "14/14 - 142s - 10s/step - accuracy: 0.6501 - loss: 0.8120 - val_accuracy: 0.6758 - val_loss: 0.7830\n",
            "Epoch 176/300\n",
            "14/14 - 141s - 10s/step - accuracy: 0.6076 - loss: 0.8599 - val_accuracy: 0.6813 - val_loss: 0.7826\n",
            "Epoch 177/300\n",
            "14/14 - 144s - 10s/step - accuracy: 0.6123 - loss: 0.8068 - val_accuracy: 0.6813 - val_loss: 0.7811\n",
            "Epoch 178/300\n",
            "14/14 - 200s - 14s/step - accuracy: 0.5981 - loss: 0.8664 - val_accuracy: 0.6868 - val_loss: 0.7807\n",
            "Epoch 179/300\n"
          ]
        }
      ],
      "source": [
        "split_ratio = 0.7\n",
        "split_percent = round(split_ratio * 100)\n",
        "\n",
        "for lr in [0.0001]:\n",
        "    for epoch in [300]:\n",
        "        print(f\"\\n📦 Training model dengan split_ratio={split_percent}%, learning_rate={lr}, epochs={epoch}\")\n",
        "\n",
        "        model, history = train_model(\n",
        "            split_ratio=split_ratio,\n",
        "            lr=lr,\n",
        "            epochs=epoch\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "721Tm1yttEKu",
      "metadata": {
        "id": "721Tm1yttEKu"
      },
      "source": [
        "###Split ratio 0.8 Learning rate 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "n4sum3cmRKXZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4sum3cmRKXZ",
        "outputId": "b8bca102-4986-48e4-e581-8b26f9b9e5ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📦 Training model dengan split_ratio=80%, learning_rate=0.001, epochs=50\n",
            "Found 484 images belonging to 3 classes.\n",
            "Found 121 images belonging to 3 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "16/16 - 150s - 9s/step - accuracy: 0.3388 - loss: 1.7727 - val_accuracy: 0.4463 - val_loss: 1.0581\n",
            "Epoch 2/50\n",
            "16/16 - 140s - 9s/step - accuracy: 0.4380 - loss: 1.2958 - val_accuracy: 0.5620 - val_loss: 0.9374\n",
            "Epoch 3/50\n",
            "16/16 - 135s - 8s/step - accuracy: 0.4545 - loss: 1.1474 - val_accuracy: 0.6116 - val_loss: 0.9040\n",
            "Epoch 4/50\n",
            "16/16 - 134s - 8s/step - accuracy: 0.4752 - loss: 1.1263 - val_accuracy: 0.6198 - val_loss: 0.9011\n",
            "Epoch 5/50\n",
            "16/16 - 134s - 8s/step - accuracy: 0.5021 - loss: 1.0430 - val_accuracy: 0.6281 - val_loss: 0.8962\n",
            "Epoch 6/50\n",
            "16/16 - 137s - 9s/step - accuracy: 0.5248 - loss: 1.0171 - val_accuracy: 0.6281 - val_loss: 0.8989\n",
            "Epoch 7/50\n",
            "16/16 - 136s - 8s/step - accuracy: 0.5372 - loss: 0.9928 - val_accuracy: 0.5785 - val_loss: 0.8901\n",
            "Epoch 8/50\n",
            "16/16 - 133s - 8s/step - accuracy: 0.5331 - loss: 0.9739 - val_accuracy: 0.6612 - val_loss: 0.8654\n",
            "Epoch 9/50\n",
            "16/16 - 148s - 9s/step - accuracy: 0.5579 - loss: 0.9430 - val_accuracy: 0.6364 - val_loss: 0.8588\n",
            "Epoch 10/50\n",
            "16/16 - 148s - 9s/step - accuracy: 0.5372 - loss: 0.9793 - val_accuracy: 0.6612 - val_loss: 0.8415\n",
            "Epoch 11/50\n",
            "16/16 - 134s - 8s/step - accuracy: 0.5723 - loss: 0.9465 - val_accuracy: 0.6694 - val_loss: 0.8478\n",
            "Epoch 12/50\n",
            "16/16 - 132s - 8s/step - accuracy: 0.5868 - loss: 0.9298 - val_accuracy: 0.6694 - val_loss: 0.8512\n",
            "Epoch 13/50\n",
            "16/16 - 133s - 8s/step - accuracy: 0.5723 - loss: 0.8848 - val_accuracy: 0.6694 - val_loss: 0.8385\n",
            "Epoch 14/50\n",
            "16/16 - 149s - 9s/step - accuracy: 0.5702 - loss: 0.9252 - val_accuracy: 0.6777 - val_loss: 0.8118\n",
            "Epoch 15/50\n",
            "16/16 - 139s - 9s/step - accuracy: 0.5806 - loss: 0.9190 - val_accuracy: 0.6281 - val_loss: 0.8063\n",
            "Epoch 16/50\n",
            "16/16 - 149s - 9s/step - accuracy: 0.6033 - loss: 0.8714 - val_accuracy: 0.6777 - val_loss: 0.7923\n",
            "Epoch 17/50\n",
            "16/16 - 133s - 8s/step - accuracy: 0.5992 - loss: 0.9027 - val_accuracy: 0.6777 - val_loss: 0.7799\n",
            "Epoch 18/50\n",
            "16/16 - 147s - 9s/step - accuracy: 0.5888 - loss: 0.8751 - val_accuracy: 0.6777 - val_loss: 0.7802\n",
            "Epoch 19/50\n",
            "16/16 - 139s - 9s/step - accuracy: 0.6260 - loss: 0.8454 - val_accuracy: 0.6860 - val_loss: 0.7613\n",
            "Epoch 20/50\n",
            "16/16 - 150s - 9s/step - accuracy: 0.6054 - loss: 0.8672 - val_accuracy: 0.6860 - val_loss: 0.7557\n",
            "Epoch 21/50\n",
            "16/16 - 133s - 8s/step - accuracy: 0.5806 - loss: 0.8931 - val_accuracy: 0.7355 - val_loss: 0.7440\n",
            "Epoch 22/50\n",
            "16/16 - 132s - 8s/step - accuracy: 0.6033 - loss: 0.8519 - val_accuracy: 0.6942 - val_loss: 0.7325\n",
            "Epoch 23/50\n",
            "16/16 - 134s - 8s/step - accuracy: 0.6116 - loss: 0.8750 - val_accuracy: 0.7190 - val_loss: 0.7288\n",
            "Epoch 24/50\n",
            "16/16 - 155s - 10s/step - accuracy: 0.6529 - loss: 0.8027 - val_accuracy: 0.7190 - val_loss: 0.7218\n",
            "Epoch 25/50\n",
            "16/16 - 133s - 8s/step - accuracy: 0.6591 - loss: 0.8255 - val_accuracy: 0.7107 - val_loss: 0.7120\n",
            "Epoch 26/50\n",
            "16/16 - 134s - 8s/step - accuracy: 0.6157 - loss: 0.8634 - val_accuracy: 0.7190 - val_loss: 0.7138\n",
            "Epoch 27/50\n",
            "16/16 - 150s - 9s/step - accuracy: 0.6426 - loss: 0.8476 - val_accuracy: 0.6942 - val_loss: 0.7110\n",
            "Epoch 28/50\n",
            "16/16 - 185s - 12s/step - accuracy: 0.6198 - loss: 0.8212 - val_accuracy: 0.7190 - val_loss: 0.6984\n",
            "Epoch 29/50\n",
            "16/16 - 147s - 9s/step - accuracy: 0.6178 - loss: 0.8204 - val_accuracy: 0.7355 - val_loss: 0.7045\n",
            "Epoch 30/50\n",
            "16/16 - 203s - 13s/step - accuracy: 0.6343 - loss: 0.8122 - val_accuracy: 0.7686 - val_loss: 0.6941\n",
            "Epoch 31/50\n",
            "16/16 - 134s - 8s/step - accuracy: 0.6240 - loss: 0.8020 - val_accuracy: 0.7190 - val_loss: 0.6871\n",
            "Epoch 32/50\n",
            "16/16 - 133s - 8s/step - accuracy: 0.6674 - loss: 0.7771 - val_accuracy: 0.7273 - val_loss: 0.6768\n",
            "Epoch 33/50\n",
            "16/16 - 133s - 8s/step - accuracy: 0.6508 - loss: 0.7902 - val_accuracy: 0.7521 - val_loss: 0.6600\n",
            "Epoch 34/50\n",
            "16/16 - 134s - 8s/step - accuracy: 0.6384 - loss: 0.8276 - val_accuracy: 0.7355 - val_loss: 0.6565\n",
            "Epoch 35/50\n",
            "16/16 - 134s - 8s/step - accuracy: 0.6756 - loss: 0.7918 - val_accuracy: 0.7769 - val_loss: 0.6476\n",
            "Epoch 36/50\n",
            "16/16 - 142s - 9s/step - accuracy: 0.6818 - loss: 0.7580 - val_accuracy: 0.7603 - val_loss: 0.6524\n",
            "Epoch 37/50\n",
            "16/16 - 133s - 8s/step - accuracy: 0.6550 - loss: 0.7603 - val_accuracy: 0.7438 - val_loss: 0.6590\n",
            "Epoch 38/50\n",
            "16/16 - 133s - 8s/step - accuracy: 0.6508 - loss: 0.7836 - val_accuracy: 0.7851 - val_loss: 0.6372\n",
            "Epoch 39/50\n",
            "16/16 - 142s - 9s/step - accuracy: 0.6653 - loss: 0.7487 - val_accuracy: 0.7521 - val_loss: 0.6458\n",
            "Epoch 40/50\n",
            "16/16 - 133s - 8s/step - accuracy: 0.6219 - loss: 0.7983 - val_accuracy: 0.7851 - val_loss: 0.6600\n",
            "Epoch 41/50\n",
            "16/16 - 149s - 9s/step - accuracy: 0.6488 - loss: 0.7909 - val_accuracy: 0.8017 - val_loss: 0.6445\n",
            "Epoch 42/50\n",
            "16/16 - 135s - 8s/step - accuracy: 0.6715 - loss: 0.7765 - val_accuracy: 0.7273 - val_loss: 0.6547\n",
            "Epoch 43/50\n",
            "16/16 - 147s - 9s/step - accuracy: 0.6632 - loss: 0.7652 - val_accuracy: 0.7273 - val_loss: 0.6645\n",
            "Epoch 44/50\n",
            "16/16 - 133s - 8s/step - accuracy: 0.7066 - loss: 0.7298 - val_accuracy: 0.7355 - val_loss: 0.6569\n",
            "Epoch 45/50\n",
            "16/16 - 156s - 10s/step - accuracy: 0.6529 - loss: 0.7567 - val_accuracy: 0.7355 - val_loss: 0.6421\n",
            "Epoch 46/50\n",
            "16/16 - 149s - 9s/step - accuracy: 0.6591 - loss: 0.7845 - val_accuracy: 0.7603 - val_loss: 0.6355\n",
            "Epoch 47/50\n",
            "16/16 - 187s - 12s/step - accuracy: 0.6736 - loss: 0.7644 - val_accuracy: 0.7438 - val_loss: 0.6550\n",
            "Epoch 48/50\n",
            "16/16 - 134s - 8s/step - accuracy: 0.6715 - loss: 0.7567 - val_accuracy: 0.7355 - val_loss: 0.6535\n",
            "Epoch 49/50\n",
            "16/16 - 133s - 8s/step - accuracy: 0.6880 - loss: 0.7468 - val_accuracy: 0.7686 - val_loss: 0.6422\n",
            "Epoch 50/50\n",
            "16/16 - 149s - 9s/step - accuracy: 0.6921 - loss: 0.7501 - val_accuracy: 0.8017 - val_loss: 0.6271\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model berhasil disimpan: model_split80_lr0.001_ep50_l20.0001.h5\n"
          ]
        }
      ],
      "source": [
        "split_ratio = 0.8\n",
        "split_percent = round(split_ratio * 100)\n",
        "\n",
        "for lr in [0.001]:\n",
        "    for epoch in [50]:\n",
        "        print(f\"\\n📦 Training model dengan split_ratio={split_percent}%, learning_rate={lr}, epochs={epoch}\")\n",
        "\n",
        "        model, history = train_model(\n",
        "            split_ratio=split_ratio,\n",
        "            lr=lr,\n",
        "            epochs=epoch\n",
        "        )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6wF8W9M-RIt1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wF8W9M-RIt1",
        "outputId": "30d6ff99-1d36-4e1d-c4dc-0d8d61506457"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📦 Training model dengan split_ratio=80%, learning_rate=0.001, epochs=100\n",
            "Found 484 images belonging to 3 classes.\n",
            "Found 121 images belonging to 3 classes.\n",
            "Epoch 1/100\n",
            "16/16 - 153s - 10s/step - accuracy: 0.3616 - loss: 1.7848 - val_accuracy: 0.4463 - val_loss: 1.0599\n",
            "Epoch 2/100\n",
            "16/16 - 135s - 8s/step - accuracy: 0.4649 - loss: 1.2651 - val_accuracy: 0.6033 - val_loss: 0.9432\n",
            "Epoch 3/100\n",
            "16/16 - 140s - 9s/step - accuracy: 0.4525 - loss: 1.2494 - val_accuracy: 0.5868 - val_loss: 0.9509\n",
            "Epoch 4/100\n",
            "16/16 - 148s - 9s/step - accuracy: 0.5165 - loss: 1.0506 - val_accuracy: 0.5868 - val_loss: 0.9422\n",
            "Epoch 5/100\n",
            "16/16 - 134s - 8s/step - accuracy: 0.4938 - loss: 1.0294 - val_accuracy: 0.6364 - val_loss: 0.9288\n",
            "Epoch 6/100\n",
            "16/16 - 149s - 9s/step - accuracy: 0.4897 - loss: 1.0023 - val_accuracy: 0.6446 - val_loss: 0.9098\n",
            "Epoch 7/100\n",
            "16/16 - 133s - 8s/step - accuracy: 0.5434 - loss: 0.9405 - val_accuracy: 0.6777 - val_loss: 0.9063\n",
            "Epoch 8/100\n",
            "16/16 - 133s - 8s/step - accuracy: 0.5145 - loss: 1.0136 - val_accuracy: 0.6529 - val_loss: 0.9124\n",
            "Epoch 9/100\n",
            "16/16 - 148s - 9s/step - accuracy: 0.5579 - loss: 0.9494 - val_accuracy: 0.6612 - val_loss: 0.8965\n",
            "Epoch 10/100\n",
            "16/16 - 133s - 8s/step - accuracy: 0.5248 - loss: 0.9903 - val_accuracy: 0.6281 - val_loss: 0.8842\n",
            "Epoch 11/100\n",
            "16/16 - 133s - 8s/step - accuracy: 0.5723 - loss: 0.9400 - val_accuracy: 0.6529 - val_loss: 0.8806\n",
            "Epoch 12/100\n",
            "16/16 - 149s - 9s/step - accuracy: 0.5723 - loss: 0.9300 - val_accuracy: 0.6198 - val_loss: 0.8788\n",
            "Epoch 13/100\n",
            "16/16 - 133s - 8s/step - accuracy: 0.5723 - loss: 0.9152 - val_accuracy: 0.6116 - val_loss: 0.8715\n",
            "Epoch 14/100\n",
            "16/16 - 133s - 8s/step - accuracy: 0.5579 - loss: 0.9250 - val_accuracy: 0.6364 - val_loss: 0.8287\n",
            "Epoch 15/100\n",
            "16/16 - 133s - 8s/step - accuracy: 0.5806 - loss: 0.9159 - val_accuracy: 0.6364 - val_loss: 0.8111\n",
            "Epoch 16/100\n",
            "16/16 - 134s - 8s/step - accuracy: 0.5806 - loss: 0.8866 - val_accuracy: 0.6612 - val_loss: 0.8082\n",
            "Epoch 17/100\n",
            "16/16 - 147s - 9s/step - accuracy: 0.5806 - loss: 0.8868 - val_accuracy: 0.6777 - val_loss: 0.7985\n",
            "Epoch 18/100\n",
            "16/16 - 134s - 8s/step - accuracy: 0.5971 - loss: 0.8555 - val_accuracy: 0.6942 - val_loss: 0.7837\n",
            "Epoch 19/100\n",
            "16/16 - 133s - 8s/step - accuracy: 0.6384 - loss: 0.8537 - val_accuracy: 0.7107 - val_loss: 0.7639\n",
            "Epoch 20/100\n",
            "16/16 - 133s - 8s/step - accuracy: 0.5806 - loss: 0.9018 - val_accuracy: 0.7190 - val_loss: 0.7555\n",
            "Epoch 21/100\n",
            "16/16 - 133s - 8s/step - accuracy: 0.6281 - loss: 0.8240 - val_accuracy: 0.7107 - val_loss: 0.7570\n",
            "Epoch 22/100\n",
            "16/16 - 142s - 9s/step - accuracy: 0.6364 - loss: 0.7922 - val_accuracy: 0.7190 - val_loss: 0.7511\n",
            "Epoch 23/100\n",
            "16/16 - 135s - 8s/step - accuracy: 0.6054 - loss: 0.8469 - val_accuracy: 0.6942 - val_loss: 0.7498\n",
            "Epoch 24/100\n",
            "16/16 - 134s - 8s/step - accuracy: 0.5971 - loss: 0.8573 - val_accuracy: 0.7273 - val_loss: 0.7426\n",
            "Epoch 25/100\n",
            "16/16 - 133s - 8s/step - accuracy: 0.6198 - loss: 0.8635 - val_accuracy: 0.7273 - val_loss: 0.7414\n",
            "Epoch 26/100\n",
            "16/16 - 150s - 9s/step - accuracy: 0.6198 - loss: 0.8360 - val_accuracy: 0.6942 - val_loss: 0.7443\n",
            "Epoch 27/100\n",
            "16/16 - 134s - 8s/step - accuracy: 0.6136 - loss: 0.8555 - val_accuracy: 0.6612 - val_loss: 0.7412\n",
            "Epoch 28/100\n",
            "16/16 - 134s - 8s/step - accuracy: 0.5909 - loss: 0.8554 - val_accuracy: 0.7025 - val_loss: 0.7345\n",
            "Epoch 29/100\n",
            "16/16 - 133s - 8s/step - accuracy: 0.6178 - loss: 0.8652 - val_accuracy: 0.6860 - val_loss: 0.7460\n",
            "Epoch 30/100\n",
            "16/16 - 133s - 8s/step - accuracy: 0.6570 - loss: 0.8268 - val_accuracy: 0.6860 - val_loss: 0.7442\n",
            "Epoch 31/100\n",
            "16/16 - 142s - 9s/step - accuracy: 0.6426 - loss: 0.8238 - val_accuracy: 0.6860 - val_loss: 0.7336\n",
            "Epoch 32/100\n",
            "16/16 - 134s - 8s/step - accuracy: 0.6074 - loss: 0.8532 - val_accuracy: 0.7521 - val_loss: 0.7347\n",
            "Epoch 33/100\n",
            "16/16 - 142s - 9s/step - accuracy: 0.6467 - loss: 0.7990 - val_accuracy: 0.7107 - val_loss: 0.7167\n",
            "Epoch 34/100\n",
            "16/16 - 134s - 8s/step - accuracy: 0.6508 - loss: 0.7704 - val_accuracy: 0.7355 - val_loss: 0.7025\n",
            "Epoch 35/100\n",
            "16/16 - 133s - 8s/step - accuracy: 0.6591 - loss: 0.7704 - val_accuracy: 0.7521 - val_loss: 0.6833\n",
            "Epoch 36/100\n",
            "16/16 - 133s - 8s/step - accuracy: 0.6426 - loss: 0.7821 - val_accuracy: 0.7273 - val_loss: 0.6846\n",
            "Epoch 37/100\n",
            "16/16 - 132s - 8s/step - accuracy: 0.6674 - loss: 0.7740 - val_accuracy: 0.7603 - val_loss: 0.6679\n",
            "Epoch 38/100\n",
            "16/16 - 149s - 9s/step - accuracy: 0.7004 - loss: 0.7409 - val_accuracy: 0.7438 - val_loss: 0.6622\n",
            "Epoch 39/100\n",
            "16/16 - 133s - 8s/step - accuracy: 0.6322 - loss: 0.8204 - val_accuracy: 0.7686 - val_loss: 0.6514\n",
            "Epoch 40/100\n",
            "16/16 - 147s - 9s/step - accuracy: 0.6632 - loss: 0.7438 - val_accuracy: 0.7603 - val_loss: 0.6615\n",
            "Epoch 41/100\n",
            "16/16 - 134s - 8s/step - accuracy: 0.6798 - loss: 0.7810 - val_accuracy: 0.7438 - val_loss: 0.6704\n",
            "Epoch 42/100\n",
            "16/16 - 133s - 8s/step - accuracy: 0.6488 - loss: 0.7400 - val_accuracy: 0.7686 - val_loss: 0.6626\n",
            "Epoch 43/100\n",
            "16/16 - 150s - 9s/step - accuracy: 0.7107 - loss: 0.7404 - val_accuracy: 0.7355 - val_loss: 0.6656\n",
            "Epoch 44/100\n",
            "16/16 - 134s - 8s/step - accuracy: 0.6446 - loss: 0.7818 - val_accuracy: 0.7107 - val_loss: 0.6651\n",
            "Epoch 45/100\n",
            "16/16 - 133s - 8s/step - accuracy: 0.6818 - loss: 0.7583 - val_accuracy: 0.7521 - val_loss: 0.6563\n",
            "Epoch 46/100\n",
            "16/16 - 132s - 8s/step - accuracy: 0.6674 - loss: 0.7600 - val_accuracy: 0.7355 - val_loss: 0.6715\n",
            "Epoch 47/100\n",
            "16/16 - 148s - 9s/step - accuracy: 0.6798 - loss: 0.7404 - val_accuracy: 0.7190 - val_loss: 0.6712\n",
            "Epoch 48/100\n",
            "16/16 - 146s - 9s/step - accuracy: 0.6467 - loss: 0.7616 - val_accuracy: 0.7769 - val_loss: 0.6278\n",
            "Epoch 49/100\n",
            "16/16 - 132s - 8s/step - accuracy: 0.6736 - loss: 0.7371 - val_accuracy: 0.7025 - val_loss: 0.6713\n",
            "Epoch 50/100\n",
            "16/16 - 147s - 9s/step - accuracy: 0.6529 - loss: 0.7612 - val_accuracy: 0.7190 - val_loss: 0.6574\n",
            "Epoch 51/100\n",
            "16/16 - 133s - 8s/step - accuracy: 0.6942 - loss: 0.7179 - val_accuracy: 0.7603 - val_loss: 0.6352\n",
            "Epoch 52/100\n",
            "16/16 - 149s - 9s/step - accuracy: 0.6653 - loss: 0.7428 - val_accuracy: 0.7025 - val_loss: 0.7014\n",
            "Epoch 53/100\n",
            "16/16 - 132s - 8s/step - accuracy: 0.6921 - loss: 0.7780 - val_accuracy: 0.7025 - val_loss: 0.7005\n",
            "Epoch 54/100\n",
            "16/16 - 132s - 8s/step - accuracy: 0.6860 - loss: 0.7661 - val_accuracy: 0.7107 - val_loss: 0.6765\n",
            "Epoch 55/100\n",
            "16/16 - 148s - 9s/step - accuracy: 0.7169 - loss: 0.6971 - val_accuracy: 0.7107 - val_loss: 0.6627\n",
            "Epoch 56/100\n",
            "16/16 - 133s - 8s/step - accuracy: 0.6942 - loss: 0.7711 - val_accuracy: 0.7273 - val_loss: 0.6643\n",
            "Epoch 57/100\n",
            "16/16 - 133s - 8s/step - accuracy: 0.7128 - loss: 0.6986 - val_accuracy: 0.7438 - val_loss: 0.6357\n",
            "Epoch 58/100\n",
            "16/16 - 148s - 9s/step - accuracy: 0.6921 - loss: 0.7265 - val_accuracy: 0.7521 - val_loss: 0.6259\n",
            "Epoch 59/100\n",
            "16/16 - 133s - 8s/step - accuracy: 0.6550 - loss: 0.7740 - val_accuracy: 0.7521 - val_loss: 0.6247\n",
            "Epoch 60/100\n",
            "16/16 - 132s - 8s/step - accuracy: 0.6860 - loss: 0.7274 - val_accuracy: 0.7603 - val_loss: 0.6270\n",
            "Epoch 61/100\n",
            "16/16 - 134s - 8s/step - accuracy: 0.6880 - loss: 0.7437 - val_accuracy: 0.7273 - val_loss: 0.6353\n",
            "Epoch 62/100\n",
            "16/16 - 143s - 9s/step - accuracy: 0.7066 - loss: 0.7014 - val_accuracy: 0.7769 - val_loss: 0.6214\n",
            "Epoch 63/100\n",
            "16/16 - 133s - 8s/step - accuracy: 0.6798 - loss: 0.7451 - val_accuracy: 0.7769 - val_loss: 0.6150\n",
            "Epoch 64/100\n",
            "16/16 - 132s - 8s/step - accuracy: 0.7169 - loss: 0.7001 - val_accuracy: 0.7603 - val_loss: 0.6173\n",
            "Epoch 65/100\n",
            "16/16 - 142s - 9s/step - accuracy: 0.7128 - loss: 0.6868 - val_accuracy: 0.7603 - val_loss: 0.6210\n",
            "Epoch 66/100\n",
            "16/16 - 148s - 9s/step - accuracy: 0.7066 - loss: 0.7270 - val_accuracy: 0.7686 - val_loss: 0.5995\n",
            "Epoch 67/100\n",
            "16/16 - 131s - 8s/step - accuracy: 0.6963 - loss: 0.6828 - val_accuracy: 0.7355 - val_loss: 0.6244\n",
            "Epoch 68/100\n",
            "16/16 - 132s - 8s/step - accuracy: 0.6880 - loss: 0.7143 - val_accuracy: 0.7273 - val_loss: 0.6152\n",
            "Epoch 69/100\n",
            "16/16 - 148s - 9s/step - accuracy: 0.6860 - loss: 0.7337 - val_accuracy: 0.7438 - val_loss: 0.6258\n",
            "Epoch 70/100\n",
            "16/16 - 133s - 8s/step - accuracy: 0.6983 - loss: 0.6813 - val_accuracy: 0.7851 - val_loss: 0.6093\n",
            "Epoch 71/100\n",
            "16/16 - 133s - 8s/step - accuracy: 0.7149 - loss: 0.7088 - val_accuracy: 0.7521 - val_loss: 0.6179\n",
            "Epoch 72/100\n",
            "16/16 - 132s - 8s/step - accuracy: 0.7128 - loss: 0.6822 - val_accuracy: 0.7769 - val_loss: 0.6104\n",
            "Epoch 73/100\n",
            "16/16 - 134s - 8s/step - accuracy: 0.7479 - loss: 0.6613 - val_accuracy: 0.7686 - val_loss: 0.6046\n",
            "Epoch 74/100\n",
            "16/16 - 132s - 8s/step - accuracy: 0.7045 - loss: 0.7019 - val_accuracy: 0.7603 - val_loss: 0.5998\n",
            "Epoch 75/100\n",
            "16/16 - 132s - 8s/step - accuracy: 0.7314 - loss: 0.6522 - val_accuracy: 0.7603 - val_loss: 0.6076\n",
            "Epoch 76/100\n",
            "16/16 - 149s - 9s/step - accuracy: 0.7128 - loss: 0.6859 - val_accuracy: 0.7851 - val_loss: 0.5939\n",
            "Epoch 77/100\n",
            "16/16 - 147s - 9s/step - accuracy: 0.7335 - loss: 0.6347 - val_accuracy: 0.7603 - val_loss: 0.6030\n",
            "Epoch 78/100\n",
            "16/16 - 132s - 8s/step - accuracy: 0.6963 - loss: 0.7024 - val_accuracy: 0.7934 - val_loss: 0.5770\n",
            "Epoch 79/100\n",
            "16/16 - 147s - 9s/step - accuracy: 0.6798 - loss: 0.6942 - val_accuracy: 0.7934 - val_loss: 0.5863\n",
            "Epoch 80/100\n",
            "16/16 - 147s - 9s/step - accuracy: 0.7314 - loss: 0.6743 - val_accuracy: 0.7686 - val_loss: 0.5966\n",
            "Epoch 81/100\n",
            "16/16 - 147s - 9s/step - accuracy: 0.7066 - loss: 0.6826 - val_accuracy: 0.7355 - val_loss: 0.6186\n",
            "Epoch 82/100\n",
            "16/16 - 133s - 8s/step - accuracy: 0.7355 - loss: 0.6583 - val_accuracy: 0.7934 - val_loss: 0.5754\n",
            "Epoch 83/100\n",
            "16/16 - 134s - 8s/step - accuracy: 0.7045 - loss: 0.6748 - val_accuracy: 0.7934 - val_loss: 0.5776\n",
            "Epoch 84/100\n",
            "16/16 - 135s - 8s/step - accuracy: 0.7376 - loss: 0.6523 - val_accuracy: 0.7603 - val_loss: 0.5996\n",
            "Epoch 85/100\n",
            "16/16 - 133s - 8s/step - accuracy: 0.7273 - loss: 0.6518 - val_accuracy: 0.7686 - val_loss: 0.5858\n",
            "Epoch 86/100\n",
            "16/16 - 147s - 9s/step - accuracy: 0.7087 - loss: 0.6624 - val_accuracy: 0.8017 - val_loss: 0.5696\n",
            "Epoch 87/100\n",
            "16/16 - 187s - 12s/step - accuracy: 0.6983 - loss: 0.6742 - val_accuracy: 0.7851 - val_loss: 0.5803\n",
            "Epoch 88/100\n",
            "16/16 - 149s - 9s/step - accuracy: 0.7521 - loss: 0.6105 - val_accuracy: 0.7934 - val_loss: 0.5900\n",
            "Epoch 89/100\n",
            "16/16 - 132s - 8s/step - accuracy: 0.7190 - loss: 0.6726 - val_accuracy: 0.7521 - val_loss: 0.5990\n",
            "Epoch 90/100\n",
            "16/16 - 147s - 9s/step - accuracy: 0.7025 - loss: 0.6889 - val_accuracy: 0.7851 - val_loss: 0.5769\n",
            "Epoch 91/100\n",
            "16/16 - 134s - 8s/step - accuracy: 0.7045 - loss: 0.6929 - val_accuracy: 0.7603 - val_loss: 0.6016\n",
            "Epoch 92/100\n",
            "16/16 - 147s - 9s/step - accuracy: 0.6694 - loss: 0.7192 - val_accuracy: 0.7851 - val_loss: 0.5883\n",
            "Epoch 93/100\n",
            "16/16 - 148s - 9s/step - accuracy: 0.7025 - loss: 0.6841 - val_accuracy: 0.7769 - val_loss: 0.6009\n",
            "Epoch 94/100\n",
            "16/16 - 135s - 8s/step - accuracy: 0.7562 - loss: 0.6085 - val_accuracy: 0.7603 - val_loss: 0.6093\n",
            "Epoch 95/100\n",
            "16/16 - 132s - 8s/step - accuracy: 0.7541 - loss: 0.6043 - val_accuracy: 0.7686 - val_loss: 0.5835\n",
            "Epoch 96/100\n",
            "16/16 - 159s - 10s/step - accuracy: 0.7479 - loss: 0.6127 - val_accuracy: 0.7851 - val_loss: 0.5701\n",
            "Epoch 97/100\n",
            "16/16 - 147s - 9s/step - accuracy: 0.7624 - loss: 0.6203 - val_accuracy: 0.7355 - val_loss: 0.6092\n",
            "Epoch 98/100\n",
            "16/16 - 133s - 8s/step - accuracy: 0.6963 - loss: 0.6975 - val_accuracy: 0.7273 - val_loss: 0.6105\n",
            "Epoch 99/100\n",
            "16/16 - 135s - 8s/step - accuracy: 0.7293 - loss: 0.6464 - val_accuracy: 0.8017 - val_loss: 0.5640\n",
            "Epoch 100/100\n",
            "16/16 - 134s - 8s/step - accuracy: 0.7479 - loss: 0.6365 - val_accuracy: 0.7851 - val_loss: 0.5644\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model berhasil disimpan: model_split80_lr0.001_ep100_l20.0001.h5\n"
          ]
        }
      ],
      "source": [
        "  split_ratio = 0.8\n",
        "split_percent = round(split_ratio * 100)\n",
        "\n",
        "for lr in [0.001]:\n",
        "    for epoch in [100]:\n",
        "        print(f\"\\n📦 Training model dengan split_ratio={split_percent}%, learning_rate={lr}, epochs={epoch}\")\n",
        "\n",
        "        model, history = train_model(\n",
        "            split_ratio=split_ratio,\n",
        "            lr=lr,\n",
        "            epochs=epoch\n",
        "        )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EssXF8q1tU_j",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EssXF8q1tU_j",
        "outputId": "8b1c6d8c-2555-4ac4-a369-458c43f93676"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📦 Training model dengan split_ratio=80%, learning_rate=0.001, epochs=200\n",
            "Found 484 images belonging to 3 classes.\n",
            "Found 121 images belonging to 3 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "16/16 - 179s - 11s/step - accuracy: 0.3905 - loss: 1.7546 - val_accuracy: 0.6281 - val_loss: 0.9463\n",
            "Epoch 2/200\n",
            "16/16 - 161s - 10s/step - accuracy: 0.3946 - loss: 1.3784 - val_accuracy: 0.6694 - val_loss: 0.8748\n",
            "Epoch 3/200\n",
            "16/16 - 151s - 9s/step - accuracy: 0.4979 - loss: 1.1549 - val_accuracy: 0.6364 - val_loss: 0.9012\n",
            "Epoch 4/200\n",
            "16/16 - 148s - 9s/step - accuracy: 0.4835 - loss: 1.0993 - val_accuracy: 0.6198 - val_loss: 0.9106\n",
            "Epoch 5/200\n",
            "16/16 - 160s - 10s/step - accuracy: 0.5062 - loss: 1.0530 - val_accuracy: 0.6364 - val_loss: 0.8916\n",
            "Epoch 6/200\n",
            "16/16 - 160s - 10s/step - accuracy: 0.4959 - loss: 1.0080 - val_accuracy: 0.6446 - val_loss: 0.8788\n",
            "Epoch 7/200\n",
            "16/16 - 150s - 9s/step - accuracy: 0.5496 - loss: 0.9829 - val_accuracy: 0.6529 - val_loss: 0.8653\n",
            "Epoch 8/200\n",
            "16/16 - 151s - 9s/step - accuracy: 0.5682 - loss: 0.9415 - val_accuracy: 0.6529 - val_loss: 0.8556\n",
            "Epoch 9/200\n",
            "16/16 - 155s - 10s/step - accuracy: 0.5103 - loss: 1.0248 - val_accuracy: 0.6777 - val_loss: 0.8553\n",
            "Epoch 10/200\n",
            "16/16 - 151s - 9s/step - accuracy: 0.5434 - loss: 0.9601 - val_accuracy: 0.6529 - val_loss: 0.8525\n",
            "Epoch 11/200\n",
            "16/16 - 162s - 10s/step - accuracy: 0.6136 - loss: 0.9063 - val_accuracy: 0.6860 - val_loss: 0.8284\n",
            "Epoch 12/200\n",
            "16/16 - 162s - 10s/step - accuracy: 0.6157 - loss: 0.8855 - val_accuracy: 0.6860 - val_loss: 0.8211\n",
            "Epoch 13/200\n",
            "16/16 - 155s - 10s/step - accuracy: 0.6302 - loss: 0.8562 - val_accuracy: 0.7190 - val_loss: 0.8060\n",
            "Epoch 14/200\n",
            "16/16 - 149s - 9s/step - accuracy: 0.5826 - loss: 0.9349 - val_accuracy: 0.7355 - val_loss: 0.7579\n",
            "Epoch 15/200\n",
            "16/16 - 150s - 9s/step - accuracy: 0.6136 - loss: 0.8949 - val_accuracy: 0.6942 - val_loss: 0.7789\n",
            "Epoch 16/200\n",
            "16/16 - 160s - 10s/step - accuracy: 0.5971 - loss: 0.8814 - val_accuracy: 0.6942 - val_loss: 0.7754\n",
            "Epoch 17/200\n",
            "16/16 - 160s - 10s/step - accuracy: 0.6054 - loss: 0.9116 - val_accuracy: 0.6860 - val_loss: 0.7906\n",
            "Epoch 18/200\n",
            "16/16 - 161s - 10s/step - accuracy: 0.6198 - loss: 0.8580 - val_accuracy: 0.7107 - val_loss: 0.7717\n",
            "Epoch 19/200\n",
            "16/16 - 152s - 10s/step - accuracy: 0.6364 - loss: 0.8352 - val_accuracy: 0.7521 - val_loss: 0.7533\n",
            "Epoch 20/200\n",
            "16/16 - 150s - 9s/step - accuracy: 0.6219 - loss: 0.8815 - val_accuracy: 0.6860 - val_loss: 0.7455\n",
            "Epoch 21/200\n",
            "16/16 - 203s - 13s/step - accuracy: 0.5909 - loss: 0.8956 - val_accuracy: 0.7025 - val_loss: 0.7364\n",
            "Epoch 22/200\n",
            "16/16 - 151s - 9s/step - accuracy: 0.6095 - loss: 0.8644 - val_accuracy: 0.7190 - val_loss: 0.7464\n",
            "Epoch 23/200\n",
            "16/16 - 150s - 9s/step - accuracy: 0.6012 - loss: 0.8833 - val_accuracy: 0.7107 - val_loss: 0.7467\n",
            "Epoch 24/200\n",
            "16/16 - 158s - 10s/step - accuracy: 0.6240 - loss: 0.8621 - val_accuracy: 0.7025 - val_loss: 0.7476\n",
            "Epoch 25/200\n",
            "16/16 - 151s - 9s/step - accuracy: 0.6364 - loss: 0.8163 - val_accuracy: 0.6860 - val_loss: 0.7392\n",
            "Epoch 26/200\n",
            "16/16 - 149s - 9s/step - accuracy: 0.6260 - loss: 0.8264 - val_accuracy: 0.7025 - val_loss: 0.7190\n",
            "Epoch 27/200\n",
            "16/16 - 163s - 10s/step - accuracy: 0.6136 - loss: 0.8332 - val_accuracy: 0.6777 - val_loss: 0.7278\n",
            "Epoch 28/200\n",
            "16/16 - 160s - 10s/step - accuracy: 0.6364 - loss: 0.8337 - val_accuracy: 0.6694 - val_loss: 0.7480\n",
            "Epoch 29/200\n",
            "16/16 - 192s - 12s/step - accuracy: 0.6736 - loss: 0.7806 - val_accuracy: 0.7273 - val_loss: 0.7092\n",
            "Epoch 30/200\n",
            "16/16 - 201s - 13s/step - accuracy: 0.6632 - loss: 0.7915 - val_accuracy: 0.7190 - val_loss: 0.6990\n",
            "Epoch 31/200\n",
            "16/16 - 202s - 13s/step - accuracy: 0.6529 - loss: 0.7949 - val_accuracy: 0.7438 - val_loss: 0.6942\n",
            "Epoch 32/200\n",
            "16/16 - 150s - 9s/step - accuracy: 0.6508 - loss: 0.7872 - val_accuracy: 0.6942 - val_loss: 0.7113\n",
            "Epoch 33/200\n",
            "16/16 - 160s - 10s/step - accuracy: 0.6550 - loss: 0.8192 - val_accuracy: 0.6364 - val_loss: 0.7242\n",
            "Epoch 34/200\n",
            "16/16 - 159s - 10s/step - accuracy: 0.6260 - loss: 0.7963 - val_accuracy: 0.7025 - val_loss: 0.7071\n",
            "Epoch 35/200\n",
            "16/16 - 148s - 9s/step - accuracy: 0.6591 - loss: 0.8023 - val_accuracy: 0.6942 - val_loss: 0.6944\n",
            "Epoch 36/200\n",
            "16/16 - 148s - 9s/step - accuracy: 0.6364 - loss: 0.7839 - val_accuracy: 0.7273 - val_loss: 0.6781\n",
            "Epoch 37/200\n",
            "16/16 - 148s - 9s/step - accuracy: 0.6674 - loss: 0.7801 - val_accuracy: 0.7190 - val_loss: 0.6719\n",
            "Epoch 38/200\n",
            "16/16 - 159s - 10s/step - accuracy: 0.6756 - loss: 0.7567 - val_accuracy: 0.7273 - val_loss: 0.7019\n",
            "Epoch 39/200\n",
            "16/16 - 147s - 9s/step - accuracy: 0.6467 - loss: 0.7861 - val_accuracy: 0.7190 - val_loss: 0.6826\n",
            "Epoch 40/200\n",
            "16/16 - 150s - 9s/step - accuracy: 0.6343 - loss: 0.7899 - val_accuracy: 0.7355 - val_loss: 0.6712\n",
            "Epoch 41/200\n",
            "16/16 - 199s - 12s/step - accuracy: 0.6591 - loss: 0.7743 - val_accuracy: 0.6942 - val_loss: 0.6605\n",
            "Epoch 42/200\n",
            "16/16 - 149s - 9s/step - accuracy: 0.6839 - loss: 0.7669 - val_accuracy: 0.7107 - val_loss: 0.6793\n",
            "Epoch 43/200\n",
            "16/16 - 148s - 9s/step - accuracy: 0.6632 - loss: 0.7822 - val_accuracy: 0.7273 - val_loss: 0.6889\n",
            "Epoch 44/200\n",
            "16/16 - 148s - 9s/step - accuracy: 0.6736 - loss: 0.7474 - val_accuracy: 0.7355 - val_loss: 0.6803\n",
            "Epoch 45/200\n",
            "16/16 - 159s - 10s/step - accuracy: 0.6529 - loss: 0.7841 - val_accuracy: 0.7438 - val_loss: 0.6723\n",
            "Epoch 46/200\n",
            "16/16 - 192s - 12s/step - accuracy: 0.6736 - loss: 0.7416 - val_accuracy: 0.7355 - val_loss: 0.6777\n",
            "Epoch 47/200\n",
            "16/16 - 151s - 9s/step - accuracy: 0.6694 - loss: 0.7743 - val_accuracy: 0.7355 - val_loss: 0.6407\n",
            "Epoch 48/200\n",
            "16/16 - 149s - 9s/step - accuracy: 0.6921 - loss: 0.7513 - val_accuracy: 0.7686 - val_loss: 0.6388\n",
            "Epoch 49/200\n",
            "16/16 - 202s - 13s/step - accuracy: 0.6756 - loss: 0.7678 - val_accuracy: 0.7190 - val_loss: 0.6532\n",
            "Epoch 50/200\n",
            "16/16 - 160s - 10s/step - accuracy: 0.6674 - loss: 0.7604 - val_accuracy: 0.7438 - val_loss: 0.6573\n",
            "Epoch 51/200\n",
            "16/16 - 191s - 12s/step - accuracy: 0.6488 - loss: 0.7632 - val_accuracy: 0.7521 - val_loss: 0.6816\n",
            "Epoch 52/200\n",
            "16/16 - 202s - 13s/step - accuracy: 0.6756 - loss: 0.7197 - val_accuracy: 0.7521 - val_loss: 0.6487\n",
            "Epoch 53/200\n",
            "16/16 - 149s - 9s/step - accuracy: 0.6694 - loss: 0.7542 - val_accuracy: 0.7273 - val_loss: 0.6542\n",
            "Epoch 54/200\n",
            "16/16 - 202s - 13s/step - accuracy: 0.6694 - loss: 0.7276 - val_accuracy: 0.7438 - val_loss: 0.6344\n",
            "Epoch 55/200\n",
            "16/16 - 160s - 10s/step - accuracy: 0.6612 - loss: 0.7600 - val_accuracy: 0.7355 - val_loss: 0.6559\n",
            "Epoch 56/200\n",
            "16/16 - 159s - 10s/step - accuracy: 0.6818 - loss: 0.7287 - val_accuracy: 0.7438 - val_loss: 0.6354\n",
            "Epoch 57/200\n",
            "16/16 - 203s - 13s/step - accuracy: 0.6901 - loss: 0.7137 - val_accuracy: 0.7521 - val_loss: 0.6315\n",
            "Epoch 58/200\n",
            "16/16 - 160s - 10s/step - accuracy: 0.6901 - loss: 0.7794 - val_accuracy: 0.7521 - val_loss: 0.6496\n",
            "Epoch 59/200\n",
            "16/16 - 192s - 12s/step - accuracy: 0.6715 - loss: 0.7416 - val_accuracy: 0.7686 - val_loss: 0.6451\n",
            "Epoch 60/200\n",
            "16/16 - 149s - 9s/step - accuracy: 0.6983 - loss: 0.7194 - val_accuracy: 0.7438 - val_loss: 0.6333\n",
            "Epoch 61/200\n",
            "16/16 - 159s - 10s/step - accuracy: 0.7004 - loss: 0.7071 - val_accuracy: 0.7686 - val_loss: 0.6194\n",
            "Epoch 62/200\n",
            "16/16 - 192s - 12s/step - accuracy: 0.7273 - loss: 0.6875 - val_accuracy: 0.7686 - val_loss: 0.6254\n",
            "Epoch 63/200\n",
            "16/16 - 149s - 9s/step - accuracy: 0.6942 - loss: 0.6954 - val_accuracy: 0.7851 - val_loss: 0.6128\n",
            "Epoch 64/200\n",
            "16/16 - 148s - 9s/step - accuracy: 0.6777 - loss: 0.7433 - val_accuracy: 0.7603 - val_loss: 0.6193\n",
            "Epoch 65/200\n",
            "16/16 - 204s - 13s/step - accuracy: 0.7376 - loss: 0.6466 - val_accuracy: 0.7686 - val_loss: 0.6027\n",
            "Epoch 66/200\n",
            "16/16 - 201s - 13s/step - accuracy: 0.7045 - loss: 0.6974 - val_accuracy: 0.7521 - val_loss: 0.6135\n",
            "Epoch 67/200\n",
            "16/16 - 202s - 13s/step - accuracy: 0.7149 - loss: 0.6774 - val_accuracy: 0.7603 - val_loss: 0.6120\n",
            "Epoch 68/200\n",
            "16/16 - 149s - 9s/step - accuracy: 0.7190 - loss: 0.6930 - val_accuracy: 0.7934 - val_loss: 0.5916\n",
            "Epoch 69/200\n",
            "16/16 - 150s - 9s/step - accuracy: 0.7087 - loss: 0.6863 - val_accuracy: 0.7521 - val_loss: 0.6258\n",
            "Epoch 70/200\n",
            "16/16 - 148s - 9s/step - accuracy: 0.7335 - loss: 0.6873 - val_accuracy: 0.7438 - val_loss: 0.6207\n",
            "Epoch 71/200\n",
            "16/16 - 160s - 10s/step - accuracy: 0.7169 - loss: 0.6797 - val_accuracy: 0.7603 - val_loss: 0.5746\n",
            "Epoch 72/200\n",
            "16/16 - 192s - 12s/step - accuracy: 0.7438 - loss: 0.6736 - val_accuracy: 0.7934 - val_loss: 0.5765\n",
            "Epoch 73/200\n",
            "16/16 - 149s - 9s/step - accuracy: 0.7376 - loss: 0.6546 - val_accuracy: 0.7934 - val_loss: 0.5869\n",
            "Epoch 74/200\n",
            "16/16 - 150s - 9s/step - accuracy: 0.7190 - loss: 0.6738 - val_accuracy: 0.7603 - val_loss: 0.5866\n",
            "Epoch 75/200\n",
            "16/16 - 150s - 9s/step - accuracy: 0.7087 - loss: 0.6606 - val_accuracy: 0.7355 - val_loss: 0.5882\n",
            "Epoch 76/200\n",
            "16/16 - 159s - 10s/step - accuracy: 0.7231 - loss: 0.6804 - val_accuracy: 0.8099 - val_loss: 0.5738\n",
            "Epoch 77/200\n",
            "16/16 - 147s - 9s/step - accuracy: 0.6901 - loss: 0.7065 - val_accuracy: 0.8099 - val_loss: 0.5787\n",
            "Epoch 78/200\n",
            "16/16 - 149s - 9s/step - accuracy: 0.7066 - loss: 0.6882 - val_accuracy: 0.7603 - val_loss: 0.6122\n",
            "Epoch 79/200\n",
            "16/16 - 201s - 13s/step - accuracy: 0.6860 - loss: 0.6823 - val_accuracy: 0.7438 - val_loss: 0.6224\n",
            "Epoch 80/200\n",
            "16/16 - 149s - 9s/step - accuracy: 0.7211 - loss: 0.6813 - val_accuracy: 0.7686 - val_loss: 0.6020\n",
            "Epoch 81/200\n",
            "16/16 - 160s - 10s/step - accuracy: 0.7087 - loss: 0.6759 - val_accuracy: 0.7851 - val_loss: 0.5942\n",
            "Epoch 82/200\n",
            "16/16 - 160s - 10s/step - accuracy: 0.7231 - loss: 0.6540 - val_accuracy: 0.8182 - val_loss: 0.5995\n",
            "Epoch 83/200\n",
            "16/16 - 146s - 9s/step - accuracy: 0.7107 - loss: 0.6869 - val_accuracy: 0.8017 - val_loss: 0.5821\n",
            "Epoch 84/200\n",
            "16/16 - 149s - 9s/step - accuracy: 0.7025 - loss: 0.6531 - val_accuracy: 0.7521 - val_loss: 0.5889\n",
            "Epoch 85/200\n",
            "16/16 - 149s - 9s/step - accuracy: 0.7417 - loss: 0.6253 - val_accuracy: 0.7603 - val_loss: 0.5892\n",
            "Epoch 86/200\n",
            "16/16 - 149s - 9s/step - accuracy: 0.7355 - loss: 0.6729 - val_accuracy: 0.8264 - val_loss: 0.5597\n",
            "Epoch 87/200\n",
            "16/16 - 148s - 9s/step - accuracy: 0.7417 - loss: 0.6339 - val_accuracy: 0.8017 - val_loss: 0.5606\n",
            "Epoch 88/200\n",
            "16/16 - 151s - 9s/step - accuracy: 0.7376 - loss: 0.6378 - val_accuracy: 0.7934 - val_loss: 0.5624\n",
            "Epoch 89/200\n",
            "16/16 - 159s - 10s/step - accuracy: 0.7335 - loss: 0.6602 - val_accuracy: 0.7521 - val_loss: 0.5685\n",
            "Epoch 90/200\n",
            "16/16 - 192s - 12s/step - accuracy: 0.7190 - loss: 0.6270 - val_accuracy: 0.7438 - val_loss: 0.5779\n",
            "Epoch 91/200\n",
            "16/16 - 202s - 13s/step - accuracy: 0.7459 - loss: 0.6280 - val_accuracy: 0.7934 - val_loss: 0.5527\n",
            "Epoch 92/200\n",
            "16/16 - 212s - 13s/step - accuracy: 0.7190 - loss: 0.6833 - val_accuracy: 0.7603 - val_loss: 0.5684\n",
            "Epoch 93/200\n",
            "16/16 - 150s - 9s/step - accuracy: 0.7438 - loss: 0.6390 - val_accuracy: 0.7603 - val_loss: 0.5707\n",
            "Epoch 94/200\n",
            "16/16 - 149s - 9s/step - accuracy: 0.7252 - loss: 0.6243 - val_accuracy: 0.7521 - val_loss: 0.5630\n",
            "Epoch 95/200\n",
            "16/16 - 159s - 10s/step - accuracy: 0.7107 - loss: 0.6636 - val_accuracy: 0.7686 - val_loss: 0.5809\n",
            "Epoch 96/200\n",
            "16/16 - 193s - 12s/step - accuracy: 0.7211 - loss: 0.6779 - val_accuracy: 0.7686 - val_loss: 0.5451\n",
            "Epoch 97/200\n",
            "16/16 - 149s - 9s/step - accuracy: 0.7583 - loss: 0.6256 - val_accuracy: 0.7934 - val_loss: 0.5673\n",
            "Epoch 98/200\n",
            "16/16 - 151s - 9s/step - accuracy: 0.7500 - loss: 0.6158 - val_accuracy: 0.7769 - val_loss: 0.5575\n",
            "Epoch 99/200\n",
            "16/16 - 201s - 13s/step - accuracy: 0.7211 - loss: 0.6480 - val_accuracy: 0.7686 - val_loss: 0.5601\n",
            "Epoch 100/200\n",
            "16/16 - 212s - 13s/step - accuracy: 0.7211 - loss: 0.6583 - val_accuracy: 0.7686 - val_loss: 0.5743\n",
            "Epoch 101/200\n",
            "16/16 - 203s - 13s/step - accuracy: 0.7335 - loss: 0.6344 - val_accuracy: 0.8099 - val_loss: 0.5355\n",
            "Epoch 102/200\n",
            "16/16 - 190s - 12s/step - accuracy: 0.7128 - loss: 0.6510 - val_accuracy: 0.7769 - val_loss: 0.5634\n",
            "Epoch 103/200\n",
            "16/16 - 150s - 9s/step - accuracy: 0.7417 - loss: 0.6310 - val_accuracy: 0.7521 - val_loss: 0.5810\n",
            "Epoch 104/200\n",
            "16/16 - 149s - 9s/step - accuracy: 0.7355 - loss: 0.6262 - val_accuracy: 0.8017 - val_loss: 0.5428\n",
            "Epoch 105/200\n",
            "16/16 - 149s - 9s/step - accuracy: 0.7169 - loss: 0.6399 - val_accuracy: 0.7934 - val_loss: 0.5573\n",
            "Epoch 106/200\n",
            "16/16 - 150s - 9s/step - accuracy: 0.7645 - loss: 0.6199 - val_accuracy: 0.7438 - val_loss: 0.6159\n",
            "Epoch 107/200\n",
            "16/16 - 161s - 10s/step - accuracy: 0.7190 - loss: 0.6671 - val_accuracy: 0.7521 - val_loss: 0.6033\n",
            "Epoch 108/200\n",
            "16/16 - 190s - 12s/step - accuracy: 0.7438 - loss: 0.6157 - val_accuracy: 0.7934 - val_loss: 0.5331\n",
            "Epoch 109/200\n",
            "16/16 - 160s - 10s/step - accuracy: 0.7169 - loss: 0.6171 - val_accuracy: 0.7851 - val_loss: 0.5447\n",
            "Epoch 110/200\n",
            "16/16 - 192s - 12s/step - accuracy: 0.7583 - loss: 0.5947 - val_accuracy: 0.7934 - val_loss: 0.5444\n",
            "Epoch 111/200\n",
            "16/16 - 148s - 9s/step - accuracy: 0.7438 - loss: 0.6065 - val_accuracy: 0.7769 - val_loss: 0.5788\n",
            "Epoch 112/200\n",
            "16/16 - 160s - 10s/step - accuracy: 0.7314 - loss: 0.6201 - val_accuracy: 0.7851 - val_loss: 0.5344\n",
            "Epoch 113/200\n",
            "16/16 - 148s - 9s/step - accuracy: 0.7169 - loss: 0.6522 - val_accuracy: 0.7769 - val_loss: 0.5521\n",
            "Epoch 114/200\n",
            "16/16 - 160s - 10s/step - accuracy: 0.7562 - loss: 0.6207 - val_accuracy: 0.7686 - val_loss: 0.5479\n",
            "Epoch 115/200\n",
            "16/16 - 149s - 9s/step - accuracy: 0.7769 - loss: 0.5982 - val_accuracy: 0.7355 - val_loss: 0.5497\n",
            "Epoch 116/200\n",
            "16/16 - 149s - 9s/step - accuracy: 0.7603 - loss: 0.5814 - val_accuracy: 0.7686 - val_loss: 0.5309\n",
            "Epoch 117/200\n",
            "16/16 - 170s - 11s/step - accuracy: 0.7211 - loss: 0.6397 - val_accuracy: 0.7769 - val_loss: 0.5327\n",
            "Epoch 118/200\n",
            "16/16 - 196s - 12s/step - accuracy: 0.7686 - loss: 0.5850 - val_accuracy: 0.7769 - val_loss: 0.5424\n",
            "Epoch 119/200\n",
            "16/16 - 168s - 11s/step - accuracy: 0.7624 - loss: 0.5856 - val_accuracy: 0.7438 - val_loss: 0.5680\n",
            "Epoch 120/200\n",
            "16/16 - 166s - 10s/step - accuracy: 0.7397 - loss: 0.6272 - val_accuracy: 0.7521 - val_loss: 0.5386\n",
            "Epoch 121/200\n",
            "16/16 - 211s - 13s/step - accuracy: 0.7479 - loss: 0.6224 - val_accuracy: 0.7686 - val_loss: 0.5317\n",
            "Epoch 122/200\n",
            "16/16 - 196s - 12s/step - accuracy: 0.7872 - loss: 0.5546 - val_accuracy: 0.7851 - val_loss: 0.5451\n",
            "Epoch 123/200\n",
            "16/16 - 167s - 10s/step - accuracy: 0.7438 - loss: 0.5880 - val_accuracy: 0.7603 - val_loss: 0.5140\n",
            "Epoch 124/200\n",
            "16/16 - 167s - 10s/step - accuracy: 0.7417 - loss: 0.5880 - val_accuracy: 0.7769 - val_loss: 0.5257\n",
            "Epoch 125/200\n",
            "16/16 - 202s - 13s/step - accuracy: 0.7335 - loss: 0.6470 - val_accuracy: 0.7851 - val_loss: 0.5179\n",
            "Epoch 126/200\n",
            "16/16 - 152s - 10s/step - accuracy: 0.7624 - loss: 0.6065 - val_accuracy: 0.8182 - val_loss: 0.5268\n",
            "Epoch 127/200\n",
            "16/16 - 160s - 10s/step - accuracy: 0.7686 - loss: 0.5932 - val_accuracy: 0.8099 - val_loss: 0.5156\n",
            "Epoch 128/200\n",
            "16/16 - 150s - 9s/step - accuracy: 0.7603 - loss: 0.5971 - val_accuracy: 0.8099 - val_loss: 0.4993\n",
            "Epoch 129/200\n",
            "16/16 - 173s - 11s/step - accuracy: 0.7603 - loss: 0.5956 - val_accuracy: 0.7769 - val_loss: 0.5201\n",
            "Epoch 130/200\n",
            "16/16 - 165s - 10s/step - accuracy: 0.7686 - loss: 0.5743 - val_accuracy: 0.7934 - val_loss: 0.5531\n",
            "Epoch 131/200\n",
            "16/16 - 164s - 10s/step - accuracy: 0.7851 - loss: 0.5303 - val_accuracy: 0.7769 - val_loss: 0.5745\n",
            "Epoch 132/200\n",
            "16/16 - 148s - 9s/step - accuracy: 0.7707 - loss: 0.5952 - val_accuracy: 0.7686 - val_loss: 0.5302\n",
            "Epoch 133/200\n",
            "16/16 - 203s - 13s/step - accuracy: 0.7624 - loss: 0.5889 - val_accuracy: 0.7686 - val_loss: 0.5480\n",
            "Epoch 134/200\n",
            "16/16 - 203s - 13s/step - accuracy: 0.7975 - loss: 0.5492 - val_accuracy: 0.7190 - val_loss: 0.5794\n",
            "Epoch 135/200\n",
            "16/16 - 201s - 13s/step - accuracy: 0.7417 - loss: 0.6389 - val_accuracy: 0.7851 - val_loss: 0.5854\n",
            "Epoch 136/200\n",
            "16/16 - 160s - 10s/step - accuracy: 0.7459 - loss: 0.5903 - val_accuracy: 0.7438 - val_loss: 0.5591\n",
            "Epoch 137/200\n",
            "16/16 - 159s - 10s/step - accuracy: 0.7459 - loss: 0.6210 - val_accuracy: 0.7934 - val_loss: 0.5101\n",
            "Epoch 138/200\n",
            "16/16 - 149s - 9s/step - accuracy: 0.7314 - loss: 0.6246 - val_accuracy: 0.7686 - val_loss: 0.5441\n",
            "Epoch 139/200\n",
            "16/16 - 150s - 9s/step - accuracy: 0.7500 - loss: 0.6313 - val_accuracy: 0.7769 - val_loss: 0.5413\n",
            "Epoch 140/200\n",
            "16/16 - 149s - 9s/step - accuracy: 0.7583 - loss: 0.5952 - val_accuracy: 0.8017 - val_loss: 0.5211\n",
            "Epoch 141/200\n",
            "16/16 - 149s - 9s/step - accuracy: 0.7521 - loss: 0.6020 - val_accuracy: 0.7851 - val_loss: 0.5424\n",
            "Epoch 142/200\n",
            "16/16 - 150s - 9s/step - accuracy: 0.7252 - loss: 0.6173 - val_accuracy: 0.7521 - val_loss: 0.5501\n",
            "Epoch 143/200\n",
            "16/16 - 149s - 9s/step - accuracy: 0.7541 - loss: 0.6106 - val_accuracy: 0.7603 - val_loss: 0.5359\n",
            "Epoch 144/200\n",
            "16/16 - 159s - 10s/step - accuracy: 0.7893 - loss: 0.5589 - val_accuracy: 0.7603 - val_loss: 0.5293\n",
            "Epoch 145/200\n",
            "16/16 - 195s - 12s/step - accuracy: 0.7645 - loss: 0.5986 - val_accuracy: 0.7603 - val_loss: 0.5142\n",
            "Epoch 146/200\n",
            "16/16 - 149s - 9s/step - accuracy: 0.7417 - loss: 0.5761 - val_accuracy: 0.7851 - val_loss: 0.5266\n",
            "Epoch 147/200\n",
            "16/16 - 150s - 9s/step - accuracy: 0.7583 - loss: 0.5788 - val_accuracy: 0.7603 - val_loss: 0.5511\n",
            "Epoch 148/200\n",
            "16/16 - 150s - 9s/step - accuracy: 0.7996 - loss: 0.5516 - val_accuracy: 0.7769 - val_loss: 0.5193\n",
            "Epoch 149/200\n",
            "16/16 - 148s - 9s/step - accuracy: 0.7500 - loss: 0.5919 - val_accuracy: 0.7769 - val_loss: 0.5168\n",
            "Epoch 150/200\n",
            "16/16 - 159s - 10s/step - accuracy: 0.7583 - loss: 0.5731 - val_accuracy: 0.8099 - val_loss: 0.5367\n",
            "Epoch 151/200\n",
            "16/16 - 191s - 12s/step - accuracy: 0.7707 - loss: 0.5884 - val_accuracy: 0.8017 - val_loss: 0.5237\n",
            "Epoch 152/200\n",
            "16/16 - 161s - 10s/step - accuracy: 0.7707 - loss: 0.5751 - val_accuracy: 0.7686 - val_loss: 0.5229\n",
            "Epoch 153/200\n",
            "16/16 - 158s - 10s/step - accuracy: 0.7665 - loss: 0.5979 - val_accuracy: 0.7851 - val_loss: 0.5183\n",
            "Epoch 154/200\n",
            "16/16 - 148s - 9s/step - accuracy: 0.7417 - loss: 0.5921 - val_accuracy: 0.7934 - val_loss: 0.5494\n",
            "Epoch 155/200\n",
            "16/16 - 149s - 9s/step - accuracy: 0.7686 - loss: 0.6226 - val_accuracy: 0.7851 - val_loss: 0.5181\n",
            "Epoch 156/200\n",
            "16/16 - 150s - 9s/step - accuracy: 0.7665 - loss: 0.5863 - val_accuracy: 0.7934 - val_loss: 0.5082\n",
            "Epoch 157/200\n",
            "16/16 - 201s - 13s/step - accuracy: 0.7645 - loss: 0.5585 - val_accuracy: 0.8182 - val_loss: 0.5215\n",
            "Epoch 158/200\n",
            "16/16 - 150s - 9s/step - accuracy: 0.7541 - loss: 0.5886 - val_accuracy: 0.7934 - val_loss: 0.5351\n",
            "Epoch 159/200\n",
            "16/16 - 147s - 9s/step - accuracy: 0.7707 - loss: 0.5361 - val_accuracy: 0.8017 - val_loss: 0.5279\n",
            "Epoch 160/200\n",
            "16/16 - 216s - 13s/step - accuracy: 0.7335 - loss: 0.5810 - val_accuracy: 0.7934 - val_loss: 0.5573\n",
            "Epoch 161/200\n",
            "16/16 - 194s - 12s/step - accuracy: 0.7748 - loss: 0.5513 - val_accuracy: 0.7355 - val_loss: 0.5552\n",
            "Epoch 162/200\n",
            "16/16 - 150s - 9s/step - accuracy: 0.7748 - loss: 0.5828 - val_accuracy: 0.7934 - val_loss: 0.5079\n",
            "Epoch 163/200\n",
            "16/16 - 161s - 10s/step - accuracy: 0.7645 - loss: 0.5542 - val_accuracy: 0.7851 - val_loss: 0.5141\n",
            "Epoch 164/200\n",
            "16/16 - 190s - 12s/step - accuracy: 0.7500 - loss: 0.5908 - val_accuracy: 0.8017 - val_loss: 0.5235\n",
            "Epoch 165/200\n",
            "16/16 - 159s - 10s/step - accuracy: 0.7686 - loss: 0.5484 - val_accuracy: 0.7769 - val_loss: 0.5225\n",
            "Epoch 166/200\n",
            "16/16 - 160s - 10s/step - accuracy: 0.7934 - loss: 0.5133 - val_accuracy: 0.7851 - val_loss: 0.5114\n",
            "Epoch 167/200\n",
            "16/16 - 148s - 9s/step - accuracy: 0.7562 - loss: 0.5514 - val_accuracy: 0.8017 - val_loss: 0.5036\n",
            "Epoch 168/200\n",
            "16/16 - 151s - 9s/step - accuracy: 0.7748 - loss: 0.5245 - val_accuracy: 0.7934 - val_loss: 0.5292\n",
            "Epoch 169/200\n",
            "16/16 - 150s - 9s/step - accuracy: 0.7479 - loss: 0.5937 - val_accuracy: 0.7769 - val_loss: 0.5109\n",
            "Epoch 170/200\n",
            "16/16 - 151s - 9s/step - accuracy: 0.7397 - loss: 0.6143 - val_accuracy: 0.8017 - val_loss: 0.4874\n",
            "Epoch 171/200\n",
            "16/16 - 149s - 9s/step - accuracy: 0.7645 - loss: 0.5371 - val_accuracy: 0.7851 - val_loss: 0.5242\n",
            "Epoch 172/200\n",
            "16/16 - 149s - 9s/step - accuracy: 0.7665 - loss: 0.5625 - val_accuracy: 0.8017 - val_loss: 0.4918\n",
            "Epoch 173/200\n",
            "16/16 - 149s - 9s/step - accuracy: 0.7831 - loss: 0.5553 - val_accuracy: 0.7686 - val_loss: 0.5085\n",
            "Epoch 174/200\n",
            "16/16 - 161s - 10s/step - accuracy: 0.7769 - loss: 0.5606 - val_accuracy: 0.7686 - val_loss: 0.5124\n",
            "Epoch 175/200\n",
            "16/16 - 192s - 12s/step - accuracy: 0.7541 - loss: 0.5691 - val_accuracy: 0.7934 - val_loss: 0.4911\n",
            "Epoch 176/200\n",
            "16/16 - 154s - 10s/step - accuracy: 0.7583 - loss: 0.5560 - val_accuracy: 0.7851 - val_loss: 0.5071\n",
            "Epoch 177/200\n",
            "16/16 - 150s - 9s/step - accuracy: 0.7521 - loss: 0.5754 - val_accuracy: 0.7851 - val_loss: 0.5085\n",
            "Epoch 178/200\n",
            "16/16 - 204s - 13s/step - accuracy: 0.7789 - loss: 0.5728 - val_accuracy: 0.7769 - val_loss: 0.4971\n",
            "Epoch 179/200\n",
            "16/16 - 201s - 13s/step - accuracy: 0.8037 - loss: 0.5090 - val_accuracy: 0.7934 - val_loss: 0.5151\n",
            "Epoch 180/200\n",
            "16/16 - 150s - 9s/step - accuracy: 0.7645 - loss: 0.5692 - val_accuracy: 0.7851 - val_loss: 0.5160\n",
            "Epoch 181/200\n",
            "16/16 - 161s - 10s/step - accuracy: 0.7851 - loss: 0.5531 - val_accuracy: 0.7355 - val_loss: 0.5704\n",
            "Epoch 182/200\n",
            "16/16 - 160s - 10s/step - accuracy: 0.7872 - loss: 0.5143 - val_accuracy: 0.7603 - val_loss: 0.5297\n",
            "Epoch 183/200\n",
            "16/16 - 164s - 10s/step - accuracy: 0.7748 - loss: 0.5284 - val_accuracy: 0.7934 - val_loss: 0.4854\n",
            "Epoch 184/200\n",
            "16/16 - 200s - 12s/step - accuracy: 0.7417 - loss: 0.5636 - val_accuracy: 0.7769 - val_loss: 0.4929\n",
            "Epoch 185/200\n",
            "16/16 - 148s - 9s/step - accuracy: 0.7955 - loss: 0.5009 - val_accuracy: 0.7769 - val_loss: 0.5126\n",
            "Epoch 186/200\n",
            "16/16 - 149s - 9s/step - accuracy: 0.7769 - loss: 0.5634 - val_accuracy: 0.8099 - val_loss: 0.4920\n",
            "Epoch 187/200\n",
            "16/16 - 150s - 9s/step - accuracy: 0.7934 - loss: 0.5269 - val_accuracy: 0.7934 - val_loss: 0.5119\n",
            "Epoch 188/200\n",
            "16/16 - 162s - 10s/step - accuracy: 0.7810 - loss: 0.5487 - val_accuracy: 0.8099 - val_loss: 0.5010\n",
            "Epoch 189/200\n",
            "16/16 - 162s - 10s/step - accuracy: 0.7500 - loss: 0.6149 - val_accuracy: 0.8017 - val_loss: 0.4875\n",
            "Epoch 190/200\n",
            "16/16 - 149s - 9s/step - accuracy: 0.7789 - loss: 0.5618 - val_accuracy: 0.7603 - val_loss: 0.5265\n",
            "Epoch 191/200\n",
            "16/16 - 204s - 13s/step - accuracy: 0.7975 - loss: 0.5217 - val_accuracy: 0.8017 - val_loss: 0.5144\n",
            "Epoch 192/200\n",
            "16/16 - 150s - 9s/step - accuracy: 0.7872 - loss: 0.5437 - val_accuracy: 0.7851 - val_loss: 0.5120\n",
            "Epoch 193/200\n",
            "16/16 - 149s - 9s/step - accuracy: 0.7748 - loss: 0.5448 - val_accuracy: 0.8182 - val_loss: 0.5028\n",
            "Epoch 194/200\n",
            "16/16 - 203s - 13s/step - accuracy: 0.7686 - loss: 0.5380 - val_accuracy: 0.7934 - val_loss: 0.5367\n",
            "Epoch 195/200\n",
            "16/16 - 150s - 9s/step - accuracy: 0.7810 - loss: 0.5387 - val_accuracy: 0.8017 - val_loss: 0.5059\n",
            "Epoch 196/200\n",
            "16/16 - 160s - 10s/step - accuracy: 0.8037 - loss: 0.4831 - val_accuracy: 0.7934 - val_loss: 0.5183\n",
            "Epoch 197/200\n",
            "16/16 - 204s - 13s/step - accuracy: 0.7975 - loss: 0.5066 - val_accuracy: 0.7851 - val_loss: 0.5265\n",
            "Epoch 198/200\n",
            "16/16 - 152s - 9s/step - accuracy: 0.7707 - loss: 0.5414 - val_accuracy: 0.8017 - val_loss: 0.4889\n",
            "Epoch 199/200\n",
            "16/16 - 163s - 10s/step - accuracy: 0.7727 - loss: 0.5666 - val_accuracy: 0.7851 - val_loss: 0.5115\n",
            "Epoch 200/200\n",
            "16/16 - 200s - 13s/step - accuracy: 0.7831 - loss: 0.5393 - val_accuracy: 0.8182 - val_loss: 0.5024\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model berhasil disimpan: model_split80_lr0.001_ep200_l20.0001.h5\n"
          ]
        }
      ],
      "source": [
        "split_ratio = 0.8\n",
        "split_percent = round(split_ratio * 100)\n",
        "\n",
        "for lr in [0.001]:\n",
        "    for epoch in [200]:\n",
        "        print(f\"\\n📦 Training model dengan split_ratio={split_percent}%, learning_rate={lr}, epochs={epoch}\")\n",
        "\n",
        "        model, history = train_model(\n",
        "            split_ratio=split_ratio,\n",
        "            lr=lr,\n",
        "            epochs=epoch\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sC09FNdTtWhX",
      "metadata": {
        "id": "sC09FNdTtWhX"
      },
      "outputs": [],
      "source": [
        "split_ratio = 0.8\n",
        "split_percent = round(split_ratio * 100)\n",
        "\n",
        "for lr in [0.001]:\n",
        "    for epoch in [300]:\n",
        "        print(f\"\\n📦 Training model dengan split_ratio={split_percent}%, learning_rate={lr}, epochs={epoch}\")\n",
        "\n",
        "        model, history = train_model(\n",
        "            split_ratio=split_ratio,\n",
        "            lr=lr,\n",
        "            epochs=epoch\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4k4rCRBZmF9o",
      "metadata": {
        "id": "4k4rCRBZmF9o"
      },
      "source": [
        "### SPLIT RATIO 0.8 LEARNING RATE 0.0001\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EgITKoF7mLDL",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgITKoF7mLDL",
        "outputId": "926ba4bc-3491-47a5-bb54-2068eece6b7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📦 Training model dengan split_ratio=80%, learning_rate=0.0001, epochs=50\n",
            "Found 484 images belonging to 3 classes.\n",
            "Found 121 images belonging to 3 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "16/16 - 76s - 5s/step - accuracy: 0.3409 - loss: 1.9056 - val_accuracy: 0.4380 - val_loss: 1.1011\n",
            "Epoch 2/50\n",
            "16/16 - 45s - 3s/step - accuracy: 0.3884 - loss: 1.6626 - val_accuracy: 0.4380 - val_loss: 1.0704\n",
            "Epoch 3/50\n",
            "16/16 - 44s - 3s/step - accuracy: 0.3636 - loss: 1.6421 - val_accuracy: 0.4711 - val_loss: 1.0282\n",
            "Epoch 4/50\n",
            "16/16 - 43s - 3s/step - accuracy: 0.3864 - loss: 1.6306 - val_accuracy: 0.4876 - val_loss: 0.9702\n",
            "Epoch 5/50\n",
            "16/16 - 42s - 3s/step - accuracy: 0.3719 - loss: 1.5073 - val_accuracy: 0.5537 - val_loss: 0.9391\n",
            "Epoch 6/50\n",
            "16/16 - 43s - 3s/step - accuracy: 0.3884 - loss: 1.4538 - val_accuracy: 0.5950 - val_loss: 0.9234\n",
            "Epoch 7/50\n",
            "16/16 - 45s - 3s/step - accuracy: 0.3822 - loss: 1.4572 - val_accuracy: 0.6364 - val_loss: 0.9137\n",
            "Epoch 8/50\n",
            "16/16 - 43s - 3s/step - accuracy: 0.3926 - loss: 1.4311 - val_accuracy: 0.6446 - val_loss: 0.9071\n",
            "Epoch 9/50\n",
            "16/16 - 40s - 3s/step - accuracy: 0.4050 - loss: 1.3869 - val_accuracy: 0.6529 - val_loss: 0.9092\n",
            "Epoch 10/50\n",
            "16/16 - 40s - 3s/step - accuracy: 0.4112 - loss: 1.3333 - val_accuracy: 0.6612 - val_loss: 0.9094\n",
            "Epoch 11/50\n",
            "16/16 - 49s - 3s/step - accuracy: 0.4401 - loss: 1.2368 - val_accuracy: 0.6446 - val_loss: 0.9095\n",
            "Epoch 12/50\n",
            "16/16 - 42s - 3s/step - accuracy: 0.4401 - loss: 1.2899 - val_accuracy: 0.6364 - val_loss: 0.9116\n",
            "Epoch 13/50\n",
            "16/16 - 42s - 3s/step - accuracy: 0.4339 - loss: 1.2435 - val_accuracy: 0.6364 - val_loss: 0.9132\n",
            "Epoch 14/50\n",
            "16/16 - 40s - 3s/step - accuracy: 0.4421 - loss: 1.2386 - val_accuracy: 0.6198 - val_loss: 0.9141\n",
            "Epoch 15/50\n",
            "16/16 - 46s - 3s/step - accuracy: 0.4566 - loss: 1.1502 - val_accuracy: 0.6612 - val_loss: 0.9065\n",
            "Epoch 16/50\n",
            "16/16 - 43s - 3s/step - accuracy: 0.4835 - loss: 1.1445 - val_accuracy: 0.6446 - val_loss: 0.9037\n",
            "Epoch 17/50\n",
            "16/16 - 81s - 5s/step - accuracy: 0.4835 - loss: 1.1539 - val_accuracy: 0.6529 - val_loss: 0.9028\n",
            "Epoch 18/50\n",
            "16/16 - 43s - 3s/step - accuracy: 0.4897 - loss: 1.1539 - val_accuracy: 0.6694 - val_loss: 0.9000\n",
            "Epoch 19/50\n",
            "16/16 - 85s - 5s/step - accuracy: 0.4525 - loss: 1.1681 - val_accuracy: 0.6529 - val_loss: 0.8984\n",
            "Epoch 20/50\n",
            "16/16 - 44s - 3s/step - accuracy: 0.4979 - loss: 1.0973 - val_accuracy: 0.6694 - val_loss: 0.8933\n",
            "Epoch 21/50\n",
            "16/16 - 42s - 3s/step - accuracy: 0.5000 - loss: 1.1037 - val_accuracy: 0.6612 - val_loss: 0.8889\n",
            "Epoch 22/50\n",
            "16/16 - 41s - 3s/step - accuracy: 0.4855 - loss: 1.1087 - val_accuracy: 0.6612 - val_loss: 0.8881\n",
            "Epoch 23/50\n",
            "16/16 - 45s - 3s/step - accuracy: 0.4669 - loss: 1.1403 - val_accuracy: 0.6694 - val_loss: 0.8888\n",
            "Epoch 24/50\n",
            "16/16 - 44s - 3s/step - accuracy: 0.4504 - loss: 1.1790 - val_accuracy: 0.6612 - val_loss: 0.8902\n",
            "Epoch 25/50\n",
            "16/16 - 84s - 5s/step - accuracy: 0.4835 - loss: 1.0963 - val_accuracy: 0.6694 - val_loss: 0.8910\n",
            "Epoch 26/50\n",
            "16/16 - 43s - 3s/step - accuracy: 0.5062 - loss: 1.1162 - val_accuracy: 0.6777 - val_loss: 0.8887\n",
            "Epoch 27/50\n",
            "16/16 - 48s - 3s/step - accuracy: 0.5289 - loss: 1.0241 - val_accuracy: 0.6942 - val_loss: 0.8848\n",
            "Epoch 28/50\n",
            "16/16 - 80s - 5s/step - accuracy: 0.5207 - loss: 1.0335 - val_accuracy: 0.6777 - val_loss: 0.8843\n",
            "Epoch 29/50\n",
            "16/16 - 80s - 5s/step - accuracy: 0.4731 - loss: 1.1232 - val_accuracy: 0.6694 - val_loss: 0.8854\n",
            "Epoch 30/50\n",
            "16/16 - 79s - 5s/step - accuracy: 0.5000 - loss: 1.0961 - val_accuracy: 0.6777 - val_loss: 0.8849\n",
            "Epoch 31/50\n",
            "16/16 - 46s - 3s/step - accuracy: 0.5124 - loss: 1.1102 - val_accuracy: 0.6612 - val_loss: 0.8873\n",
            "Epoch 32/50\n",
            "16/16 - 41s - 3s/step - accuracy: 0.4855 - loss: 1.0984 - val_accuracy: 0.6694 - val_loss: 0.8881\n",
            "Epoch 33/50\n",
            "16/16 - 42s - 3s/step - accuracy: 0.4979 - loss: 1.0673 - val_accuracy: 0.6860 - val_loss: 0.8859\n",
            "Epoch 34/50\n",
            "16/16 - 41s - 3s/step - accuracy: 0.4876 - loss: 1.0887 - val_accuracy: 0.6529 - val_loss: 0.8878\n",
            "Epoch 35/50\n",
            "16/16 - 45s - 3s/step - accuracy: 0.4876 - loss: 1.0803 - val_accuracy: 0.6529 - val_loss: 0.8873\n",
            "Epoch 36/50\n",
            "16/16 - 42s - 3s/step - accuracy: 0.5021 - loss: 1.1089 - val_accuracy: 0.6529 - val_loss: 0.8871\n",
            "Epoch 37/50\n",
            "16/16 - 41s - 3s/step - accuracy: 0.4814 - loss: 1.0485 - val_accuracy: 0.6860 - val_loss: 0.8838\n",
            "Epoch 38/50\n",
            "16/16 - 82s - 5s/step - accuracy: 0.5269 - loss: 1.0287 - val_accuracy: 0.6777 - val_loss: 0.8830\n",
            "Epoch 39/50\n",
            "16/16 - 43s - 3s/step - accuracy: 0.5124 - loss: 1.0180 - val_accuracy: 0.6777 - val_loss: 0.8829\n",
            "Epoch 40/50\n",
            "16/16 - 43s - 3s/step - accuracy: 0.4731 - loss: 1.0274 - val_accuracy: 0.6694 - val_loss: 0.8844\n",
            "Epoch 41/50\n",
            "16/16 - 44s - 3s/step - accuracy: 0.5248 - loss: 1.0340 - val_accuracy: 0.6777 - val_loss: 0.8833\n",
            "Epoch 42/50\n",
            "16/16 - 40s - 2s/step - accuracy: 0.5310 - loss: 1.0176 - val_accuracy: 0.6777 - val_loss: 0.8843\n",
            "Epoch 43/50\n",
            "16/16 - 45s - 3s/step - accuracy: 0.5558 - loss: 0.9858 - val_accuracy: 0.6860 - val_loss: 0.8838\n",
            "Epoch 44/50\n",
            "16/16 - 42s - 3s/step - accuracy: 0.5537 - loss: 0.9822 - val_accuracy: 0.6777 - val_loss: 0.8815\n",
            "Epoch 45/50\n",
            "16/16 - 41s - 3s/step - accuracy: 0.4938 - loss: 1.0391 - val_accuracy: 0.6694 - val_loss: 0.8787\n",
            "Epoch 46/50\n",
            "16/16 - 42s - 3s/step - accuracy: 0.5351 - loss: 0.9796 - val_accuracy: 0.6777 - val_loss: 0.8749\n",
            "Epoch 47/50\n",
            "16/16 - 47s - 3s/step - accuracy: 0.5310 - loss: 0.9817 - val_accuracy: 0.6694 - val_loss: 0.8734\n",
            "Epoch 48/50\n",
            "16/16 - 42s - 3s/step - accuracy: 0.5558 - loss: 0.9783 - val_accuracy: 0.6529 - val_loss: 0.8718\n",
            "Epoch 49/50\n",
            "16/16 - 41s - 3s/step - accuracy: 0.5186 - loss: 1.0012 - val_accuracy: 0.6612 - val_loss: 0.8699\n",
            "Epoch 50/50\n",
            "16/16 - 41s - 3s/step - accuracy: 0.5227 - loss: 0.9894 - val_accuracy: 0.6694 - val_loss: 0.8678\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model berhasil disimpan: model_split80_lr0.0001_ep50_l20.0001.h5\n"
          ]
        }
      ],
      "source": [
        "split_ratio = 0.8\n",
        "split_percent = round(split_ratio * 100)\n",
        "\n",
        "for lr in [0.0001]:\n",
        "    for epoch in [50]:\n",
        "        print(f\"\\n📦 Training model dengan split_ratio={split_percent}%, learning_rate={lr}, epochs={epoch}\")\n",
        "\n",
        "        model, history = train_model(\n",
        "            split_ratio=split_ratio,\n",
        "            lr=lr,\n",
        "            epochs=epoch\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oS_YuDL-zWtk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oS_YuDL-zWtk",
        "outputId": "449d0d62-33e1-46c1-a462-03aa3a0adc95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📦 Training model dengan split_ratio=80%, learning_rate=0.0001, epochs=100\n",
            "Found 484 images belonging to 3 classes.\n",
            "Found 121 images belonging to 3 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "16/16 - 168s - 11s/step - accuracy: 0.3492 - loss: 2.1094 - val_accuracy: 0.3967 - val_loss: 1.1628\n",
            "Epoch 2/100\n",
            "16/16 - 157s - 10s/step - accuracy: 0.3802 - loss: 1.8801 - val_accuracy: 0.4793 - val_loss: 1.1095\n",
            "Epoch 3/100\n",
            "16/16 - 152s - 9s/step - accuracy: 0.3967 - loss: 1.7730 - val_accuracy: 0.4793 - val_loss: 1.0674\n",
            "Epoch 4/100\n",
            "16/16 - 151s - 9s/step - accuracy: 0.3740 - loss: 1.6903 - val_accuracy: 0.5124 - val_loss: 1.0330\n",
            "Epoch 5/100\n",
            "16/16 - 150s - 9s/step - accuracy: 0.3471 - loss: 1.6926 - val_accuracy: 0.5537 - val_loss: 0.9939\n",
            "Epoch 6/100\n",
            "16/16 - 208s - 13s/step - accuracy: 0.4194 - loss: 1.4897 - val_accuracy: 0.5372 - val_loss: 0.9779\n",
            "Epoch 7/100\n",
            "16/16 - 150s - 9s/step - accuracy: 0.4029 - loss: 1.4889 - val_accuracy: 0.5702 - val_loss: 0.9652\n",
            "Epoch 8/100\n",
            "16/16 - 150s - 9s/step - accuracy: 0.4463 - loss: 1.4132 - val_accuracy: 0.5455 - val_loss: 0.9581\n",
            "Epoch 9/100\n",
            "16/16 - 150s - 9s/step - accuracy: 0.3967 - loss: 1.5041 - val_accuracy: 0.5372 - val_loss: 0.9564\n",
            "Epoch 10/100\n",
            "16/16 - 166s - 10s/step - accuracy: 0.4215 - loss: 1.3481 - val_accuracy: 0.5620 - val_loss: 0.9428\n",
            "Epoch 11/100\n",
            "16/16 - 150s - 9s/step - accuracy: 0.4029 - loss: 1.4431 - val_accuracy: 0.5702 - val_loss: 0.9332\n",
            "Epoch 12/100\n",
            "16/16 - 150s - 9s/step - accuracy: 0.4669 - loss: 1.3532 - val_accuracy: 0.5620 - val_loss: 0.9295\n",
            "Epoch 13/100\n",
            "16/16 - 208s - 13s/step - accuracy: 0.4360 - loss: 1.3535 - val_accuracy: 0.5702 - val_loss: 0.9280\n",
            "Epoch 14/100\n",
            "16/16 - 150s - 9s/step - accuracy: 0.4050 - loss: 1.3084 - val_accuracy: 0.5620 - val_loss: 0.9254\n",
            "Epoch 15/100\n",
            "16/16 - 159s - 10s/step - accuracy: 0.4566 - loss: 1.2198 - val_accuracy: 0.5868 - val_loss: 0.9257\n",
            "Epoch 16/100\n",
            "16/16 - 190s - 12s/step - accuracy: 0.4628 - loss: 1.2045 - val_accuracy: 0.5950 - val_loss: 0.9265\n",
            "Epoch 17/100\n",
            "16/16 - 150s - 9s/step - accuracy: 0.4669 - loss: 1.2052 - val_accuracy: 0.5868 - val_loss: 0.9256\n",
            "Epoch 18/100\n",
            "16/16 - 197s - 12s/step - accuracy: 0.4690 - loss: 1.1418 - val_accuracy: 0.5868 - val_loss: 0.9260\n",
            "Epoch 19/100\n",
            "16/16 - 155s - 10s/step - accuracy: 0.3967 - loss: 1.2891 - val_accuracy: 0.5868 - val_loss: 0.9252\n",
            "Epoch 20/100\n",
            "16/16 - 142s - 9s/step - accuracy: 0.4752 - loss: 1.1214 - val_accuracy: 0.5702 - val_loss: 0.9250\n",
            "Epoch 21/100\n",
            "16/16 - 145s - 9s/step - accuracy: 0.4401 - loss: 1.2010 - val_accuracy: 0.5702 - val_loss: 0.9241\n",
            "Epoch 22/100\n",
            "16/16 - 145s - 9s/step - accuracy: 0.4566 - loss: 1.1428 - val_accuracy: 0.5950 - val_loss: 0.9200\n",
            "Epoch 23/100\n",
            "16/16 - 155s - 10s/step - accuracy: 0.4731 - loss: 1.0949 - val_accuracy: 0.6116 - val_loss: 0.9133\n",
            "Epoch 24/100\n",
            "16/16 - 204s - 13s/step - accuracy: 0.4566 - loss: 1.1474 - val_accuracy: 0.6116 - val_loss: 0.9097\n",
            "Epoch 25/100\n",
            "16/16 - 158s - 10s/step - accuracy: 0.4876 - loss: 1.0641 - val_accuracy: 0.6033 - val_loss: 0.9080\n",
            "Epoch 26/100\n",
            "16/16 - 158s - 10s/step - accuracy: 0.4711 - loss: 1.0925 - val_accuracy: 0.6198 - val_loss: 0.9046\n",
            "Epoch 27/100\n",
            "16/16 - 202s - 13s/step - accuracy: 0.4855 - loss: 1.0979 - val_accuracy: 0.6116 - val_loss: 0.9032\n",
            "Epoch 28/100\n",
            "16/16 - 145s - 9s/step - accuracy: 0.5124 - loss: 1.0815 - val_accuracy: 0.6033 - val_loss: 0.9063\n",
            "Epoch 29/100\n",
            "16/16 - 204s - 13s/step - accuracy: 0.5000 - loss: 1.0584 - val_accuracy: 0.6116 - val_loss: 0.9029\n",
            "Epoch 30/100\n",
            "16/16 - 146s - 9s/step - accuracy: 0.5041 - loss: 1.0728 - val_accuracy: 0.6198 - val_loss: 0.8987\n",
            "Epoch 31/100\n",
            "16/16 - 158s - 10s/step - accuracy: 0.4835 - loss: 1.0732 - val_accuracy: 0.6364 - val_loss: 0.8980\n",
            "Epoch 32/100\n",
            "16/16 - 145s - 9s/step - accuracy: 0.5145 - loss: 1.0666 - val_accuracy: 0.6364 - val_loss: 0.8961\n",
            "Epoch 33/100\n",
            "16/16 - 144s - 9s/step - accuracy: 0.4793 - loss: 1.1005 - val_accuracy: 0.6364 - val_loss: 0.8942\n",
            "Epoch 34/100\n",
            "16/16 - 145s - 9s/step - accuracy: 0.5269 - loss: 1.0055 - val_accuracy: 0.6198 - val_loss: 0.8916\n",
            "Epoch 35/100\n",
            "16/16 - 146s - 9s/step - accuracy: 0.4855 - loss: 1.0476 - val_accuracy: 0.6198 - val_loss: 0.8890\n",
            "Epoch 36/100\n",
            "16/16 - 157s - 10s/step - accuracy: 0.5227 - loss: 1.0623 - val_accuracy: 0.6281 - val_loss: 0.8852\n",
            "Epoch 37/100\n",
            "16/16 - 143s - 9s/step - accuracy: 0.4814 - loss: 1.0950 - val_accuracy: 0.6281 - val_loss: 0.8814\n",
            "Epoch 38/100\n",
            "16/16 - 157s - 10s/step - accuracy: 0.4938 - loss: 1.0960 - val_accuracy: 0.6446 - val_loss: 0.8796\n",
            "Epoch 39/100\n",
            "16/16 - 147s - 9s/step - accuracy: 0.5041 - loss: 1.0157 - val_accuracy: 0.6446 - val_loss: 0.8804\n",
            "Epoch 40/100\n",
            "16/16 - 145s - 9s/step - accuracy: 0.4917 - loss: 1.0364 - val_accuracy: 0.6198 - val_loss: 0.8810\n",
            "Epoch 41/100\n",
            "16/16 - 202s - 13s/step - accuracy: 0.5269 - loss: 1.0348 - val_accuracy: 0.6364 - val_loss: 0.8819\n",
            "Epoch 42/100\n",
            "16/16 - 146s - 9s/step - accuracy: 0.5331 - loss: 1.0001 - val_accuracy: 0.6281 - val_loss: 0.8816\n",
            "Epoch 43/100\n",
            "16/16 - 157s - 10s/step - accuracy: 0.5062 - loss: 1.0090 - val_accuracy: 0.6281 - val_loss: 0.8824\n",
            "Epoch 44/100\n",
            "16/16 - 144s - 9s/step - accuracy: 0.4711 - loss: 1.0644 - val_accuracy: 0.6364 - val_loss: 0.8813\n",
            "Epoch 45/100\n",
            "16/16 - 146s - 9s/step - accuracy: 0.4979 - loss: 1.0349 - val_accuracy: 0.6281 - val_loss: 0.8820\n",
            "Epoch 46/100\n",
            "16/16 - 146s - 9s/step - accuracy: 0.5227 - loss: 1.0341 - val_accuracy: 0.6198 - val_loss: 0.8785\n",
            "Epoch 47/100\n",
            "16/16 - 144s - 9s/step - accuracy: 0.5269 - loss: 0.9771 - val_accuracy: 0.6198 - val_loss: 0.8783\n",
            "Epoch 48/100\n",
            "16/16 - 145s - 9s/step - accuracy: 0.5806 - loss: 0.9296 - val_accuracy: 0.6281 - val_loss: 0.8782\n",
            "Epoch 49/100\n",
            "16/16 - 160s - 10s/step - accuracy: 0.5021 - loss: 1.0069 - val_accuracy: 0.6446 - val_loss: 0.8769\n",
            "Epoch 50/100\n",
            "16/16 - 194s - 12s/step - accuracy: 0.5021 - loss: 1.0194 - val_accuracy: 0.6446 - val_loss: 0.8763\n",
            "Epoch 51/100\n",
            "16/16 - 198s - 12s/step - accuracy: 0.5310 - loss: 0.9870 - val_accuracy: 0.6364 - val_loss: 0.8720\n",
            "Epoch 52/100\n",
            "16/16 - 148s - 9s/step - accuracy: 0.5372 - loss: 0.9974 - val_accuracy: 0.6446 - val_loss: 0.8690\n",
            "Epoch 53/100\n",
            "16/16 - 148s - 9s/step - accuracy: 0.5186 - loss: 1.0376 - val_accuracy: 0.6529 - val_loss: 0.8694\n",
            "Epoch 54/100\n",
            "16/16 - 147s - 9s/step - accuracy: 0.5372 - loss: 0.9944 - val_accuracy: 0.6529 - val_loss: 0.8692\n",
            "Epoch 55/100\n",
            "16/16 - 158s - 10s/step - accuracy: 0.5393 - loss: 0.9501 - val_accuracy: 0.6694 - val_loss: 0.8668\n",
            "Epoch 56/100\n",
            "16/16 - 191s - 12s/step - accuracy: 0.4959 - loss: 1.0393 - val_accuracy: 0.6612 - val_loss: 0.8652\n",
            "Epoch 57/100\n",
            "16/16 - 159s - 10s/step - accuracy: 0.5331 - loss: 0.9798 - val_accuracy: 0.6612 - val_loss: 0.8631\n",
            "Epoch 58/100\n",
            "16/16 - 159s - 10s/step - accuracy: 0.5145 - loss: 1.0087 - val_accuracy: 0.6694 - val_loss: 0.8630\n",
            "Epoch 59/100\n",
            "16/16 - 201s - 13s/step - accuracy: 0.5310 - loss: 0.9974 - val_accuracy: 0.6777 - val_loss: 0.8592\n",
            "Epoch 60/100\n",
            "16/16 - 158s - 10s/step - accuracy: 0.5558 - loss: 0.9420 - val_accuracy: 0.7025 - val_loss: 0.8575\n",
            "Epoch 61/100\n",
            "16/16 - 144s - 9s/step - accuracy: 0.5062 - loss: 1.0186 - val_accuracy: 0.6942 - val_loss: 0.8567\n",
            "Epoch 62/100\n",
            "16/16 - 146s - 9s/step - accuracy: 0.5496 - loss: 0.9861 - val_accuracy: 0.7025 - val_loss: 0.8557\n",
            "Epoch 63/100\n",
            "16/16 - 145s - 9s/step - accuracy: 0.5124 - loss: 0.9900 - val_accuracy: 0.6612 - val_loss: 0.8579\n",
            "Epoch 64/100\n",
            "16/16 - 145s - 9s/step - accuracy: 0.5475 - loss: 0.9837 - val_accuracy: 0.6612 - val_loss: 0.8569\n",
            "Epoch 65/100\n",
            "16/16 - 144s - 9s/step - accuracy: 0.5579 - loss: 0.9376 - val_accuracy: 0.6612 - val_loss: 0.8534\n",
            "Epoch 66/100\n",
            "16/16 - 144s - 9s/step - accuracy: 0.5393 - loss: 0.9929 - val_accuracy: 0.6612 - val_loss: 0.8520\n",
            "Epoch 67/100\n",
            "16/16 - 147s - 9s/step - accuracy: 0.5393 - loss: 1.0000 - val_accuracy: 0.6694 - val_loss: 0.8521\n",
            "Epoch 68/100\n",
            "16/16 - 148s - 9s/step - accuracy: 0.5661 - loss: 0.9476 - val_accuracy: 0.6860 - val_loss: 0.8525\n",
            "Epoch 69/100\n",
            "16/16 - 147s - 9s/step - accuracy: 0.5785 - loss: 0.9354 - val_accuracy: 0.6860 - val_loss: 0.8515\n",
            "Epoch 70/100\n",
            "16/16 - 159s - 10s/step - accuracy: 0.5186 - loss: 0.9672 - val_accuracy: 0.6942 - val_loss: 0.8504\n",
            "Epoch 71/100\n",
            "16/16 - 190s - 12s/step - accuracy: 0.5248 - loss: 0.9544 - val_accuracy: 0.6777 - val_loss: 0.8500\n",
            "Epoch 72/100\n",
            "16/16 - 148s - 9s/step - accuracy: 0.5455 - loss: 0.9615 - val_accuracy: 0.6777 - val_loss: 0.8490\n",
            "Epoch 73/100\n",
            "16/16 - 148s - 9s/step - accuracy: 0.5620 - loss: 0.9406 - val_accuracy: 0.6777 - val_loss: 0.8467\n",
            "Epoch 74/100\n",
            "16/16 - 147s - 9s/step - accuracy: 0.5269 - loss: 0.9699 - val_accuracy: 0.6860 - val_loss: 0.8461\n",
            "Epoch 75/100\n",
            "16/16 - 144s - 9s/step - accuracy: 0.5599 - loss: 0.9294 - val_accuracy: 0.6860 - val_loss: 0.8478\n",
            "Epoch 76/100\n",
            "16/16 - 146s - 9s/step - accuracy: 0.5475 - loss: 0.9767 - val_accuracy: 0.6529 - val_loss: 0.8491\n",
            "Epoch 77/100\n",
            "16/16 - 145s - 9s/step - accuracy: 0.5372 - loss: 0.9644 - val_accuracy: 0.6612 - val_loss: 0.8484\n",
            "Epoch 78/100\n",
            "16/16 - 148s - 9s/step - accuracy: 0.5248 - loss: 0.9526 - val_accuracy: 0.6612 - val_loss: 0.8466\n",
            "Epoch 79/100\n",
            "16/16 - 145s - 9s/step - accuracy: 0.5455 - loss: 0.9371 - val_accuracy: 0.6777 - val_loss: 0.8455\n",
            "Epoch 80/100\n",
            "16/16 - 202s - 13s/step - accuracy: 0.5682 - loss: 0.9316 - val_accuracy: 0.6694 - val_loss: 0.8441\n",
            "Epoch 81/100\n",
            "16/16 - 152s - 10s/step - accuracy: 0.5661 - loss: 0.9175 - val_accuracy: 0.6777 - val_loss: 0.8400\n",
            "Epoch 82/100\n",
            "16/16 - 147s - 9s/step - accuracy: 0.5909 - loss: 0.9344 - val_accuracy: 0.6860 - val_loss: 0.8376\n",
            "Epoch 83/100\n",
            "16/16 - 158s - 10s/step - accuracy: 0.5517 - loss: 0.9311 - val_accuracy: 0.6860 - val_loss: 0.8359\n",
            "Epoch 84/100\n",
            "16/16 - 143s - 9s/step - accuracy: 0.5992 - loss: 0.9116 - val_accuracy: 0.6860 - val_loss: 0.8364\n",
            "Epoch 85/100\n",
            "16/16 - 145s - 9s/step - accuracy: 0.5579 - loss: 0.9555 - val_accuracy: 0.6860 - val_loss: 0.8338\n",
            "Epoch 86/100\n",
            "16/16 - 158s - 10s/step - accuracy: 0.5558 - loss: 0.9522 - val_accuracy: 0.7025 - val_loss: 0.8307\n",
            "Epoch 87/100\n",
            "16/16 - 143s - 9s/step - accuracy: 0.5413 - loss: 0.9400 - val_accuracy: 0.7025 - val_loss: 0.8293\n",
            "Epoch 88/100\n",
            "16/16 - 203s - 13s/step - accuracy: 0.5764 - loss: 0.9208 - val_accuracy: 0.7107 - val_loss: 0.8271\n",
            "Epoch 89/100\n",
            "16/16 - 144s - 9s/step - accuracy: 0.5640 - loss: 0.9230 - val_accuracy: 0.7107 - val_loss: 0.8255\n",
            "Epoch 90/100\n",
            "16/16 - 156s - 10s/step - accuracy: 0.5702 - loss: 0.9057 - val_accuracy: 0.7107 - val_loss: 0.8253\n",
            "Epoch 91/100\n",
            "16/16 - 145s - 9s/step - accuracy: 0.5847 - loss: 0.9372 - val_accuracy: 0.7025 - val_loss: 0.8240\n",
            "Epoch 92/100\n",
            "16/16 - 144s - 9s/step - accuracy: 0.5517 - loss: 0.9564 - val_accuracy: 0.6942 - val_loss: 0.8218\n",
            "Epoch 93/100\n",
            "16/16 - 157s - 10s/step - accuracy: 0.5888 - loss: 0.9255 - val_accuracy: 0.6860 - val_loss: 0.8212\n",
            "Epoch 94/100\n",
            "16/16 - 157s - 10s/step - accuracy: 0.5599 - loss: 0.9192 - val_accuracy: 0.6942 - val_loss: 0.8183\n",
            "Epoch 95/100\n",
            "16/16 - 143s - 9s/step - accuracy: 0.5764 - loss: 0.9432 - val_accuracy: 0.6942 - val_loss: 0.8164\n",
            "Epoch 96/100\n",
            "16/16 - 144s - 9s/step - accuracy: 0.5744 - loss: 0.9772 - val_accuracy: 0.6942 - val_loss: 0.8157\n",
            "Epoch 97/100\n",
            "16/16 - 156s - 10s/step - accuracy: 0.5310 - loss: 1.0208 - val_accuracy: 0.6942 - val_loss: 0.8167\n",
            "Epoch 98/100\n",
            "16/16 - 204s - 13s/step - accuracy: 0.5620 - loss: 0.9211 - val_accuracy: 0.7025 - val_loss: 0.8180\n",
            "Epoch 99/100\n",
            "16/16 - 156s - 10s/step - accuracy: 0.5909 - loss: 0.9443 - val_accuracy: 0.7107 - val_loss: 0.8185\n",
            "Epoch 100/100\n",
            "16/16 - 146s - 9s/step - accuracy: 0.5847 - loss: 0.9387 - val_accuracy: 0.7025 - val_loss: 0.8172\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model berhasil disimpan: model_split80_lr0.0001_ep100_l20.0001.h5\n"
          ]
        }
      ],
      "source": [
        "split_ratio = 0.8\n",
        "split_percent = round(split_ratio * 100)\n",
        "\n",
        "for lr in [0.0001]:\n",
        "    for epoch in [100]:\n",
        "        print(f\"\\n📦 Training model dengan split_ratio={split_percent}%, learning_rate={lr}, epochs={epoch}\")\n",
        "\n",
        "        model, history = train_model(\n",
        "            split_ratio=split_ratio,\n",
        "            lr=lr,\n",
        "            epochs=epoch\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OIQGHNS52DMh",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIQGHNS52DMh",
        "outputId": "81d3ea2a-9733-46ce-88f0-e6d24f2bad1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📦 Training model dengan split_ratio=80%, learning_rate=0.0001, epochs=200\n",
            "Found 484 images belonging to 3 classes.\n",
            "Found 121 images belonging to 3 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "16/16 - 92s - 6s/step - accuracy: 0.2934 - loss: 1.9952 - val_accuracy: 0.3306 - val_loss: 1.1315\n",
            "Epoch 2/200\n",
            "16/16 - 82s - 5s/step - accuracy: 0.3347 - loss: 1.8883 - val_accuracy: 0.4132 - val_loss: 1.0596\n",
            "Epoch 3/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.3285 - loss: 1.7034 - val_accuracy: 0.4545 - val_loss: 1.0089\n",
            "Epoch 4/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.3616 - loss: 1.5372 - val_accuracy: 0.5124 - val_loss: 0.9816\n",
            "Epoch 5/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.3843 - loss: 1.5084 - val_accuracy: 0.5289 - val_loss: 0.9651\n",
            "Epoch 6/200\n",
            "16/16 - 87s - 5s/step - accuracy: 0.4174 - loss: 1.4989 - val_accuracy: 0.5207 - val_loss: 0.9610\n",
            "Epoch 7/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.4050 - loss: 1.4207 - val_accuracy: 0.5455 - val_loss: 0.9499\n",
            "Epoch 8/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.4153 - loss: 1.4007 - val_accuracy: 0.5455 - val_loss: 0.9431\n",
            "Epoch 9/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.4318 - loss: 1.3561 - val_accuracy: 0.5455 - val_loss: 0.9368\n",
            "Epoch 10/200\n",
            "16/16 - 87s - 5s/step - accuracy: 0.4339 - loss: 1.1998 - val_accuracy: 0.5455 - val_loss: 0.9288\n",
            "Epoch 11/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.4277 - loss: 1.2809 - val_accuracy: 0.5620 - val_loss: 0.9224\n",
            "Epoch 12/200\n",
            "16/16 - 85s - 5s/step - accuracy: 0.4339 - loss: 1.2340 - val_accuracy: 0.5950 - val_loss: 0.9167\n",
            "Epoch 13/200\n",
            "16/16 - 142s - 9s/step - accuracy: 0.4587 - loss: 1.2376 - val_accuracy: 0.5868 - val_loss: 0.9136\n",
            "Epoch 14/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.4318 - loss: 1.2099 - val_accuracy: 0.5868 - val_loss: 0.9107\n",
            "Epoch 15/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.4463 - loss: 1.2197 - val_accuracy: 0.5868 - val_loss: 0.9144\n",
            "Epoch 16/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.4587 - loss: 1.1505 - val_accuracy: 0.6033 - val_loss: 0.9071\n",
            "Epoch 17/200\n",
            "16/16 - 87s - 5s/step - accuracy: 0.4690 - loss: 1.1381 - val_accuracy: 0.6198 - val_loss: 0.9037\n",
            "Epoch 18/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.4587 - loss: 1.1648 - val_accuracy: 0.6116 - val_loss: 0.8987\n",
            "Epoch 19/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.4566 - loss: 1.1926 - val_accuracy: 0.6364 - val_loss: 0.8982\n",
            "Epoch 20/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.4731 - loss: 1.1477 - val_accuracy: 0.6116 - val_loss: 0.8995\n",
            "Epoch 21/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.4649 - loss: 1.1108 - val_accuracy: 0.6446 - val_loss: 0.8941\n",
            "Epoch 22/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.4835 - loss: 1.1301 - val_accuracy: 0.6612 - val_loss: 0.8926\n",
            "Epoch 23/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.4711 - loss: 1.1116 - val_accuracy: 0.6529 - val_loss: 0.8906\n",
            "Epoch 24/200\n",
            "16/16 - 88s - 5s/step - accuracy: 0.4959 - loss: 1.1198 - val_accuracy: 0.6364 - val_loss: 0.8891\n",
            "Epoch 25/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.4752 - loss: 1.1015 - val_accuracy: 0.6033 - val_loss: 0.8930\n",
            "Epoch 26/200\n",
            "16/16 - 88s - 5s/step - accuracy: 0.4607 - loss: 1.1055 - val_accuracy: 0.6033 - val_loss: 0.8940\n",
            "Epoch 27/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.4628 - loss: 1.1428 - val_accuracy: 0.6033 - val_loss: 0.8945\n",
            "Epoch 28/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.4835 - loss: 1.0951 - val_accuracy: 0.6116 - val_loss: 0.8942\n",
            "Epoch 29/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.5041 - loss: 1.0241 - val_accuracy: 0.6116 - val_loss: 0.8931\n",
            "Epoch 30/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.4938 - loss: 1.0940 - val_accuracy: 0.6364 - val_loss: 0.8915\n",
            "Epoch 31/200\n",
            "16/16 - 108s - 7s/step - accuracy: 0.4835 - loss: 1.0553 - val_accuracy: 0.6281 - val_loss: 0.8933\n",
            "Epoch 32/200\n",
            "16/16 - 85s - 5s/step - accuracy: 0.5227 - loss: 1.0409 - val_accuracy: 0.6116 - val_loss: 0.8938\n",
            "Epoch 33/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.4731 - loss: 1.0901 - val_accuracy: 0.6116 - val_loss: 0.8936\n",
            "Epoch 34/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.5145 - loss: 1.0419 - val_accuracy: 0.6033 - val_loss: 0.8917\n",
            "Epoch 35/200\n",
            "16/16 - 85s - 5s/step - accuracy: 0.4876 - loss: 1.0754 - val_accuracy: 0.6198 - val_loss: 0.8914\n",
            "Epoch 36/200\n",
            "16/16 - 85s - 5s/step - accuracy: 0.5269 - loss: 1.0359 - val_accuracy: 0.6116 - val_loss: 0.8918\n",
            "Epoch 37/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.5062 - loss: 1.0606 - val_accuracy: 0.6198 - val_loss: 0.8932\n",
            "Epoch 38/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.5000 - loss: 1.0483 - val_accuracy: 0.5785 - val_loss: 0.8934\n",
            "Epoch 39/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.5145 - loss: 1.0334 - val_accuracy: 0.6116 - val_loss: 0.8927\n",
            "Epoch 40/200\n",
            "16/16 - 140s - 9s/step - accuracy: 0.5579 - loss: 0.9867 - val_accuracy: 0.6116 - val_loss: 0.8929\n",
            "Epoch 41/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.5248 - loss: 0.9851 - val_accuracy: 0.6033 - val_loss: 0.8892\n",
            "Epoch 42/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.5186 - loss: 1.0177 - val_accuracy: 0.6198 - val_loss: 0.8908\n",
            "Epoch 43/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.5124 - loss: 1.0178 - val_accuracy: 0.5950 - val_loss: 0.8911\n",
            "Epoch 44/200\n",
            "16/16 - 87s - 5s/step - accuracy: 0.5248 - loss: 1.0032 - val_accuracy: 0.5950 - val_loss: 0.8905\n",
            "Epoch 45/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.5227 - loss: 0.9788 - val_accuracy: 0.5950 - val_loss: 0.8881\n",
            "Epoch 46/200\n",
            "16/16 - 88s - 5s/step - accuracy: 0.5165 - loss: 1.0152 - val_accuracy: 0.6033 - val_loss: 0.8852\n",
            "Epoch 47/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.5227 - loss: 0.9865 - val_accuracy: 0.6198 - val_loss: 0.8829\n",
            "Epoch 48/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.5248 - loss: 0.9795 - val_accuracy: 0.6446 - val_loss: 0.8805\n",
            "Epoch 49/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.5083 - loss: 1.0060 - val_accuracy: 0.6529 - val_loss: 0.8811\n",
            "Epoch 50/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.5393 - loss: 1.0089 - val_accuracy: 0.6281 - val_loss: 0.8794\n",
            "Epoch 51/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.5661 - loss: 0.9584 - val_accuracy: 0.6529 - val_loss: 0.8731\n",
            "Epoch 52/200\n",
            "16/16 - 87s - 5s/step - accuracy: 0.5331 - loss: 0.9943 - val_accuracy: 0.6529 - val_loss: 0.8691\n",
            "Epoch 53/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.5331 - loss: 0.9563 - val_accuracy: 0.6694 - val_loss: 0.8648\n",
            "Epoch 54/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.5145 - loss: 1.0122 - val_accuracy: 0.6694 - val_loss: 0.8639\n",
            "Epoch 55/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.5289 - loss: 0.9959 - val_accuracy: 0.6694 - val_loss: 0.8636\n",
            "Epoch 56/200\n",
            "16/16 - 142s - 9s/step - accuracy: 0.5496 - loss: 1.0068 - val_accuracy: 0.6612 - val_loss: 0.8619\n",
            "Epoch 57/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.5289 - loss: 0.9816 - val_accuracy: 0.6612 - val_loss: 0.8598\n",
            "Epoch 58/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.5579 - loss: 0.9738 - val_accuracy: 0.6612 - val_loss: 0.8606\n",
            "Epoch 59/200\n",
            "16/16 - 101s - 6s/step - accuracy: 0.5517 - loss: 0.9768 - val_accuracy: 0.6777 - val_loss: 0.8601\n",
            "Epoch 60/200\n",
            "16/16 - 125s - 8s/step - accuracy: 0.5475 - loss: 0.9603 - val_accuracy: 0.6529 - val_loss: 0.8618\n",
            "Epoch 61/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.5269 - loss: 0.9732 - val_accuracy: 0.6364 - val_loss: 0.8625\n",
            "Epoch 62/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.5744 - loss: 0.9738 - val_accuracy: 0.6612 - val_loss: 0.8595\n",
            "Epoch 63/200\n",
            "16/16 - 143s - 9s/step - accuracy: 0.5207 - loss: 0.9734 - val_accuracy: 0.6777 - val_loss: 0.8561\n",
            "Epoch 64/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.5475 - loss: 0.9670 - val_accuracy: 0.6694 - val_loss: 0.8553\n",
            "Epoch 65/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.5124 - loss: 0.9875 - val_accuracy: 0.6777 - val_loss: 0.8535\n",
            "Epoch 66/200\n",
            "16/16 - 87s - 5s/step - accuracy: 0.5868 - loss: 0.9294 - val_accuracy: 0.6777 - val_loss: 0.8508\n",
            "Epoch 67/200\n",
            "16/16 - 87s - 5s/step - accuracy: 0.5930 - loss: 0.9185 - val_accuracy: 0.6860 - val_loss: 0.8490\n",
            "Epoch 68/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.5331 - loss: 0.9429 - val_accuracy: 0.6777 - val_loss: 0.8498\n",
            "Epoch 69/200\n",
            "16/16 - 87s - 5s/step - accuracy: 0.5393 - loss: 0.9880 - val_accuracy: 0.6529 - val_loss: 0.8513\n",
            "Epoch 70/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.5744 - loss: 0.9450 - val_accuracy: 0.6777 - val_loss: 0.8508\n",
            "Epoch 71/200\n",
            "16/16 - 82s - 5s/step - accuracy: 0.5640 - loss: 0.9375 - val_accuracy: 0.6942 - val_loss: 0.8492\n",
            "Epoch 72/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.5455 - loss: 0.9549 - val_accuracy: 0.7025 - val_loss: 0.8474\n",
            "Epoch 73/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.5372 - loss: 0.9765 - val_accuracy: 0.6694 - val_loss: 0.8485\n",
            "Epoch 74/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.5682 - loss: 0.9603 - val_accuracy: 0.6860 - val_loss: 0.8477\n",
            "Epoch 75/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.5579 - loss: 0.9668 - val_accuracy: 0.6942 - val_loss: 0.8467\n",
            "Epoch 76/200\n",
            "16/16 - 141s - 9s/step - accuracy: 0.5393 - loss: 0.9649 - val_accuracy: 0.6942 - val_loss: 0.8460\n",
            "Epoch 77/200\n",
            "16/16 - 82s - 5s/step - accuracy: 0.5888 - loss: 0.9162 - val_accuracy: 0.6942 - val_loss: 0.8430\n",
            "Epoch 78/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.5455 - loss: 0.9681 - val_accuracy: 0.7025 - val_loss: 0.8406\n",
            "Epoch 79/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.5434 - loss: 0.9822 - val_accuracy: 0.6942 - val_loss: 0.8392\n",
            "Epoch 80/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.5620 - loss: 0.9313 - val_accuracy: 0.6942 - val_loss: 0.8360\n",
            "Epoch 81/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.5826 - loss: 0.9110 - val_accuracy: 0.6694 - val_loss: 0.8338\n",
            "Epoch 82/200\n",
            "16/16 - 82s - 5s/step - accuracy: 0.5806 - loss: 0.9138 - val_accuracy: 0.7025 - val_loss: 0.8297\n",
            "Epoch 83/200\n",
            "16/16 - 86s - 5s/step - accuracy: 0.5723 - loss: 0.9132 - val_accuracy: 0.6942 - val_loss: 0.8279\n",
            "Epoch 84/200\n",
            "16/16 - 86s - 5s/step - accuracy: 0.5661 - loss: 0.9462 - val_accuracy: 0.7025 - val_loss: 0.8262\n",
            "Epoch 85/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.5702 - loss: 0.9439 - val_accuracy: 0.7107 - val_loss: 0.8221\n",
            "Epoch 86/200\n",
            "16/16 - 81s - 5s/step - accuracy: 0.5888 - loss: 0.8990 - val_accuracy: 0.7190 - val_loss: 0.8183\n",
            "Epoch 87/200\n",
            "16/16 - 82s - 5s/step - accuracy: 0.5558 - loss: 0.9448 - val_accuracy: 0.7107 - val_loss: 0.8176\n",
            "Epoch 88/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.6033 - loss: 0.9032 - val_accuracy: 0.6942 - val_loss: 0.8170\n",
            "Epoch 89/200\n",
            "16/16 - 82s - 5s/step - accuracy: 0.5847 - loss: 0.9297 - val_accuracy: 0.6860 - val_loss: 0.8176\n",
            "Epoch 90/200\n",
            "16/16 - 82s - 5s/step - accuracy: 0.5640 - loss: 0.9770 - val_accuracy: 0.6777 - val_loss: 0.8162\n",
            "Epoch 91/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.5620 - loss: 0.9428 - val_accuracy: 0.6860 - val_loss: 0.8158\n",
            "Epoch 92/200\n",
            "16/16 - 82s - 5s/step - accuracy: 0.5764 - loss: 0.9409 - val_accuracy: 0.6860 - val_loss: 0.8142\n",
            "Epoch 93/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.5723 - loss: 0.9251 - val_accuracy: 0.7273 - val_loss: 0.8123\n",
            "Epoch 94/200\n",
            "16/16 - 141s - 9s/step - accuracy: 0.5764 - loss: 0.8954 - val_accuracy: 0.7521 - val_loss: 0.8092\n",
            "Epoch 95/200\n",
            "16/16 - 82s - 5s/step - accuracy: 0.5661 - loss: 0.9029 - val_accuracy: 0.7273 - val_loss: 0.8096\n",
            "Epoch 96/200\n",
            "16/16 - 86s - 5s/step - accuracy: 0.5620 - loss: 0.9516 - val_accuracy: 0.7438 - val_loss: 0.8091\n",
            "Epoch 97/200\n",
            "16/16 - 86s - 5s/step - accuracy: 0.5909 - loss: 0.9049 - val_accuracy: 0.7355 - val_loss: 0.8091\n",
            "Epoch 98/200\n",
            "16/16 - 82s - 5s/step - accuracy: 0.6095 - loss: 0.8953 - val_accuracy: 0.7190 - val_loss: 0.8092\n",
            "Epoch 99/200\n",
            "16/16 - 82s - 5s/step - accuracy: 0.5806 - loss: 0.9060 - val_accuracy: 0.7521 - val_loss: 0.8052\n",
            "Epoch 100/200\n",
            "16/16 - 82s - 5s/step - accuracy: 0.5744 - loss: 0.9325 - val_accuracy: 0.7438 - val_loss: 0.8039\n",
            "Epoch 101/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.5909 - loss: 0.9096 - val_accuracy: 0.7355 - val_loss: 0.8017\n",
            "Epoch 102/200\n",
            "16/16 - 82s - 5s/step - accuracy: 0.5537 - loss: 0.9649 - val_accuracy: 0.7355 - val_loss: 0.8016\n",
            "Epoch 103/200\n",
            "16/16 - 82s - 5s/step - accuracy: 0.6054 - loss: 0.8814 - val_accuracy: 0.7438 - val_loss: 0.8025\n",
            "Epoch 104/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.5847 - loss: 0.9111 - val_accuracy: 0.7273 - val_loss: 0.8033\n",
            "Epoch 105/200\n",
            "16/16 - 86s - 5s/step - accuracy: 0.5868 - loss: 0.8974 - val_accuracy: 0.7190 - val_loss: 0.8030\n",
            "Epoch 106/200\n",
            "16/16 - 82s - 5s/step - accuracy: 0.5785 - loss: 0.9177 - val_accuracy: 0.6942 - val_loss: 0.8024\n",
            "Epoch 107/200\n",
            "16/16 - 143s - 9s/step - accuracy: 0.5702 - loss: 0.8950 - val_accuracy: 0.6860 - val_loss: 0.8028\n",
            "Epoch 108/200\n",
            "16/16 - 82s - 5s/step - accuracy: 0.5785 - loss: 0.9185 - val_accuracy: 0.6777 - val_loss: 0.8021\n",
            "Epoch 109/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.5558 - loss: 0.9407 - val_accuracy: 0.6777 - val_loss: 0.8026\n",
            "Epoch 110/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.5579 - loss: 0.9604 - val_accuracy: 0.6777 - val_loss: 0.8039\n",
            "Epoch 111/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.5455 - loss: 0.9508 - val_accuracy: 0.6777 - val_loss: 0.8032\n",
            "Epoch 112/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.5847 - loss: 0.8969 - val_accuracy: 0.6694 - val_loss: 0.8027\n",
            "Epoch 113/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.5826 - loss: 0.8844 - val_accuracy: 0.6777 - val_loss: 0.8024\n",
            "Epoch 114/200\n",
            "16/16 - 82s - 5s/step - accuracy: 0.5888 - loss: 0.9021 - val_accuracy: 0.6942 - val_loss: 0.8027\n",
            "Epoch 115/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.5868 - loss: 0.8943 - val_accuracy: 0.6942 - val_loss: 0.7997\n",
            "Epoch 116/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.5868 - loss: 0.9166 - val_accuracy: 0.6942 - val_loss: 0.7994\n",
            "Epoch 117/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.5868 - loss: 0.8869 - val_accuracy: 0.6860 - val_loss: 0.7985\n",
            "Epoch 118/200\n",
            "16/16 - 87s - 5s/step - accuracy: 0.5620 - loss: 0.8968 - val_accuracy: 0.6860 - val_loss: 0.7985\n",
            "Epoch 119/200\n",
            "16/16 - 86s - 5s/step - accuracy: 0.5992 - loss: 0.8772 - val_accuracy: 0.6694 - val_loss: 0.7951\n",
            "Epoch 120/200\n",
            "16/16 - 82s - 5s/step - accuracy: 0.5372 - loss: 0.9388 - val_accuracy: 0.6777 - val_loss: 0.7923\n",
            "Epoch 121/200\n",
            "16/16 - 82s - 5s/step - accuracy: 0.5888 - loss: 0.8766 - val_accuracy: 0.6777 - val_loss: 0.7905\n",
            "Epoch 122/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.5888 - loss: 0.8961 - val_accuracy: 0.6942 - val_loss: 0.7889\n",
            "Epoch 123/200\n",
            "16/16 - 82s - 5s/step - accuracy: 0.6033 - loss: 0.8891 - val_accuracy: 0.6942 - val_loss: 0.7884\n",
            "Epoch 124/200\n",
            "16/16 - 82s - 5s/step - accuracy: 0.5702 - loss: 0.9436 - val_accuracy: 0.6942 - val_loss: 0.7882\n",
            "Epoch 125/200\n",
            "16/16 - 143s - 9s/step - accuracy: 0.5517 - loss: 0.9087 - val_accuracy: 0.7273 - val_loss: 0.7872\n",
            "Epoch 126/200\n",
            "16/16 - 145s - 9s/step - accuracy: 0.6095 - loss: 0.8885 - val_accuracy: 0.7273 - val_loss: 0.7873\n",
            "Epoch 127/200\n",
            "16/16 - 87s - 5s/step - accuracy: 0.6095 - loss: 0.9346 - val_accuracy: 0.7190 - val_loss: 0.7852\n",
            "Epoch 128/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.5992 - loss: 0.8874 - val_accuracy: 0.7107 - val_loss: 0.7820\n",
            "Epoch 129/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.5950 - loss: 0.9086 - val_accuracy: 0.7273 - val_loss: 0.7814\n",
            "Epoch 130/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.6116 - loss: 0.8673 - val_accuracy: 0.7273 - val_loss: 0.7804\n",
            "Epoch 131/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.6198 - loss: 0.8718 - val_accuracy: 0.7190 - val_loss: 0.7773\n",
            "Epoch 132/200\n",
            "16/16 - 82s - 5s/step - accuracy: 0.5992 - loss: 0.8785 - val_accuracy: 0.7107 - val_loss: 0.7780\n",
            "Epoch 133/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.5992 - loss: 0.9161 - val_accuracy: 0.6942 - val_loss: 0.7797\n",
            "Epoch 134/200\n",
            "16/16 - 82s - 5s/step - accuracy: 0.6198 - loss: 0.8528 - val_accuracy: 0.7107 - val_loss: 0.7793\n",
            "Epoch 135/200\n",
            "16/16 - 86s - 5s/step - accuracy: 0.6095 - loss: 0.8716 - val_accuracy: 0.7025 - val_loss: 0.7768\n",
            "Epoch 136/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.6219 - loss: 0.8743 - val_accuracy: 0.7025 - val_loss: 0.7752\n",
            "Epoch 137/200\n",
            "16/16 - 82s - 5s/step - accuracy: 0.6054 - loss: 0.8693 - val_accuracy: 0.6942 - val_loss: 0.7738\n",
            "Epoch 138/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.5950 - loss: 0.8987 - val_accuracy: 0.7025 - val_loss: 0.7722\n",
            "Epoch 139/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.5909 - loss: 0.8814 - val_accuracy: 0.7107 - val_loss: 0.7712\n",
            "Epoch 140/200\n",
            "16/16 - 82s - 5s/step - accuracy: 0.6219 - loss: 0.8755 - val_accuracy: 0.7025 - val_loss: 0.7689\n",
            "Epoch 141/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.5868 - loss: 0.9231 - val_accuracy: 0.7190 - val_loss: 0.7674\n",
            "Epoch 142/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.6240 - loss: 0.8250 - val_accuracy: 0.7273 - val_loss: 0.7670\n",
            "Epoch 143/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.6136 - loss: 0.8734 - val_accuracy: 0.7273 - val_loss: 0.7646\n",
            "Epoch 144/200\n",
            "16/16 - 82s - 5s/step - accuracy: 0.6012 - loss: 0.8799 - val_accuracy: 0.7355 - val_loss: 0.7632\n",
            "Epoch 145/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.6178 - loss: 0.8573 - val_accuracy: 0.7273 - val_loss: 0.7612\n",
            "Epoch 146/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.6281 - loss: 0.8608 - val_accuracy: 0.7273 - val_loss: 0.7582\n",
            "Epoch 147/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.6322 - loss: 0.8798 - val_accuracy: 0.7273 - val_loss: 0.7574\n",
            "Epoch 148/200\n",
            "16/16 - 82s - 5s/step - accuracy: 0.6136 - loss: 0.8600 - val_accuracy: 0.7355 - val_loss: 0.7553\n",
            "Epoch 149/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.5888 - loss: 0.8599 - val_accuracy: 0.7355 - val_loss: 0.7552\n",
            "Epoch 150/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.6054 - loss: 0.8869 - val_accuracy: 0.7273 - val_loss: 0.7567\n",
            "Epoch 151/200\n",
            "16/16 - 82s - 5s/step - accuracy: 0.6012 - loss: 0.8427 - val_accuracy: 0.7273 - val_loss: 0.7582\n",
            "Epoch 152/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.5888 - loss: 0.8864 - val_accuracy: 0.7107 - val_loss: 0.7583\n",
            "Epoch 153/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.6446 - loss: 0.8344 - val_accuracy: 0.7190 - val_loss: 0.7572\n",
            "Epoch 154/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.5888 - loss: 0.8970 - val_accuracy: 0.7107 - val_loss: 0.7556\n",
            "Epoch 155/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.6426 - loss: 0.8433 - val_accuracy: 0.7025 - val_loss: 0.7529\n",
            "Epoch 156/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.6116 - loss: 0.8590 - val_accuracy: 0.7107 - val_loss: 0.7520\n",
            "Epoch 157/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.6095 - loss: 0.8629 - val_accuracy: 0.7355 - val_loss: 0.7526\n",
            "Epoch 158/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.6095 - loss: 0.8745 - val_accuracy: 0.7438 - val_loss: 0.7513\n",
            "Epoch 159/200\n",
            "16/16 - 82s - 5s/step - accuracy: 0.6302 - loss: 0.8556 - val_accuracy: 0.7355 - val_loss: 0.7517\n",
            "Epoch 160/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.6178 - loss: 0.8190 - val_accuracy: 0.7273 - val_loss: 0.7497\n",
            "Epoch 161/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.6219 - loss: 0.8419 - val_accuracy: 0.7521 - val_loss: 0.7476\n",
            "Epoch 162/200\n",
            "16/16 - 86s - 5s/step - accuracy: 0.6198 - loss: 0.8564 - val_accuracy: 0.7438 - val_loss: 0.7451\n",
            "Epoch 163/200\n",
            "16/16 - 82s - 5s/step - accuracy: 0.6260 - loss: 0.8425 - val_accuracy: 0.7438 - val_loss: 0.7447\n",
            "Epoch 164/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.6364 - loss: 0.8559 - val_accuracy: 0.7355 - val_loss: 0.7446\n",
            "Epoch 165/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.5971 - loss: 0.8580 - val_accuracy: 0.7355 - val_loss: 0.7436\n",
            "Epoch 166/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.6343 - loss: 0.8278 - val_accuracy: 0.7438 - val_loss: 0.7408\n",
            "Epoch 167/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.6198 - loss: 0.8589 - val_accuracy: 0.7273 - val_loss: 0.7386\n",
            "Epoch 168/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.6116 - loss: 0.8496 - val_accuracy: 0.7273 - val_loss: 0.7375\n",
            "Epoch 169/200\n",
            "16/16 - 82s - 5s/step - accuracy: 0.6095 - loss: 0.8740 - val_accuracy: 0.7438 - val_loss: 0.7363\n",
            "Epoch 170/200\n",
            "16/16 - 87s - 5s/step - accuracy: 0.6364 - loss: 0.8364 - val_accuracy: 0.7273 - val_loss: 0.7372\n",
            "Epoch 171/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.6426 - loss: 0.8295 - val_accuracy: 0.7273 - val_loss: 0.7382\n",
            "Epoch 172/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.6240 - loss: 0.8734 - val_accuracy: 0.7273 - val_loss: 0.7381\n",
            "Epoch 173/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.6715 - loss: 0.8050 - val_accuracy: 0.7438 - val_loss: 0.7375\n",
            "Epoch 174/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.6426 - loss: 0.8261 - val_accuracy: 0.7438 - val_loss: 0.7349\n",
            "Epoch 175/200\n",
            "16/16 - 86s - 5s/step - accuracy: 0.6136 - loss: 0.8748 - val_accuracy: 0.7521 - val_loss: 0.7337\n",
            "Epoch 176/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.6426 - loss: 0.8306 - val_accuracy: 0.7521 - val_loss: 0.7327\n",
            "Epoch 177/200\n",
            "16/16 - 81s - 5s/step - accuracy: 0.6384 - loss: 0.8158 - val_accuracy: 0.7521 - val_loss: 0.7316\n",
            "Epoch 178/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.6095 - loss: 0.8614 - val_accuracy: 0.7603 - val_loss: 0.7319\n",
            "Epoch 179/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.6322 - loss: 0.8302 - val_accuracy: 0.7769 - val_loss: 0.7309\n",
            "Epoch 180/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.6384 - loss: 0.8377 - val_accuracy: 0.7521 - val_loss: 0.7312\n",
            "Epoch 181/200\n",
            "16/16 - 84s - 5s/step - accuracy: 0.5950 - loss: 0.8497 - val_accuracy: 0.7686 - val_loss: 0.7306\n",
            "Epoch 182/200\n",
            "16/16 - 82s - 5s/step - accuracy: 0.6095 - loss: 0.8831 - val_accuracy: 0.7603 - val_loss: 0.7309\n",
            "Epoch 183/200\n",
            "16/16 - 86s - 5s/step - accuracy: 0.6054 - loss: 0.8465 - val_accuracy: 0.7769 - val_loss: 0.7292\n",
            "Epoch 184/200\n",
            "16/16 - 87s - 5s/step - accuracy: 0.6260 - loss: 0.8713 - val_accuracy: 0.7438 - val_loss: 0.7313\n",
            "Epoch 185/200\n",
            "16/16 - 82s - 5s/step - accuracy: 0.6488 - loss: 0.8643 - val_accuracy: 0.7603 - val_loss: 0.7302\n",
            "Epoch 186/200\n",
            "16/16 - 142s - 9s/step - accuracy: 0.6178 - loss: 0.8820 - val_accuracy: 0.7603 - val_loss: 0.7321\n",
            "Epoch 187/200\n",
            "16/16 - 82s - 5s/step - accuracy: 0.6384 - loss: 0.8276 - val_accuracy: 0.7686 - val_loss: 0.7322\n",
            "Epoch 188/200\n",
            "16/16 - 82s - 5s/step - accuracy: 0.6260 - loss: 0.8292 - val_accuracy: 0.7603 - val_loss: 0.7276\n",
            "Epoch 189/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.6012 - loss: 0.8614 - val_accuracy: 0.7603 - val_loss: 0.7274\n",
            "Epoch 190/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.6136 - loss: 0.8613 - val_accuracy: 0.7521 - val_loss: 0.7279\n",
            "Epoch 191/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.6116 - loss: 0.8413 - val_accuracy: 0.7603 - val_loss: 0.7275\n",
            "Epoch 192/200\n",
            "16/16 - 143s - 9s/step - accuracy: 0.6074 - loss: 0.8357 - val_accuracy: 0.7521 - val_loss: 0.7252\n",
            "Epoch 193/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.6260 - loss: 0.8750 - val_accuracy: 0.7521 - val_loss: 0.7248\n",
            "Epoch 194/200\n",
            "16/16 - 86s - 5s/step - accuracy: 0.6095 - loss: 0.8507 - val_accuracy: 0.7603 - val_loss: 0.7279\n",
            "Epoch 195/200\n",
            "16/16 - 87s - 5s/step - accuracy: 0.6095 - loss: 0.8598 - val_accuracy: 0.7686 - val_loss: 0.7272\n",
            "Epoch 196/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.6550 - loss: 0.8221 - val_accuracy: 0.7521 - val_loss: 0.7258\n",
            "Epoch 197/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.6178 - loss: 0.8350 - val_accuracy: 0.7603 - val_loss: 0.7252\n",
            "Epoch 198/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.6488 - loss: 0.8257 - val_accuracy: 0.7355 - val_loss: 0.7264\n",
            "Epoch 199/200\n",
            "16/16 - 83s - 5s/step - accuracy: 0.6240 - loss: 0.8425 - val_accuracy: 0.7438 - val_loss: 0.7264\n",
            "Epoch 200/200\n",
            "16/16 - 82s - 5s/step - accuracy: 0.6116 - loss: 0.8011 - val_accuracy: 0.7355 - val_loss: 0.7251\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model berhasil disimpan: model_split80_lr0.0001_ep200_l20.0001.h5\n"
          ]
        }
      ],
      "source": [
        "split_ratio = 0.8\n",
        "split_percent = round(split_ratio * 100)\n",
        "\n",
        "for lr in [0.0001]:\n",
        "    for epoch in [200]:\n",
        "        print(f\"\\n📦 Training model dengan split_ratio={split_percent}%, learning_rate={lr}, epochs={epoch}\")\n",
        "\n",
        "        model, history = train_model(\n",
        "            split_ratio=split_ratio,\n",
        "            lr=lr,\n",
        "            epochs=epoch\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "H512suNlPI9o",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "H512suNlPI9o",
        "outputId": "c71df847-ee62-4217-c2bd-0cfbad1970d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📦 Training model dengan split_ratio=80%, learning_rate=0.0001, epochs=300\n",
            "Found 484 images belonging to 3 classes.\n",
            "Found 121 images belonging to 3 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "16/16 - 158s - 10s/step - accuracy: 0.3037 - loss: 2.1703 - val_accuracy: 0.3388 - val_loss: 1.2415\n",
            "Epoch 2/300\n",
            "16/16 - 127s - 8s/step - accuracy: 0.3244 - loss: 2.0826 - val_accuracy: 0.3967 - val_loss: 1.1412\n",
            "Epoch 3/300\n",
            "16/16 - 128s - 8s/step - accuracy: 0.3616 - loss: 1.8405 - val_accuracy: 0.4876 - val_loss: 1.0696\n",
            "Epoch 4/300\n",
            "16/16 - 132s - 8s/step - accuracy: 0.3740 - loss: 1.6884 - val_accuracy: 0.5041 - val_loss: 1.0435\n",
            "Epoch 5/300\n",
            "16/16 - 129s - 8s/step - accuracy: 0.3595 - loss: 1.6801 - val_accuracy: 0.4876 - val_loss: 1.0221\n",
            "Epoch 6/300\n",
            "16/16 - 128s - 8s/step - accuracy: 0.4112 - loss: 1.5344 - val_accuracy: 0.5289 - val_loss: 1.0049\n",
            "Epoch 7/300\n",
            "16/16 - 143s - 9s/step - accuracy: 0.4050 - loss: 1.4734 - val_accuracy: 0.5455 - val_loss: 0.9960\n",
            "Epoch 8/300\n",
            "16/16 - 131s - 8s/step - accuracy: 0.4504 - loss: 1.3872 - val_accuracy: 0.5702 - val_loss: 0.9744\n",
            "Epoch 9/300\n",
            "16/16 - 129s - 8s/step - accuracy: 0.4793 - loss: 1.3708 - val_accuracy: 0.5950 - val_loss: 0.9398\n",
            "Epoch 10/300\n",
            "16/16 - 129s - 8s/step - accuracy: 0.3946 - loss: 1.4694 - val_accuracy: 0.6364 - val_loss: 0.9328\n",
            "Epoch 11/300\n",
            "16/16 - 129s - 8s/step - accuracy: 0.4215 - loss: 1.3517 - val_accuracy: 0.6281 - val_loss: 0.9188\n",
            "Epoch 12/300\n",
            "16/16 - 129s - 8s/step - accuracy: 0.4607 - loss: 1.3048 - val_accuracy: 0.6198 - val_loss: 0.9122\n",
            "Epoch 13/300\n",
            "16/16 - 148s - 9s/step - accuracy: 0.4773 - loss: 1.2247 - val_accuracy: 0.6281 - val_loss: 0.8994\n",
            "Epoch 14/300\n",
            "16/16 - 129s - 8s/step - accuracy: 0.4628 - loss: 1.2834 - val_accuracy: 0.6446 - val_loss: 0.8913\n",
            "Epoch 15/300\n",
            "16/16 - 129s - 8s/step - accuracy: 0.4649 - loss: 1.2246 - val_accuracy: 0.6446 - val_loss: 0.8920\n",
            "Epoch 16/300\n",
            "16/16 - 143s - 9s/step - accuracy: 0.4339 - loss: 1.2818 - val_accuracy: 0.6364 - val_loss: 0.8879\n",
            "Epoch 17/300\n",
            "16/16 - 143s - 9s/step - accuracy: 0.4566 - loss: 1.2458 - val_accuracy: 0.6612 - val_loss: 0.8892\n",
            "Epoch 18/300\n",
            "16/16 - 129s - 8s/step - accuracy: 0.4566 - loss: 1.1602 - val_accuracy: 0.6529 - val_loss: 0.8879\n",
            "Epoch 19/300\n",
            "16/16 - 140s - 9s/step - accuracy: 0.4690 - loss: 1.1746 - val_accuracy: 0.6281 - val_loss: 0.8881\n",
            "Epoch 20/300\n",
            "16/16 - 143s - 9s/step - accuracy: 0.4897 - loss: 1.1072 - val_accuracy: 0.6364 - val_loss: 0.8848\n",
            "Epoch 21/300\n",
            "16/16 - 143s - 9s/step - accuracy: 0.4401 - loss: 1.1394 - val_accuracy: 0.6281 - val_loss: 0.8850\n",
            "Epoch 22/300\n",
            "16/16 - 134s - 8s/step - accuracy: 0.4835 - loss: 1.1209 - val_accuracy: 0.6116 - val_loss: 0.8906\n",
            "Epoch 23/300\n",
            "16/16 - 150s - 9s/step - accuracy: 0.5124 - loss: 1.1346 - val_accuracy: 0.5950 - val_loss: 0.8952\n",
            "Epoch 24/300\n",
            "16/16 - 145s - 9s/step - accuracy: 0.4876 - loss: 1.1490 - val_accuracy: 0.6116 - val_loss: 0.8912\n",
            "Epoch 25/300\n",
            "16/16 - 129s - 8s/step - accuracy: 0.4979 - loss: 1.0784 - val_accuracy: 0.6033 - val_loss: 0.8948\n",
            "Epoch 26/300\n",
            "16/16 - 146s - 9s/step - accuracy: 0.4897 - loss: 1.1442 - val_accuracy: 0.6033 - val_loss: 0.8944\n",
            "Epoch 27/300\n",
            "16/16 - 137s - 9s/step - accuracy: 0.4752 - loss: 1.0873 - val_accuracy: 0.6033 - val_loss: 0.8900\n",
            "Epoch 28/300\n",
            "16/16 - 129s - 8s/step - accuracy: 0.4793 - loss: 1.1111 - val_accuracy: 0.6198 - val_loss: 0.8864\n",
            "Epoch 29/300\n",
            "16/16 - 126s - 8s/step - accuracy: 0.5269 - loss: 1.0582 - val_accuracy: 0.6364 - val_loss: 0.8871\n",
            "Epoch 30/300\n",
            "16/16 - 158s - 10s/step - accuracy: 0.5000 - loss: 1.0653 - val_accuracy: 0.6281 - val_loss: 0.8870\n",
            "Epoch 31/300\n",
            "16/16 - 143s - 9s/step - accuracy: 0.5083 - loss: 1.0727 - val_accuracy: 0.6198 - val_loss: 0.8852\n",
            "Epoch 32/300\n",
            "16/16 - 128s - 8s/step - accuracy: 0.4938 - loss: 1.0335 - val_accuracy: 0.6281 - val_loss: 0.8817\n",
            "Epoch 33/300\n",
            "16/16 - 143s - 9s/step - accuracy: 0.5041 - loss: 1.0700 - val_accuracy: 0.6281 - val_loss: 0.8772\n",
            "Epoch 34/300\n",
            "16/16 - 129s - 8s/step - accuracy: 0.5310 - loss: 1.0771 - val_accuracy: 0.6281 - val_loss: 0.8743\n",
            "Epoch 35/300\n",
            "16/16 - 143s - 9s/step - accuracy: 0.5351 - loss: 1.0111 - val_accuracy: 0.6198 - val_loss: 0.8766\n",
            "Epoch 36/300\n",
            "16/16 - 127s - 8s/step - accuracy: 0.5289 - loss: 1.0431 - val_accuracy: 0.6281 - val_loss: 0.8761\n",
            "Epoch 37/300\n",
            "16/16 - 125s - 8s/step - accuracy: 0.5310 - loss: 1.0136 - val_accuracy: 0.6198 - val_loss: 0.8773\n",
            "Epoch 38/300\n",
            "16/16 - 129s - 8s/step - accuracy: 0.5248 - loss: 1.0130 - val_accuracy: 0.6116 - val_loss: 0.8749\n",
            "Epoch 39/300\n",
            "16/16 - 143s - 9s/step - accuracy: 0.5062 - loss: 1.0335 - val_accuracy: 0.6116 - val_loss: 0.8745\n",
            "Epoch 40/300\n",
            "16/16 - 126s - 8s/step - accuracy: 0.5165 - loss: 0.9963 - val_accuracy: 0.6116 - val_loss: 0.8704\n",
            "Epoch 41/300\n",
            "16/16 - 128s - 8s/step - accuracy: 0.5579 - loss: 0.9620 - val_accuracy: 0.6198 - val_loss: 0.8684\n",
            "Epoch 42/300\n",
            "16/16 - 143s - 9s/step - accuracy: 0.5165 - loss: 1.0426 - val_accuracy: 0.6116 - val_loss: 0.8676\n",
            "Epoch 43/300\n",
            "16/16 - 128s - 8s/step - accuracy: 0.5579 - loss: 0.9885 - val_accuracy: 0.6198 - val_loss: 0.8650\n",
            "Epoch 44/300\n",
            "16/16 - 128s - 8s/step - accuracy: 0.5496 - loss: 1.0054 - val_accuracy: 0.6198 - val_loss: 0.8652\n",
            "Epoch 45/300\n",
            "16/16 - 143s - 9s/step - accuracy: 0.5248 - loss: 0.9942 - val_accuracy: 0.6116 - val_loss: 0.8621\n",
            "Epoch 46/300\n",
            "16/16 - 129s - 8s/step - accuracy: 0.5413 - loss: 0.9964 - val_accuracy: 0.6198 - val_loss: 0.8559\n",
            "Epoch 47/300\n",
            "16/16 - 141s - 9s/step - accuracy: 0.5393 - loss: 1.0055 - val_accuracy: 0.6281 - val_loss: 0.8553\n",
            "Epoch 48/300\n",
            "16/16 - 128s - 8s/step - accuracy: 0.5434 - loss: 0.9658 - val_accuracy: 0.6281 - val_loss: 0.8506\n",
            "Epoch 49/300\n",
            "16/16 - 144s - 9s/step - accuracy: 0.5083 - loss: 1.0103 - val_accuracy: 0.6198 - val_loss: 0.8496\n",
            "Epoch 50/300\n",
            "16/16 - 128s - 8s/step - accuracy: 0.5413 - loss: 0.9717 - val_accuracy: 0.6198 - val_loss: 0.8489\n",
            "Epoch 51/300\n",
            "16/16 - 142s - 9s/step - accuracy: 0.5310 - loss: 1.0492 - val_accuracy: 0.6198 - val_loss: 0.8471\n",
            "Epoch 52/300\n",
            "16/16 - 157s - 10s/step - accuracy: 0.5269 - loss: 1.0149 - val_accuracy: 0.6281 - val_loss: 0.8468\n",
            "Epoch 53/300\n",
            "16/16 - 143s - 9s/step - accuracy: 0.5475 - loss: 1.0186 - val_accuracy: 0.6281 - val_loss: 0.8470\n",
            "Epoch 54/300\n",
            "16/16 - 143s - 9s/step - accuracy: 0.5310 - loss: 0.9941 - val_accuracy: 0.6198 - val_loss: 0.8513\n",
            "Epoch 55/300\n",
            "16/16 - 128s - 8s/step - accuracy: 0.5517 - loss: 0.9879 - val_accuracy: 0.6198 - val_loss: 0.8548\n",
            "Epoch 56/300\n",
            "16/16 - 157s - 10s/step - accuracy: 0.5351 - loss: 0.9706 - val_accuracy: 0.6198 - val_loss: 0.8520\n",
            "Epoch 57/300\n",
            "16/16 - 128s - 8s/step - accuracy: 0.5310 - loss: 0.9843 - val_accuracy: 0.6198 - val_loss: 0.8470\n",
            "Epoch 58/300\n",
            "16/16 - 127s - 8s/step - accuracy: 0.5372 - loss: 0.9528 - val_accuracy: 0.6364 - val_loss: 0.8445\n",
            "Epoch 59/300\n",
            "16/16 - 142s - 9s/step - accuracy: 0.5289 - loss: 1.0127 - val_accuracy: 0.6446 - val_loss: 0.8462\n",
            "Epoch 60/300\n",
            "16/16 - 142s - 9s/step - accuracy: 0.5682 - loss: 0.9475 - val_accuracy: 0.6446 - val_loss: 0.8466\n",
            "Epoch 61/300\n",
            "16/16 - 143s - 9s/step - accuracy: 0.5434 - loss: 0.9655 - val_accuracy: 0.6364 - val_loss: 0.8444\n",
            "Epoch 62/300\n",
            "16/16 - 128s - 8s/step - accuracy: 0.5744 - loss: 0.9625 - val_accuracy: 0.6446 - val_loss: 0.8407\n",
            "Epoch 63/300\n",
            "16/16 - 142s - 9s/step - accuracy: 0.5289 - loss: 0.9880 - val_accuracy: 0.6446 - val_loss: 0.8395\n",
            "Epoch 64/300\n",
            "16/16 - 143s - 9s/step - accuracy: 0.5269 - loss: 0.9715 - val_accuracy: 0.6446 - val_loss: 0.8392\n",
            "Epoch 65/300\n",
            "16/16 - 128s - 8s/step - accuracy: 0.5475 - loss: 0.9445 - val_accuracy: 0.6364 - val_loss: 0.8383\n",
            "Epoch 66/300\n",
            "16/16 - 143s - 9s/step - accuracy: 0.5496 - loss: 0.9435 - val_accuracy: 0.6446 - val_loss: 0.8375\n",
            "Epoch 67/300\n",
            "16/16 - 127s - 8s/step - accuracy: 0.5372 - loss: 0.9699 - val_accuracy: 0.6364 - val_loss: 0.8370\n",
            "Epoch 68/300\n",
            "16/16 - 142s - 9s/step - accuracy: 0.5620 - loss: 0.9661 - val_accuracy: 0.6446 - val_loss: 0.8362\n",
            "Epoch 69/300\n",
            "16/16 - 129s - 8s/step - accuracy: 0.5702 - loss: 0.9436 - val_accuracy: 0.6364 - val_loss: 0.8324\n",
            "Epoch 70/300\n",
            "16/16 - 143s - 9s/step - accuracy: 0.6136 - loss: 0.8844 - val_accuracy: 0.6446 - val_loss: 0.8290\n",
            "Epoch 71/300\n",
            "16/16 - 128s - 8s/step - accuracy: 0.5393 - loss: 0.9447 - val_accuracy: 0.6446 - val_loss: 0.8253\n",
            "Epoch 72/300\n",
            "16/16 - 141s - 9s/step - accuracy: 0.5620 - loss: 0.9541 - val_accuracy: 0.6446 - val_loss: 0.8281\n",
            "Epoch 73/300\n",
            "16/16 - 143s - 9s/step - accuracy: 0.5413 - loss: 0.9695 - val_accuracy: 0.6364 - val_loss: 0.8274\n",
            "Epoch 74/300\n",
            "16/16 - 128s - 8s/step - accuracy: 0.5764 - loss: 0.9657 - val_accuracy: 0.6364 - val_loss: 0.8301\n",
            "Epoch 75/300\n",
            "16/16 - 142s - 9s/step - accuracy: 0.5826 - loss: 0.9245 - val_accuracy: 0.6446 - val_loss: 0.8317\n",
            "Epoch 76/300\n",
            "16/16 - 128s - 8s/step - accuracy: 0.5806 - loss: 0.9036 - val_accuracy: 0.6446 - val_loss: 0.8287\n",
            "Epoch 77/300\n",
            "16/16 - 129s - 8s/step - accuracy: 0.5640 - loss: 0.9729 - val_accuracy: 0.6364 - val_loss: 0.8276\n",
            "Epoch 78/300\n",
            "16/16 - 129s - 8s/step - accuracy: 0.5785 - loss: 0.9113 - val_accuracy: 0.6364 - val_loss: 0.8262\n",
            "Epoch 79/300\n",
            "16/16 - 143s - 9s/step - accuracy: 0.5661 - loss: 0.9469 - val_accuracy: 0.6364 - val_loss: 0.8218\n",
            "Epoch 80/300\n",
            "16/16 - 143s - 9s/step - accuracy: 0.5868 - loss: 0.9403 - val_accuracy: 0.6364 - val_loss: 0.8205\n",
            "Epoch 81/300\n",
            "16/16 - 128s - 8s/step - accuracy: 0.5702 - loss: 0.9561 - val_accuracy: 0.6446 - val_loss: 0.8203\n",
            "Epoch 82/300\n",
            "16/16 - 144s - 9s/step - accuracy: 0.6178 - loss: 0.9031 - val_accuracy: 0.6446 - val_loss: 0.8190\n",
            "Epoch 83/300\n",
            "16/16 - 128s - 8s/step - accuracy: 0.5888 - loss: 0.9392 - val_accuracy: 0.6364 - val_loss: 0.8176\n",
            "Epoch 84/300\n",
            "16/16 - 142s - 9s/step - accuracy: 0.5868 - loss: 0.9564 - val_accuracy: 0.6446 - val_loss: 0.8186\n",
            "Epoch 85/300\n",
            "16/16 - 128s - 8s/step - accuracy: 0.5620 - loss: 0.9091 - val_accuracy: 0.6364 - val_loss: 0.8180\n",
            "Epoch 86/300\n",
            "16/16 - 126s - 8s/step - accuracy: 0.5682 - loss: 0.8983 - val_accuracy: 0.6364 - val_loss: 0.8141\n",
            "Epoch 87/300\n",
            "16/16 - 126s - 8s/step - accuracy: 0.5744 - loss: 0.9150 - val_accuracy: 0.6446 - val_loss: 0.8094\n",
            "Epoch 88/300\n",
            "16/16 - 142s - 9s/step - accuracy: 0.5723 - loss: 0.9548 - val_accuracy: 0.6446 - val_loss: 0.8095\n",
            "Epoch 89/300\n",
            "16/16 - 157s - 10s/step - accuracy: 0.5909 - loss: 0.9637 - val_accuracy: 0.6446 - val_loss: 0.8084\n",
            "Epoch 90/300\n",
            "16/16 - 127s - 8s/step - accuracy: 0.5992 - loss: 0.8771 - val_accuracy: 0.6446 - val_loss: 0.8083\n",
            "Epoch 91/300\n",
            "16/16 - 143s - 9s/step - accuracy: 0.5723 - loss: 0.9588 - val_accuracy: 0.6364 - val_loss: 0.8081\n",
            "Epoch 92/300\n",
            "16/16 - 142s - 9s/step - accuracy: 0.5537 - loss: 0.9139 - val_accuracy: 0.6364 - val_loss: 0.8075\n",
            "Epoch 93/300\n",
            "16/16 - 127s - 8s/step - accuracy: 0.5744 - loss: 0.9272 - val_accuracy: 0.6364 - val_loss: 0.8058\n",
            "Epoch 94/300\n",
            "16/16 - 127s - 8s/step - accuracy: 0.5702 - loss: 0.9002 - val_accuracy: 0.6364 - val_loss: 0.8036\n",
            "Epoch 95/300\n",
            "16/16 - 127s - 8s/step - accuracy: 0.5579 - loss: 0.9445 - val_accuracy: 0.6446 - val_loss: 0.8013\n",
            "Epoch 96/300\n",
            "16/16 - 141s - 9s/step - accuracy: 0.5764 - loss: 0.9310 - val_accuracy: 0.6364 - val_loss: 0.8014\n",
            "Epoch 97/300\n",
            "16/16 - 126s - 8s/step - accuracy: 0.5640 - loss: 0.9340 - val_accuracy: 0.6364 - val_loss: 0.8008\n",
            "Epoch 98/300\n",
            "16/16 - 126s - 8s/step - accuracy: 0.5950 - loss: 0.8938 - val_accuracy: 0.6364 - val_loss: 0.7989\n",
            "Epoch 99/300\n",
            "16/16 - 126s - 8s/step - accuracy: 0.5723 - loss: 0.9331 - val_accuracy: 0.6529 - val_loss: 0.7982\n",
            "Epoch 100/300\n",
            "16/16 - 126s - 8s/step - accuracy: 0.6054 - loss: 0.8752 - val_accuracy: 0.6529 - val_loss: 0.7991\n",
            "Epoch 101/300\n",
            "16/16 - 144s - 9s/step - accuracy: 0.5868 - loss: 0.9073 - val_accuracy: 0.6612 - val_loss: 0.7951\n",
            "Epoch 102/300\n",
            "16/16 - 127s - 8s/step - accuracy: 0.6136 - loss: 0.8548 - val_accuracy: 0.6612 - val_loss: 0.7902\n",
            "Epoch 103/300\n",
            "16/16 - 126s - 8s/step - accuracy: 0.6095 - loss: 0.8897 - val_accuracy: 0.6529 - val_loss: 0.7880\n",
            "Epoch 104/300\n",
            "16/16 - 127s - 8s/step - accuracy: 0.5785 - loss: 0.9004 - val_accuracy: 0.6529 - val_loss: 0.7876\n",
            "Epoch 105/300\n",
            "16/16 - 126s - 8s/step - accuracy: 0.6033 - loss: 0.8883 - val_accuracy: 0.6694 - val_loss: 0.7847\n",
            "Epoch 106/300\n",
            "16/16 - 142s - 9s/step - accuracy: 0.5971 - loss: 0.9126 - val_accuracy: 0.6612 - val_loss: 0.7832\n",
            "Epoch 107/300\n"
          ]
        }
      ],
      "source": [
        "split_ratio = 0.8\n",
        "split_percent = round(split_ratio * 100)\n",
        "\n",
        "for lr in [0.0001]:\n",
        "    for epoch in [300]:\n",
        "        print(f\"\\n📦 Training model dengan split_ratio={split_percent}%, learning_rate={lr}, epochs={epoch}\")\n",
        "\n",
        "        model, history = train_model(\n",
        "            split_ratio=split_ratio,\n",
        "            lr=lr,\n",
        "            epochs=epoch\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9QL6BrJXLwEr",
      "metadata": {
        "id": "9QL6BrJXLwEr"
      },
      "source": [
        "### SPLIT RATIO 0.9 LR 0.001\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-elc5tn6LqUe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-elc5tn6LqUe",
        "outputId": "a76f5dbb-0952-45dc-f156-5684d64039d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📦 Training model dengan split_ratio=90%, learning_rate=0.001, epochs=50\n",
            "Found 544 images belonging to 3 classes.\n",
            "Found 61 images belonging to 3 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "17/17 - 179s - 11s/step - accuracy: 0.3824 - loss: 1.7930 - val_accuracy: 0.4754 - val_loss: 1.3003\n",
            "Epoch 2/50\n",
            "17/17 - 159s - 9s/step - accuracy: 0.4890 - loss: 1.3321 - val_accuracy: 0.5246 - val_loss: 0.9882\n",
            "Epoch 3/50\n",
            "17/17 - 197s - 12s/step - accuracy: 0.4688 - loss: 1.2002 - val_accuracy: 0.5246 - val_loss: 0.9903\n",
            "Epoch 4/50\n",
            "17/17 - 156s - 9s/step - accuracy: 0.4761 - loss: 1.0818 - val_accuracy: 0.5738 - val_loss: 0.9975\n",
            "Epoch 5/50\n",
            "17/17 - 154s - 9s/step - accuracy: 0.5533 - loss: 0.9871 - val_accuracy: 0.5738 - val_loss: 0.9774\n",
            "Epoch 6/50\n",
            "17/17 - 161s - 9s/step - accuracy: 0.5699 - loss: 0.9811 - val_accuracy: 0.6393 - val_loss: 0.9487\n",
            "Epoch 7/50\n",
            "17/17 - 154s - 9s/step - accuracy: 0.5607 - loss: 0.9643 - val_accuracy: 0.5574 - val_loss: 0.9320\n",
            "Epoch 8/50\n",
            "17/17 - 156s - 9s/step - accuracy: 0.5570 - loss: 0.9570 - val_accuracy: 0.5738 - val_loss: 0.9231\n",
            "Epoch 9/50\n",
            "17/17 - 155s - 9s/step - accuracy: 0.5717 - loss: 0.9491 - val_accuracy: 0.5574 - val_loss: 0.9108\n",
            "Epoch 10/50\n",
            "17/17 - 212s - 12s/step - accuracy: 0.5754 - loss: 0.9571 - val_accuracy: 0.6393 - val_loss: 0.8968\n",
            "Epoch 11/50\n",
            "17/17 - 190s - 11s/step - accuracy: 0.5570 - loss: 0.9292 - val_accuracy: 0.5902 - val_loss: 0.8953\n",
            "Epoch 12/50\n",
            "17/17 - 155s - 9s/step - accuracy: 0.5827 - loss: 0.8902 - val_accuracy: 0.5738 - val_loss: 0.8863\n",
            "Epoch 13/50\n",
            "17/17 - 211s - 12s/step - accuracy: 0.5827 - loss: 0.9285 - val_accuracy: 0.5738 - val_loss: 0.8782\n",
            "Epoch 14/50\n",
            "17/17 - 153s - 9s/step - accuracy: 0.5993 - loss: 0.8847 - val_accuracy: 0.5738 - val_loss: 0.8916\n",
            "Epoch 15/50\n",
            "17/17 - 159s - 9s/step - accuracy: 0.6268 - loss: 0.8716 - val_accuracy: 0.6066 - val_loss: 0.8776\n",
            "Epoch 16/50\n",
            "17/17 - 160s - 9s/step - accuracy: 0.5956 - loss: 0.8939 - val_accuracy: 0.5902 - val_loss: 0.8582\n",
            "Epoch 17/50\n",
            "17/17 - 162s - 10s/step - accuracy: 0.5680 - loss: 0.8982 - val_accuracy: 0.6393 - val_loss: 0.8573\n",
            "Epoch 18/50\n",
            "17/17 - 196s - 12s/step - accuracy: 0.6452 - loss: 0.8212 - val_accuracy: 0.6557 - val_loss: 0.8489\n",
            "Epoch 19/50\n",
            "17/17 - 208s - 12s/step - accuracy: 0.6140 - loss: 0.9122 - val_accuracy: 0.5902 - val_loss: 0.8478\n",
            "Epoch 20/50\n",
            "17/17 - 156s - 9s/step - accuracy: 0.6066 - loss: 0.8674 - val_accuracy: 0.6393 - val_loss: 0.8349\n",
            "Epoch 21/50\n",
            "17/17 - 158s - 9s/step - accuracy: 0.6305 - loss: 0.8315 - val_accuracy: 0.6230 - val_loss: 0.8401\n",
            "Epoch 22/50\n",
            "17/17 - 162s - 10s/step - accuracy: 0.6342 - loss: 0.8605 - val_accuracy: 0.6230 - val_loss: 0.8500\n",
            "Epoch 23/50\n",
            "17/17 - 158s - 9s/step - accuracy: 0.6066 - loss: 0.8694 - val_accuracy: 0.6230 - val_loss: 0.8401\n",
            "Epoch 24/50\n",
            "17/17 - 159s - 9s/step - accuracy: 0.6507 - loss: 0.7902 - val_accuracy: 0.6230 - val_loss: 0.8242\n",
            "Epoch 25/50\n",
            "17/17 - 157s - 9s/step - accuracy: 0.6121 - loss: 0.8554 - val_accuracy: 0.6066 - val_loss: 0.8211\n",
            "Epoch 26/50\n",
            "17/17 - 162s - 10s/step - accuracy: 0.6324 - loss: 0.8357 - val_accuracy: 0.6230 - val_loss: 0.8037\n",
            "Epoch 27/50\n",
            "17/17 - 159s - 9s/step - accuracy: 0.6121 - loss: 0.8495 - val_accuracy: 0.6721 - val_loss: 0.7937\n",
            "Epoch 28/50\n",
            "17/17 - 167s - 10s/step - accuracy: 0.6636 - loss: 0.8031 - val_accuracy: 0.6721 - val_loss: 0.7831\n",
            "Epoch 29/50\n",
            "17/17 - 155s - 9s/step - accuracy: 0.6783 - loss: 0.7954 - val_accuracy: 0.6393 - val_loss: 0.7969\n",
            "Epoch 30/50\n",
            "17/17 - 160s - 9s/step - accuracy: 0.6562 - loss: 0.8034 - val_accuracy: 0.7049 - val_loss: 0.7820\n",
            "Epoch 31/50\n",
            "17/17 - 159s - 9s/step - accuracy: 0.6893 - loss: 0.7705 - val_accuracy: 0.6721 - val_loss: 0.7576\n",
            "Epoch 32/50\n",
            "17/17 - 161s - 9s/step - accuracy: 0.6654 - loss: 0.7628 - val_accuracy: 0.6393 - val_loss: 0.7471\n",
            "Epoch 33/50\n",
            "17/17 - 156s - 9s/step - accuracy: 0.6654 - loss: 0.7574 - val_accuracy: 0.6721 - val_loss: 0.7462\n",
            "Epoch 34/50\n",
            "17/17 - 163s - 10s/step - accuracy: 0.6618 - loss: 0.7926 - val_accuracy: 0.6393 - val_loss: 0.7594\n",
            "Epoch 35/50\n",
            "17/17 - 193s - 11s/step - accuracy: 0.6654 - loss: 0.7791 - val_accuracy: 0.6393 - val_loss: 0.7599\n",
            "Epoch 36/50\n",
            "17/17 - 159s - 9s/step - accuracy: 0.6489 - loss: 0.7917 - val_accuracy: 0.6885 - val_loss: 0.7609\n",
            "Epoch 37/50\n",
            "17/17 - 154s - 9s/step - accuracy: 0.6526 - loss: 0.7650 - val_accuracy: 0.7213 - val_loss: 0.7474\n",
            "Epoch 38/50\n",
            "17/17 - 153s - 9s/step - accuracy: 0.6599 - loss: 0.7777 - val_accuracy: 0.7213 - val_loss: 0.7345\n",
            "Epoch 39/50\n",
            "17/17 - 159s - 9s/step - accuracy: 0.6710 - loss: 0.7937 - val_accuracy: 0.6393 - val_loss: 0.7269\n",
            "Epoch 40/50\n",
            "17/17 - 155s - 9s/step - accuracy: 0.7096 - loss: 0.7401 - val_accuracy: 0.6393 - val_loss: 0.7433\n",
            "Epoch 41/50\n",
            "17/17 - 154s - 9s/step - accuracy: 0.6507 - loss: 0.7800 - val_accuracy: 0.6557 - val_loss: 0.7415\n",
            "Epoch 42/50\n",
            "17/17 - 153s - 9s/step - accuracy: 0.6820 - loss: 0.7432 - val_accuracy: 0.6885 - val_loss: 0.7284\n",
            "Epoch 43/50\n",
            "17/17 - 153s - 9s/step - accuracy: 0.6746 - loss: 0.7615 - val_accuracy: 0.6885 - val_loss: 0.7237\n",
            "Epoch 44/50\n",
            "17/17 - 152s - 9s/step - accuracy: 0.7059 - loss: 0.7377 - val_accuracy: 0.6393 - val_loss: 0.7175\n",
            "Epoch 45/50\n",
            "17/17 - 152s - 9s/step - accuracy: 0.6893 - loss: 0.7574 - val_accuracy: 0.6393 - val_loss: 0.7261\n",
            "Epoch 46/50\n",
            "17/17 - 153s - 9s/step - accuracy: 0.6746 - loss: 0.7332 - val_accuracy: 0.6557 - val_loss: 0.7029\n",
            "Epoch 47/50\n",
            "17/17 - 151s - 9s/step - accuracy: 0.6857 - loss: 0.7380 - val_accuracy: 0.6557 - val_loss: 0.7229\n",
            "Epoch 48/50\n",
            "17/17 - 205s - 12s/step - accuracy: 0.6893 - loss: 0.7494 - val_accuracy: 0.6557 - val_loss: 0.7374\n",
            "Epoch 49/50\n",
            "17/17 - 152s - 9s/step - accuracy: 0.6618 - loss: 0.7817 - val_accuracy: 0.6721 - val_loss: 0.7151\n",
            "Epoch 50/50\n",
            "17/17 - 154s - 9s/step - accuracy: 0.6985 - loss: 0.7364 - val_accuracy: 0.6721 - val_loss: 0.7184\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model berhasil disimpan: model_split90_lr0.001_ep50_l20.0001.h5\n"
          ]
        }
      ],
      "source": [
        "split_ratio = 0.9\n",
        "split_percent = round(split_ratio * 100)\n",
        "\n",
        "for lr in [0.001]:\n",
        "    for epoch in [50]:\n",
        "        print(f\"\\n📦 Training model dengan split_ratio={split_percent}%, learning_rate={lr}, epochs={epoch}\")\n",
        "\n",
        "        model, history = train_model(\n",
        "            split_ratio=split_ratio,\n",
        "            lr=lr,\n",
        "            epochs=epoch\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HVjZkmId9xxi",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVjZkmId9xxi",
        "outputId": "f00ce3ca-ef25-4bd9-fec2-767439eccac3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📦 Training model dengan split_ratio=90%, learning_rate=0.001, epochs=100\n",
            "Found 544 images belonging to 3 classes.\n",
            "Found 61 images belonging to 3 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "17/17 - 162s - 10s/step - accuracy: 0.3787 - loss: 2.0356 - val_accuracy: 0.4754 - val_loss: 1.0725\n",
            "Epoch 2/100\n",
            "17/17 - 147s - 9s/step - accuracy: 0.4779 - loss: 1.2587 - val_accuracy: 0.4590 - val_loss: 1.0073\n",
            "Epoch 3/100\n",
            "17/17 - 206s - 12s/step - accuracy: 0.4853 - loss: 1.1313 - val_accuracy: 0.5410 - val_loss: 0.9761\n",
            "Epoch 4/100\n",
            "17/17 - 148s - 9s/step - accuracy: 0.5037 - loss: 1.0333 - val_accuracy: 0.5246 - val_loss: 0.9573\n",
            "Epoch 5/100\n",
            "17/17 - 208s - 12s/step - accuracy: 0.5184 - loss: 1.0114 - val_accuracy: 0.5246 - val_loss: 0.9613\n",
            "Epoch 6/100\n",
            "17/17 - 161s - 9s/step - accuracy: 0.5404 - loss: 1.0086 - val_accuracy: 0.5738 - val_loss: 0.9573\n",
            "Epoch 7/100\n",
            "17/17 - 190s - 11s/step - accuracy: 0.5699 - loss: 0.9866 - val_accuracy: 0.5902 - val_loss: 0.9381\n",
            "Epoch 8/100\n",
            "17/17 - 148s - 9s/step - accuracy: 0.5533 - loss: 0.9385 - val_accuracy: 0.6721 - val_loss: 0.9176\n",
            "Epoch 9/100\n",
            "17/17 - 151s - 9s/step - accuracy: 0.5349 - loss: 0.9765 - val_accuracy: 0.5410 - val_loss: 0.9144\n",
            "Epoch 10/100\n",
            "17/17 - 158s - 9s/step - accuracy: 0.5588 - loss: 0.9306 - val_accuracy: 0.6393 - val_loss: 0.9034\n",
            "Epoch 11/100\n",
            "17/17 - 152s - 9s/step - accuracy: 0.5625 - loss: 0.9355 - val_accuracy: 0.5738 - val_loss: 0.9048\n",
            "Epoch 12/100\n",
            "17/17 - 148s - 9s/step - accuracy: 0.5607 - loss: 0.9570 - val_accuracy: 0.5902 - val_loss: 0.8961\n",
            "Epoch 13/100\n",
            "17/17 - 147s - 9s/step - accuracy: 0.6158 - loss: 0.8596 - val_accuracy: 0.6393 - val_loss: 0.8686\n",
            "Epoch 14/100\n",
            "17/17 - 154s - 9s/step - accuracy: 0.5772 - loss: 0.9156 - val_accuracy: 0.6721 - val_loss: 0.8536\n",
            "Epoch 15/100\n",
            "17/17 - 200s - 12s/step - accuracy: 0.5846 - loss: 0.8922 - val_accuracy: 0.6393 - val_loss: 0.8376\n",
            "Epoch 16/100\n",
            "17/17 - 153s - 9s/step - accuracy: 0.6140 - loss: 0.8309 - val_accuracy: 0.6557 - val_loss: 0.8214\n",
            "Epoch 17/100\n",
            "17/17 - 146s - 9s/step - accuracy: 0.5919 - loss: 0.8881 - val_accuracy: 0.6066 - val_loss: 0.8061\n",
            "Epoch 18/100\n",
            "17/17 - 201s - 12s/step - accuracy: 0.6176 - loss: 0.8637 - val_accuracy: 0.6721 - val_loss: 0.8091\n",
            "Epoch 19/100\n",
            "17/17 - 147s - 9s/step - accuracy: 0.6158 - loss: 0.8677 - val_accuracy: 0.6230 - val_loss: 0.8103\n",
            "Epoch 20/100\n",
            "17/17 - 207s - 12s/step - accuracy: 0.6158 - loss: 0.8810 - val_accuracy: 0.6230 - val_loss: 0.8006\n",
            "Epoch 21/100\n",
            "17/17 - 147s - 9s/step - accuracy: 0.6029 - loss: 0.8654 - val_accuracy: 0.6721 - val_loss: 0.7921\n",
            "Epoch 22/100\n",
            "17/17 - 148s - 9s/step - accuracy: 0.6379 - loss: 0.8337 - val_accuracy: 0.6230 - val_loss: 0.7949\n",
            "Epoch 23/100\n",
            "17/17 - 144s - 8s/step - accuracy: 0.6489 - loss: 0.8103 - val_accuracy: 0.6557 - val_loss: 0.7986\n",
            "Epoch 24/100\n",
            "17/17 - 145s - 9s/step - accuracy: 0.6360 - loss: 0.8065 - val_accuracy: 0.6066 - val_loss: 0.7907\n",
            "Epoch 25/100\n",
            "17/17 - 145s - 9s/step - accuracy: 0.6342 - loss: 0.8363 - val_accuracy: 0.6557 - val_loss: 0.7811\n",
            "Epoch 26/100\n",
            "17/17 - 202s - 12s/step - accuracy: 0.6673 - loss: 0.7914 - val_accuracy: 0.6721 - val_loss: 0.7745\n",
            "Epoch 27/100\n",
            "17/17 - 146s - 9s/step - accuracy: 0.6305 - loss: 0.8276 - val_accuracy: 0.6230 - val_loss: 0.7520\n",
            "Epoch 28/100\n",
            "17/17 - 152s - 9s/step - accuracy: 0.6415 - loss: 0.8004 - val_accuracy: 0.6230 - val_loss: 0.7384\n",
            "Epoch 29/100\n",
            "17/17 - 153s - 9s/step - accuracy: 0.6379 - loss: 0.8084 - val_accuracy: 0.6393 - val_loss: 0.7481\n",
            "Epoch 30/100\n",
            "17/17 - 148s - 9s/step - accuracy: 0.6489 - loss: 0.7820 - val_accuracy: 0.6885 - val_loss: 0.7446\n",
            "Epoch 31/100\n",
            "17/17 - 147s - 9s/step - accuracy: 0.6728 - loss: 0.7806 - val_accuracy: 0.6393 - val_loss: 0.7302\n",
            "Epoch 32/100\n",
            "17/17 - 147s - 9s/step - accuracy: 0.6471 - loss: 0.7959 - val_accuracy: 0.6721 - val_loss: 0.7360\n",
            "Epoch 33/100\n",
            "17/17 - 151s - 9s/step - accuracy: 0.6305 - loss: 0.8091 - val_accuracy: 0.6393 - val_loss: 0.7517\n",
            "Epoch 34/100\n",
            "17/17 - 147s - 9s/step - accuracy: 0.6985 - loss: 0.7629 - val_accuracy: 0.6885 - val_loss: 0.7048\n",
            "Epoch 35/100\n",
            "17/17 - 153s - 9s/step - accuracy: 0.6801 - loss: 0.7627 - val_accuracy: 0.6885 - val_loss: 0.6936\n",
            "Epoch 36/100\n",
            "17/17 - 148s - 9s/step - accuracy: 0.6581 - loss: 0.7931 - val_accuracy: 0.7049 - val_loss: 0.6860\n",
            "Epoch 37/100\n",
            "17/17 - 153s - 9s/step - accuracy: 0.6765 - loss: 0.7435 - val_accuracy: 0.6721 - val_loss: 0.6814\n",
            "Epoch 38/100\n",
            "17/17 - 147s - 9s/step - accuracy: 0.6765 - loss: 0.7397 - val_accuracy: 0.7049 - val_loss: 0.6893\n",
            "Epoch 39/100\n",
            "17/17 - 152s - 9s/step - accuracy: 0.6893 - loss: 0.7228 - val_accuracy: 0.7541 - val_loss: 0.6761\n",
            "Epoch 40/100\n",
            "17/17 - 153s - 9s/step - accuracy: 0.6636 - loss: 0.7781 - val_accuracy: 0.7377 - val_loss: 0.6678\n",
            "Epoch 41/100\n",
            "17/17 - 146s - 9s/step - accuracy: 0.6783 - loss: 0.7493 - val_accuracy: 0.7377 - val_loss: 0.6736\n",
            "Epoch 42/100\n",
            "17/17 - 147s - 9s/step - accuracy: 0.6820 - loss: 0.7257 - val_accuracy: 0.7377 - val_loss: 0.6735\n",
            "Epoch 43/100\n",
            "17/17 - 151s - 9s/step - accuracy: 0.6544 - loss: 0.7603 - val_accuracy: 0.7213 - val_loss: 0.6725\n",
            "Epoch 44/100\n",
            "17/17 - 146s - 9s/step - accuracy: 0.6691 - loss: 0.7238 - val_accuracy: 0.7049 - val_loss: 0.6855\n",
            "Epoch 45/100\n",
            "17/17 - 149s - 9s/step - accuracy: 0.6801 - loss: 0.7299 - val_accuracy: 0.7213 - val_loss: 0.6857\n",
            "Epoch 46/100\n",
            "17/17 - 152s - 9s/step - accuracy: 0.7151 - loss: 0.6997 - val_accuracy: 0.7049 - val_loss: 0.6817\n",
            "Epoch 47/100\n",
            "17/17 - 151s - 9s/step - accuracy: 0.7261 - loss: 0.6800 - val_accuracy: 0.7213 - val_loss: 0.6734\n",
            "Epoch 48/100\n",
            "17/17 - 146s - 9s/step - accuracy: 0.6875 - loss: 0.7587 - val_accuracy: 0.7213 - val_loss: 0.6580\n",
            "Epoch 49/100\n",
            "17/17 - 147s - 9s/step - accuracy: 0.6581 - loss: 0.7651 - val_accuracy: 0.7049 - val_loss: 0.6558\n",
            "Epoch 50/100\n",
            "17/17 - 152s - 9s/step - accuracy: 0.6691 - loss: 0.7307 - val_accuracy: 0.6721 - val_loss: 0.6701\n",
            "Epoch 51/100\n",
            "17/17 - 146s - 9s/step - accuracy: 0.6930 - loss: 0.7196 - val_accuracy: 0.7049 - val_loss: 0.6701\n",
            "Epoch 52/100\n",
            "17/17 - 153s - 9s/step - accuracy: 0.6801 - loss: 0.7294 - val_accuracy: 0.7049 - val_loss: 0.6627\n",
            "Epoch 53/100\n",
            "17/17 - 146s - 9s/step - accuracy: 0.6838 - loss: 0.7180 - val_accuracy: 0.7213 - val_loss: 0.6610\n",
            "Epoch 54/100\n",
            "17/17 - 153s - 9s/step - accuracy: 0.6967 - loss: 0.7148 - val_accuracy: 0.7049 - val_loss: 0.6522\n",
            "Epoch 55/100\n",
            "17/17 - 148s - 9s/step - accuracy: 0.7169 - loss: 0.6927 - val_accuracy: 0.7377 - val_loss: 0.6451\n",
            "Epoch 56/100\n",
            "17/17 - 154s - 9s/step - accuracy: 0.6820 - loss: 0.7003 - val_accuracy: 0.7541 - val_loss: 0.6437\n",
            "Epoch 57/100\n",
            "17/17 - 148s - 9s/step - accuracy: 0.7243 - loss: 0.6698 - val_accuracy: 0.7213 - val_loss: 0.6510\n",
            "Epoch 58/100\n",
            "17/17 - 147s - 9s/step - accuracy: 0.6912 - loss: 0.7131 - val_accuracy: 0.7213 - val_loss: 0.6502\n",
            "Epoch 59/100\n",
            "17/17 - 147s - 9s/step - accuracy: 0.7298 - loss: 0.6757 - val_accuracy: 0.7377 - val_loss: 0.6348\n",
            "Epoch 60/100\n",
            "17/17 - 151s - 9s/step - accuracy: 0.7132 - loss: 0.6485 - val_accuracy: 0.7213 - val_loss: 0.6288\n",
            "Epoch 61/100\n",
            "17/17 - 152s - 9s/step - accuracy: 0.7059 - loss: 0.6818 - val_accuracy: 0.7049 - val_loss: 0.6463\n",
            "Epoch 62/100\n",
            "17/17 - 196s - 12s/step - accuracy: 0.7132 - loss: 0.6865 - val_accuracy: 0.7049 - val_loss: 0.6395\n",
            "Epoch 63/100\n",
            "17/17 - 146s - 9s/step - accuracy: 0.7059 - loss: 0.6938 - val_accuracy: 0.7213 - val_loss: 0.6274\n",
            "Epoch 64/100\n",
            "17/17 - 202s - 12s/step - accuracy: 0.7059 - loss: 0.6833 - val_accuracy: 0.7049 - val_loss: 0.6280\n",
            "Epoch 65/100\n",
            "17/17 - 204s - 12s/step - accuracy: 0.7022 - loss: 0.6797 - val_accuracy: 0.6721 - val_loss: 0.6265\n",
            "Epoch 66/100\n",
            "17/17 - 147s - 9s/step - accuracy: 0.7151 - loss: 0.6799 - val_accuracy: 0.6885 - val_loss: 0.6283\n",
            "Epoch 67/100\n",
            "17/17 - 147s - 9s/step - accuracy: 0.7390 - loss: 0.6539 - val_accuracy: 0.6885 - val_loss: 0.6303\n",
            "Epoch 68/100\n",
            "17/17 - 148s - 9s/step - accuracy: 0.7316 - loss: 0.6481 - val_accuracy: 0.6885 - val_loss: 0.6172\n",
            "Epoch 69/100\n",
            "17/17 - 148s - 9s/step - accuracy: 0.6967 - loss: 0.6966 - val_accuracy: 0.6885 - val_loss: 0.6282\n",
            "Epoch 70/100\n",
            "17/17 - 155s - 9s/step - accuracy: 0.7316 - loss: 0.6824 - val_accuracy: 0.7049 - val_loss: 0.6282\n",
            "Epoch 71/100\n",
            "17/17 - 148s - 9s/step - accuracy: 0.7445 - loss: 0.6454 - val_accuracy: 0.6885 - val_loss: 0.6316\n",
            "Epoch 72/100\n",
            "17/17 - 148s - 9s/step - accuracy: 0.7353 - loss: 0.6850 - val_accuracy: 0.7049 - val_loss: 0.6480\n",
            "Epoch 73/100\n",
            "17/17 - 202s - 12s/step - accuracy: 0.7629 - loss: 0.6131 - val_accuracy: 0.6885 - val_loss: 0.6114\n",
            "Epoch 74/100\n",
            "17/17 - 147s - 9s/step - accuracy: 0.7243 - loss: 0.6721 - val_accuracy: 0.7377 - val_loss: 0.6032\n",
            "Epoch 75/100\n",
            "17/17 - 153s - 9s/step - accuracy: 0.6967 - loss: 0.6965 - val_accuracy: 0.6721 - val_loss: 0.6318\n",
            "Epoch 76/100\n",
            "17/17 - 146s - 9s/step - accuracy: 0.7537 - loss: 0.6355 - val_accuracy: 0.7049 - val_loss: 0.6312\n",
            "Epoch 77/100\n",
            "17/17 - 153s - 9s/step - accuracy: 0.7298 - loss: 0.6603 - val_accuracy: 0.7213 - val_loss: 0.6054\n",
            "Epoch 78/100\n",
            "17/17 - 147s - 9s/step - accuracy: 0.7390 - loss: 0.6513 - val_accuracy: 0.7377 - val_loss: 0.6028\n",
            "Epoch 79/100\n",
            "17/17 - 148s - 9s/step - accuracy: 0.7114 - loss: 0.6433 - val_accuracy: 0.6885 - val_loss: 0.6139\n",
            "Epoch 80/100\n",
            "17/17 - 152s - 9s/step - accuracy: 0.7261 - loss: 0.6478 - val_accuracy: 0.7049 - val_loss: 0.6117\n",
            "Epoch 81/100\n",
            "17/17 - 153s - 9s/step - accuracy: 0.7353 - loss: 0.6483 - val_accuracy: 0.6885 - val_loss: 0.6121\n",
            "Epoch 82/100\n",
            "17/17 - 147s - 9s/step - accuracy: 0.7261 - loss: 0.6486 - val_accuracy: 0.7049 - val_loss: 0.6020\n",
            "Epoch 83/100\n",
            "17/17 - 147s - 9s/step - accuracy: 0.7445 - loss: 0.6449 - val_accuracy: 0.7213 - val_loss: 0.6090\n",
            "Epoch 84/100\n",
            "17/17 - 153s - 9s/step - accuracy: 0.7555 - loss: 0.6173 - val_accuracy: 0.7377 - val_loss: 0.6086\n",
            "Epoch 85/100\n",
            "17/17 - 147s - 9s/step - accuracy: 0.7114 - loss: 0.6663 - val_accuracy: 0.7377 - val_loss: 0.6016\n",
            "Epoch 86/100\n",
            "17/17 - 201s - 12s/step - accuracy: 0.7574 - loss: 0.6355 - val_accuracy: 0.7213 - val_loss: 0.6015\n",
            "Epoch 87/100\n",
            "17/17 - 154s - 9s/step - accuracy: 0.7463 - loss: 0.6158 - val_accuracy: 0.7213 - val_loss: 0.6251\n",
            "Epoch 88/100\n",
            "17/17 - 146s - 9s/step - accuracy: 0.7500 - loss: 0.6314 - val_accuracy: 0.7049 - val_loss: 0.6169\n",
            "Epoch 89/100\n",
            "17/17 - 146s - 9s/step - accuracy: 0.7316 - loss: 0.6203 - val_accuracy: 0.7213 - val_loss: 0.6393\n",
            "Epoch 90/100\n",
            "17/17 - 147s - 9s/step - accuracy: 0.7371 - loss: 0.6167 - val_accuracy: 0.7377 - val_loss: 0.6105\n",
            "Epoch 91/100\n",
            "17/17 - 152s - 9s/step - accuracy: 0.7518 - loss: 0.6108 - val_accuracy: 0.7377 - val_loss: 0.6206\n",
            "Epoch 92/100\n",
            "17/17 - 146s - 9s/step - accuracy: 0.7371 - loss: 0.6396 - val_accuracy: 0.7541 - val_loss: 0.6099\n",
            "Epoch 93/100\n",
            "17/17 - 151s - 9s/step - accuracy: 0.7316 - loss: 0.6397 - val_accuracy: 0.7377 - val_loss: 0.5779\n",
            "Epoch 94/100\n",
            "17/17 - 146s - 9s/step - accuracy: 0.7408 - loss: 0.6237 - val_accuracy: 0.7377 - val_loss: 0.5853\n",
            "Epoch 95/100\n",
            "17/17 - 143s - 8s/step - accuracy: 0.7629 - loss: 0.6034 - val_accuracy: 0.7705 - val_loss: 0.5756\n",
            "Epoch 96/100\n",
            "17/17 - 145s - 9s/step - accuracy: 0.7243 - loss: 0.6398 - val_accuracy: 0.7213 - val_loss: 0.5828\n",
            "Epoch 97/100\n",
            "17/17 - 145s - 9s/step - accuracy: 0.7114 - loss: 0.6616 - val_accuracy: 0.7869 - val_loss: 0.5729\n",
            "Epoch 98/100\n",
            "17/17 - 146s - 9s/step - accuracy: 0.7335 - loss: 0.6257 - val_accuracy: 0.7869 - val_loss: 0.5766\n",
            "Epoch 99/100\n",
            "17/17 - 149s - 9s/step - accuracy: 0.7500 - loss: 0.6106 - val_accuracy: 0.7705 - val_loss: 0.5776\n",
            "Epoch 100/100\n",
            "17/17 - 146s - 9s/step - accuracy: 0.7500 - loss: 0.6129 - val_accuracy: 0.7377 - val_loss: 0.5843\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model berhasil disimpan: model_split90_lr0.001_ep100_l20.0001.h5\n"
          ]
        }
      ],
      "source": [
        "split_ratio = 0.9\n",
        "split_percent = round(split_ratio * 100)\n",
        "\n",
        "for lr in [0.001]:\n",
        "    for epoch in [100]:\n",
        "        print(f\"\\n📦 Training model dengan split_ratio={split_percent}%, learning_rate={lr}, epochs={epoch}\")\n",
        "\n",
        "        model, history = train_model(\n",
        "            split_ratio=split_ratio,\n",
        "            lr=lr,\n",
        "            epochs=epoch\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WRcUl4akGdlu",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRcUl4akGdlu",
        "outputId": "a3f4f6b6-36cc-499c-b267-c2f1de5bc22a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📦 Training model dengan split_ratio=90%, learning_rate=0.001, epochs=200\n",
            "Found 544 images belonging to 3 classes.\n",
            "Found 61 images belonging to 3 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "17/17 - 156s - 9s/step - accuracy: 0.3566 - loss: 1.7369 - val_accuracy: 0.4754 - val_loss: 1.0545\n",
            "Epoch 2/200\n",
            "17/17 - 135s - 8s/step - accuracy: 0.4210 - loss: 1.3255 - val_accuracy: 0.4754 - val_loss: 1.0302\n",
            "Epoch 3/200\n",
            "17/17 - 147s - 9s/step - accuracy: 0.4926 - loss: 1.1165 - val_accuracy: 0.5574 - val_loss: 0.9647\n",
            "Epoch 4/200\n",
            "17/17 - 141s - 8s/step - accuracy: 0.4853 - loss: 1.0824 - val_accuracy: 0.5574 - val_loss: 0.9628\n",
            "Epoch 5/200\n",
            "17/17 - 134s - 8s/step - accuracy: 0.5092 - loss: 1.0546 - val_accuracy: 0.5246 - val_loss: 0.9542\n",
            "Epoch 6/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.4963 - loss: 0.9906 - val_accuracy: 0.5738 - val_loss: 0.9369\n",
            "Epoch 7/200\n",
            "17/17 - 140s - 8s/step - accuracy: 0.5147 - loss: 1.0267 - val_accuracy: 0.5574 - val_loss: 0.9354\n",
            "Epoch 8/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.5349 - loss: 0.9762 - val_accuracy: 0.5738 - val_loss: 0.9259\n",
            "Epoch 9/200\n",
            "17/17 - 138s - 8s/step - accuracy: 0.5349 - loss: 0.9474 - val_accuracy: 0.6066 - val_loss: 0.9129\n",
            "Epoch 10/200\n",
            "17/17 - 134s - 8s/step - accuracy: 0.5901 - loss: 0.9435 - val_accuracy: 0.6066 - val_loss: 0.9071\n",
            "Epoch 11/200\n",
            "17/17 - 138s - 8s/step - accuracy: 0.5551 - loss: 0.9361 - val_accuracy: 0.6393 - val_loss: 0.8947\n",
            "Epoch 12/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.5956 - loss: 0.9112 - val_accuracy: 0.5902 - val_loss: 0.8843\n",
            "Epoch 13/200\n",
            "17/17 - 144s - 8s/step - accuracy: 0.5662 - loss: 0.9434 - val_accuracy: 0.6230 - val_loss: 0.8714\n",
            "Epoch 14/200\n",
            "17/17 - 139s - 8s/step - accuracy: 0.6085 - loss: 0.8611 - val_accuracy: 0.6557 - val_loss: 0.8538\n",
            "Epoch 15/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.5735 - loss: 0.9123 - val_accuracy: 0.5902 - val_loss: 0.8501\n",
            "Epoch 16/200\n",
            "17/17 - 142s - 8s/step - accuracy: 0.5790 - loss: 0.9326 - val_accuracy: 0.6721 - val_loss: 0.8348\n",
            "Epoch 17/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.6195 - loss: 0.8797 - val_accuracy: 0.6230 - val_loss: 0.8419\n",
            "Epoch 18/200\n",
            "17/17 - 146s - 9s/step - accuracy: 0.6397 - loss: 0.8275 - val_accuracy: 0.6393 - val_loss: 0.8242\n",
            "Epoch 19/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.6066 - loss: 0.8572 - val_accuracy: 0.6557 - val_loss: 0.8076\n",
            "Epoch 20/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.6562 - loss: 0.8352 - val_accuracy: 0.6721 - val_loss: 0.8096\n",
            "Epoch 21/200\n",
            "17/17 - 131s - 8s/step - accuracy: 0.6250 - loss: 0.8141 - val_accuracy: 0.6393 - val_loss: 0.7799\n",
            "Epoch 22/200\n",
            "17/17 - 138s - 8s/step - accuracy: 0.6195 - loss: 0.8619 - val_accuracy: 0.6721 - val_loss: 0.7814\n",
            "Epoch 23/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.6048 - loss: 0.8880 - val_accuracy: 0.6721 - val_loss: 0.7812\n",
            "Epoch 24/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.6452 - loss: 0.8049 - val_accuracy: 0.6885 - val_loss: 0.7861\n",
            "Epoch 25/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.6526 - loss: 0.8254 - val_accuracy: 0.6557 - val_loss: 0.7551\n",
            "Epoch 26/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.6268 - loss: 0.8375 - val_accuracy: 0.6885 - val_loss: 0.7559\n",
            "Epoch 27/200\n",
            "17/17 - 141s - 8s/step - accuracy: 0.6452 - loss: 0.8165 - val_accuracy: 0.7213 - val_loss: 0.7535\n",
            "Epoch 28/200\n",
            "17/17 - 131s - 8s/step - accuracy: 0.6765 - loss: 0.8022 - val_accuracy: 0.6885 - val_loss: 0.7571\n",
            "Epoch 29/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.6728 - loss: 0.7636 - val_accuracy: 0.6885 - val_loss: 0.7413\n",
            "Epoch 30/200\n",
            "17/17 - 133s - 8s/step - accuracy: 0.6710 - loss: 0.8147 - val_accuracy: 0.6721 - val_loss: 0.7397\n",
            "Epoch 31/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.6636 - loss: 0.8199 - val_accuracy: 0.7049 - val_loss: 0.7204\n",
            "Epoch 32/200\n",
            "17/17 - 133s - 8s/step - accuracy: 0.6562 - loss: 0.8109 - val_accuracy: 0.7213 - val_loss: 0.7153\n",
            "Epoch 33/200\n",
            "17/17 - 140s - 8s/step - accuracy: 0.6691 - loss: 0.7772 - val_accuracy: 0.7049 - val_loss: 0.7129\n",
            "Epoch 34/200\n",
            "17/17 - 134s - 8s/step - accuracy: 0.6857 - loss: 0.7451 - val_accuracy: 0.7213 - val_loss: 0.6826\n",
            "Epoch 35/200\n",
            "17/17 - 133s - 8s/step - accuracy: 0.6728 - loss: 0.7949 - val_accuracy: 0.7213 - val_loss: 0.6866\n",
            "Epoch 36/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.6250 - loss: 0.7847 - val_accuracy: 0.7049 - val_loss: 0.7006\n",
            "Epoch 37/200\n",
            "17/17 - 131s - 8s/step - accuracy: 0.6562 - loss: 0.7650 - val_accuracy: 0.7213 - val_loss: 0.6957\n",
            "Epoch 38/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.6507 - loss: 0.7814 - val_accuracy: 0.7049 - val_loss: 0.7067\n",
            "Epoch 39/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.6324 - loss: 0.7832 - val_accuracy: 0.7049 - val_loss: 0.6921\n",
            "Epoch 40/200\n",
            "17/17 - 142s - 8s/step - accuracy: 0.6838 - loss: 0.7430 - val_accuracy: 0.7049 - val_loss: 0.6867\n",
            "Epoch 41/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.6710 - loss: 0.7979 - val_accuracy: 0.7541 - val_loss: 0.6847\n",
            "Epoch 42/200\n",
            "17/17 - 139s - 8s/step - accuracy: 0.6562 - loss: 0.7869 - val_accuracy: 0.7541 - val_loss: 0.6957\n",
            "Epoch 43/200\n",
            "17/17 - 140s - 8s/step - accuracy: 0.6820 - loss: 0.7271 - val_accuracy: 0.7213 - val_loss: 0.7033\n",
            "Epoch 44/200\n",
            "17/17 - 133s - 8s/step - accuracy: 0.6618 - loss: 0.7813 - val_accuracy: 0.7049 - val_loss: 0.7088\n",
            "Epoch 45/200\n",
            "17/17 - 142s - 8s/step - accuracy: 0.6728 - loss: 0.7830 - val_accuracy: 0.7213 - val_loss: 0.7016\n",
            "Epoch 46/200\n",
            "17/17 - 140s - 8s/step - accuracy: 0.6599 - loss: 0.7496 - val_accuracy: 0.6885 - val_loss: 0.7098\n",
            "Epoch 47/200\n",
            "17/17 - 134s - 8s/step - accuracy: 0.6985 - loss: 0.7446 - val_accuracy: 0.7541 - val_loss: 0.6915\n",
            "Epoch 48/200\n",
            "17/17 - 133s - 8s/step - accuracy: 0.6857 - loss: 0.7598 - val_accuracy: 0.7377 - val_loss: 0.6954\n",
            "Epoch 49/200\n",
            "17/17 - 131s - 8s/step - accuracy: 0.6562 - loss: 0.7680 - val_accuracy: 0.7377 - val_loss: 0.7057\n",
            "Epoch 50/200\n",
            "17/17 - 140s - 8s/step - accuracy: 0.6838 - loss: 0.7495 - val_accuracy: 0.7049 - val_loss: 0.7106\n",
            "Epoch 51/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.7059 - loss: 0.7085 - val_accuracy: 0.6885 - val_loss: 0.6844\n",
            "Epoch 52/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.7169 - loss: 0.6892 - val_accuracy: 0.7705 - val_loss: 0.6482\n",
            "Epoch 53/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.7224 - loss: 0.6567 - val_accuracy: 0.7541 - val_loss: 0.6513\n",
            "Epoch 54/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.6710 - loss: 0.7417 - val_accuracy: 0.7213 - val_loss: 0.6681\n",
            "Epoch 55/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.6985 - loss: 0.7303 - val_accuracy: 0.7541 - val_loss: 0.6637\n",
            "Epoch 56/200\n",
            "17/17 - 139s - 8s/step - accuracy: 0.7188 - loss: 0.7108 - val_accuracy: 0.7213 - val_loss: 0.6759\n",
            "Epoch 57/200\n",
            "17/17 - 140s - 8s/step - accuracy: 0.7224 - loss: 0.6855 - val_accuracy: 0.7213 - val_loss: 0.6401\n",
            "Epoch 58/200\n",
            "17/17 - 133s - 8s/step - accuracy: 0.7059 - loss: 0.7183 - val_accuracy: 0.6885 - val_loss: 0.6507\n",
            "Epoch 59/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.7022 - loss: 0.7218 - val_accuracy: 0.7377 - val_loss: 0.6339\n",
            "Epoch 60/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.7132 - loss: 0.6614 - val_accuracy: 0.7377 - val_loss: 0.6291\n",
            "Epoch 61/200\n",
            "17/17 - 133s - 8s/step - accuracy: 0.7169 - loss: 0.7028 - val_accuracy: 0.7377 - val_loss: 0.6190\n",
            "Epoch 62/200\n",
            "17/17 - 141s - 8s/step - accuracy: 0.7096 - loss: 0.6757 - val_accuracy: 0.7049 - val_loss: 0.6314\n",
            "Epoch 63/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.6949 - loss: 0.6840 - val_accuracy: 0.7049 - val_loss: 0.6225\n",
            "Epoch 64/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.7096 - loss: 0.7201 - val_accuracy: 0.7213 - val_loss: 0.6302\n",
            "Epoch 65/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.6967 - loss: 0.7127 - val_accuracy: 0.6885 - val_loss: 0.6394\n",
            "Epoch 66/200\n",
            "17/17 - 140s - 8s/step - accuracy: 0.7077 - loss: 0.6877 - val_accuracy: 0.6885 - val_loss: 0.6309\n",
            "Epoch 67/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.7445 - loss: 0.6448 - val_accuracy: 0.7049 - val_loss: 0.6237\n",
            "Epoch 68/200\n",
            "17/17 - 133s - 8s/step - accuracy: 0.7555 - loss: 0.6299 - val_accuracy: 0.7213 - val_loss: 0.6113\n",
            "Epoch 69/200\n",
            "17/17 - 139s - 8s/step - accuracy: 0.7206 - loss: 0.6746 - val_accuracy: 0.7541 - val_loss: 0.5986\n",
            "Epoch 70/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.7224 - loss: 0.7077 - val_accuracy: 0.7049 - val_loss: 0.6419\n",
            "Epoch 71/200\n",
            "17/17 - 133s - 8s/step - accuracy: 0.7206 - loss: 0.6786 - val_accuracy: 0.7213 - val_loss: 0.6357\n",
            "Epoch 72/200\n",
            "17/17 - 140s - 8s/step - accuracy: 0.7445 - loss: 0.6448 - val_accuracy: 0.6885 - val_loss: 0.6393\n",
            "Epoch 73/200\n",
            "17/17 - 140s - 8s/step - accuracy: 0.7298 - loss: 0.6328 - val_accuracy: 0.7705 - val_loss: 0.6174\n",
            "Epoch 74/200\n",
            "17/17 - 134s - 8s/step - accuracy: 0.6985 - loss: 0.6935 - val_accuracy: 0.7213 - val_loss: 0.6188\n",
            "Epoch 75/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.7316 - loss: 0.6572 - val_accuracy: 0.6721 - val_loss: 0.6338\n",
            "Epoch 76/200\n",
            "17/17 - 131s - 8s/step - accuracy: 0.7463 - loss: 0.6351 - val_accuracy: 0.7049 - val_loss: 0.6250\n",
            "Epoch 77/200\n",
            "17/17 - 139s - 8s/step - accuracy: 0.7206 - loss: 0.6648 - val_accuracy: 0.7213 - val_loss: 0.6245\n",
            "Epoch 78/200\n",
            "17/17 - 133s - 8s/step - accuracy: 0.7206 - loss: 0.6833 - val_accuracy: 0.7049 - val_loss: 0.6064\n",
            "Epoch 79/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.7390 - loss: 0.6708 - val_accuracy: 0.7377 - val_loss: 0.5937\n",
            "Epoch 80/200\n",
            "17/17 - 149s - 9s/step - accuracy: 0.7335 - loss: 0.6310 - val_accuracy: 0.7049 - val_loss: 0.6071\n",
            "Epoch 81/200\n",
            "17/17 - 136s - 8s/step - accuracy: 0.7353 - loss: 0.6568 - val_accuracy: 0.7377 - val_loss: 0.5999\n",
            "Epoch 82/200\n",
            "17/17 - 140s - 8s/step - accuracy: 0.7316 - loss: 0.6399 - val_accuracy: 0.7213 - val_loss: 0.5939\n",
            "Epoch 83/200\n",
            "17/17 - 133s - 8s/step - accuracy: 0.7022 - loss: 0.6519 - val_accuracy: 0.7213 - val_loss: 0.6023\n",
            "Epoch 84/200\n",
            "17/17 - 143s - 8s/step - accuracy: 0.7426 - loss: 0.6227 - val_accuracy: 0.7213 - val_loss: 0.6045\n",
            "Epoch 85/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.7445 - loss: 0.6491 - val_accuracy: 0.7213 - val_loss: 0.6102\n",
            "Epoch 86/200\n",
            "17/17 - 150s - 9s/step - accuracy: 0.7279 - loss: 0.6696 - val_accuracy: 0.7377 - val_loss: 0.5853\n",
            "Epoch 87/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.7886 - loss: 0.5778 - val_accuracy: 0.7541 - val_loss: 0.6092\n",
            "Epoch 88/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.7335 - loss: 0.6187 - val_accuracy: 0.7541 - val_loss: 0.5927\n",
            "Epoch 89/200\n",
            "17/17 - 141s - 8s/step - accuracy: 0.7335 - loss: 0.6328 - val_accuracy: 0.7541 - val_loss: 0.5742\n",
            "Epoch 90/200\n",
            "17/17 - 139s - 8s/step - accuracy: 0.7316 - loss: 0.6503 - val_accuracy: 0.7541 - val_loss: 0.5755\n",
            "Epoch 91/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.7059 - loss: 0.6520 - val_accuracy: 0.7705 - val_loss: 0.6011\n",
            "Epoch 92/200\n",
            "17/17 - 139s - 8s/step - accuracy: 0.7463 - loss: 0.6485 - val_accuracy: 0.7541 - val_loss: 0.5998\n",
            "Epoch 93/200\n",
            "17/17 - 141s - 8s/step - accuracy: 0.7574 - loss: 0.6033 - val_accuracy: 0.7213 - val_loss: 0.5952\n",
            "Epoch 94/200\n",
            "17/17 - 133s - 8s/step - accuracy: 0.7298 - loss: 0.6466 - val_accuracy: 0.7213 - val_loss: 0.5884\n",
            "Epoch 95/200\n",
            "17/17 - 139s - 8s/step - accuracy: 0.7298 - loss: 0.6621 - val_accuracy: 0.7705 - val_loss: 0.5541\n",
            "Epoch 96/200\n",
            "17/17 - 139s - 8s/step - accuracy: 0.7537 - loss: 0.6128 - val_accuracy: 0.7541 - val_loss: 0.5742\n",
            "Epoch 97/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.7206 - loss: 0.6363 - val_accuracy: 0.7541 - val_loss: 0.5769\n",
            "Epoch 98/200\n",
            "17/17 - 140s - 8s/step - accuracy: 0.7849 - loss: 0.5783 - val_accuracy: 0.7377 - val_loss: 0.5923\n",
            "Epoch 99/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.7371 - loss: 0.6305 - val_accuracy: 0.7541 - val_loss: 0.5623\n",
            "Epoch 100/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.7647 - loss: 0.5953 - val_accuracy: 0.7213 - val_loss: 0.5550\n",
            "Epoch 101/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.7555 - loss: 0.6137 - val_accuracy: 0.7541 - val_loss: 0.5707\n",
            "Epoch 102/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.7426 - loss: 0.6515 - val_accuracy: 0.7377 - val_loss: 0.5706\n",
            "Epoch 103/200\n",
            "17/17 - 151s - 9s/step - accuracy: 0.7206 - loss: 0.6104 - val_accuracy: 0.7213 - val_loss: 0.5875\n",
            "Epoch 104/200\n",
            "17/17 - 133s - 8s/step - accuracy: 0.7849 - loss: 0.5608 - val_accuracy: 0.7213 - val_loss: 0.6000\n",
            "Epoch 105/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.7665 - loss: 0.5997 - val_accuracy: 0.7049 - val_loss: 0.6055\n",
            "Epoch 106/200\n",
            "17/17 - 131s - 8s/step - accuracy: 0.7776 - loss: 0.5739 - val_accuracy: 0.7213 - val_loss: 0.5956\n",
            "Epoch 107/200\n",
            "17/17 - 140s - 8s/step - accuracy: 0.7555 - loss: 0.6071 - val_accuracy: 0.7213 - val_loss: 0.6186\n",
            "Epoch 108/200\n",
            "17/17 - 140s - 8s/step - accuracy: 0.7610 - loss: 0.5883 - val_accuracy: 0.7541 - val_loss: 0.5814\n",
            "Epoch 109/200\n",
            "17/17 - 139s - 8s/step - accuracy: 0.7739 - loss: 0.5987 - val_accuracy: 0.7213 - val_loss: 0.5967\n",
            "Epoch 110/200\n",
            "17/17 - 141s - 8s/step - accuracy: 0.7371 - loss: 0.6168 - val_accuracy: 0.7377 - val_loss: 0.5632\n",
            "Epoch 111/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.7279 - loss: 0.6436 - val_accuracy: 0.7377 - val_loss: 0.5701\n",
            "Epoch 112/200\n",
            "17/17 - 142s - 8s/step - accuracy: 0.7445 - loss: 0.6121 - val_accuracy: 0.7213 - val_loss: 0.5820\n",
            "Epoch 113/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.7592 - loss: 0.5977 - val_accuracy: 0.7213 - val_loss: 0.5816\n",
            "Epoch 114/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.7886 - loss: 0.5924 - val_accuracy: 0.7213 - val_loss: 0.6118\n",
            "Epoch 115/200\n",
            "17/17 - 138s - 8s/step - accuracy: 0.7445 - loss: 0.6114 - val_accuracy: 0.7705 - val_loss: 0.5727\n",
            "Epoch 116/200\n",
            "17/17 - 130s - 8s/step - accuracy: 0.7647 - loss: 0.5638 - val_accuracy: 0.7705 - val_loss: 0.5588\n",
            "Epoch 117/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.7537 - loss: 0.5680 - val_accuracy: 0.7541 - val_loss: 0.5669\n",
            "Epoch 118/200\n",
            "17/17 - 131s - 8s/step - accuracy: 0.7408 - loss: 0.6007 - val_accuracy: 0.7541 - val_loss: 0.5566\n",
            "Epoch 119/200\n",
            "17/17 - 131s - 8s/step - accuracy: 0.7592 - loss: 0.6144 - val_accuracy: 0.7541 - val_loss: 0.5571\n",
            "Epoch 120/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.7518 - loss: 0.5909 - val_accuracy: 0.7705 - val_loss: 0.5640\n",
            "Epoch 121/200\n",
            "17/17 - 138s - 8s/step - accuracy: 0.7500 - loss: 0.6131 - val_accuracy: 0.7541 - val_loss: 0.5705\n",
            "Epoch 122/200\n",
            "17/17 - 135s - 8s/step - accuracy: 0.7684 - loss: 0.5863 - val_accuracy: 0.7705 - val_loss: 0.6076\n",
            "Epoch 123/200\n",
            "17/17 - 133s - 8s/step - accuracy: 0.7739 - loss: 0.5991 - val_accuracy: 0.7213 - val_loss: 0.5970\n",
            "Epoch 124/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.7647 - loss: 0.5667 - val_accuracy: 0.7541 - val_loss: 0.5472\n",
            "Epoch 125/200\n",
            "17/17 - 131s - 8s/step - accuracy: 0.7482 - loss: 0.6227 - val_accuracy: 0.7213 - val_loss: 0.5609\n",
            "Epoch 126/200\n",
            "17/17 - 133s - 8s/step - accuracy: 0.7592 - loss: 0.5905 - val_accuracy: 0.7541 - val_loss: 0.5421\n",
            "Epoch 127/200\n",
            "17/17 - 133s - 8s/step - accuracy: 0.7757 - loss: 0.5991 - val_accuracy: 0.7377 - val_loss: 0.5415\n",
            "Epoch 128/200\n",
            "17/17 - 131s - 8s/step - accuracy: 0.7463 - loss: 0.5764 - val_accuracy: 0.7377 - val_loss: 0.5498\n",
            "Epoch 129/200\n",
            "17/17 - 139s - 8s/step - accuracy: 0.7518 - loss: 0.5564 - val_accuracy: 0.7541 - val_loss: 0.5396\n",
            "Epoch 130/200\n",
            "17/17 - 134s - 8s/step - accuracy: 0.7794 - loss: 0.5549 - val_accuracy: 0.7705 - val_loss: 0.5505\n",
            "Epoch 131/200\n",
            "17/17 - 139s - 8s/step - accuracy: 0.7684 - loss: 0.5603 - val_accuracy: 0.7541 - val_loss: 0.5405\n",
            "Epoch 132/200\n",
            "17/17 - 135s - 8s/step - accuracy: 0.7647 - loss: 0.5650 - val_accuracy: 0.7541 - val_loss: 0.5543\n",
            "Epoch 133/200\n",
            "17/17 - 139s - 8s/step - accuracy: 0.7537 - loss: 0.5828 - val_accuracy: 0.7541 - val_loss: 0.5386\n",
            "Epoch 134/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.7610 - loss: 0.5581 - val_accuracy: 0.7541 - val_loss: 0.5151\n",
            "Epoch 135/200\n",
            "17/17 - 134s - 8s/step - accuracy: 0.7574 - loss: 0.5628 - val_accuracy: 0.7049 - val_loss: 0.5365\n",
            "Epoch 136/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.7923 - loss: 0.5384 - val_accuracy: 0.7377 - val_loss: 0.5200\n",
            "Epoch 137/200\n",
            "17/17 - 133s - 8s/step - accuracy: 0.7960 - loss: 0.5153 - val_accuracy: 0.7541 - val_loss: 0.5203\n",
            "Epoch 138/200\n",
            "17/17 - 138s - 8s/step - accuracy: 0.7904 - loss: 0.5796 - val_accuracy: 0.7541 - val_loss: 0.5204\n",
            "Epoch 139/200\n",
            "17/17 - 133s - 8s/step - accuracy: 0.7776 - loss: 0.5638 - val_accuracy: 0.7213 - val_loss: 0.5272\n",
            "Epoch 140/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.7757 - loss: 0.5567 - val_accuracy: 0.7541 - val_loss: 0.5340\n",
            "Epoch 141/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.7592 - loss: 0.5794 - val_accuracy: 0.7377 - val_loss: 0.5337\n",
            "Epoch 142/200\n",
            "17/17 - 139s - 8s/step - accuracy: 0.7831 - loss: 0.5370 - val_accuracy: 0.7541 - val_loss: 0.5470\n",
            "Epoch 143/200\n",
            "17/17 - 134s - 8s/step - accuracy: 0.7831 - loss: 0.5382 - val_accuracy: 0.7541 - val_loss: 0.5511\n",
            "Epoch 144/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.7868 - loss: 0.5269 - val_accuracy: 0.7541 - val_loss: 0.5435\n",
            "Epoch 145/200\n",
            "17/17 - 139s - 8s/step - accuracy: 0.7757 - loss: 0.5551 - val_accuracy: 0.7541 - val_loss: 0.5426\n",
            "Epoch 146/200\n",
            "17/17 - 142s - 8s/step - accuracy: 0.7812 - loss: 0.5178 - val_accuracy: 0.7541 - val_loss: 0.5344\n",
            "Epoch 147/200\n",
            "17/17 - 141s - 8s/step - accuracy: 0.7757 - loss: 0.5551 - val_accuracy: 0.7705 - val_loss: 0.5633\n",
            "Epoch 148/200\n",
            "17/17 - 140s - 8s/step - accuracy: 0.7390 - loss: 0.5890 - val_accuracy: 0.7541 - val_loss: 0.5492\n",
            "Epoch 149/200\n",
            "17/17 - 133s - 8s/step - accuracy: 0.7904 - loss: 0.5416 - val_accuracy: 0.7377 - val_loss: 0.5463\n",
            "Epoch 150/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.7849 - loss: 0.5285 - val_accuracy: 0.7541 - val_loss: 0.5315\n",
            "Epoch 151/200\n",
            "17/17 - 131s - 8s/step - accuracy: 0.7518 - loss: 0.5717 - val_accuracy: 0.7213 - val_loss: 0.5624\n",
            "Epoch 152/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.7665 - loss: 0.5503 - val_accuracy: 0.7377 - val_loss: 0.5214\n",
            "Epoch 153/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.7812 - loss: 0.5541 - val_accuracy: 0.7213 - val_loss: 0.5217\n",
            "Epoch 154/200\n",
            "17/17 - 133s - 8s/step - accuracy: 0.7702 - loss: 0.5642 - val_accuracy: 0.7377 - val_loss: 0.5372\n",
            "Epoch 155/200\n",
            "17/17 - 138s - 8s/step - accuracy: 0.7904 - loss: 0.5198 - val_accuracy: 0.7541 - val_loss: 0.5254\n",
            "Epoch 156/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.7610 - loss: 0.5674 - val_accuracy: 0.7705 - val_loss: 0.5414\n",
            "Epoch 157/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.7665 - loss: 0.5497 - val_accuracy: 0.7541 - val_loss: 0.5309\n",
            "Epoch 158/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.7739 - loss: 0.5559 - val_accuracy: 0.7377 - val_loss: 0.5539\n",
            "Epoch 159/200\n",
            "17/17 - 131s - 8s/step - accuracy: 0.8107 - loss: 0.5152 - val_accuracy: 0.7377 - val_loss: 0.5227\n",
            "Epoch 160/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.7941 - loss: 0.5250 - val_accuracy: 0.7213 - val_loss: 0.5417\n",
            "Epoch 161/200\n",
            "17/17 - 139s - 8s/step - accuracy: 0.7812 - loss: 0.5368 - val_accuracy: 0.7541 - val_loss: 0.5166\n",
            "Epoch 162/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.7996 - loss: 0.5329 - val_accuracy: 0.7705 - val_loss: 0.4991\n",
            "Epoch 163/200\n",
            "17/17 - 139s - 8s/step - accuracy: 0.8033 - loss: 0.5227 - val_accuracy: 0.7705 - val_loss: 0.5399\n",
            "Epoch 164/200\n",
            "17/17 - 142s - 8s/step - accuracy: 0.7978 - loss: 0.4972 - val_accuracy: 0.7869 - val_loss: 0.5266\n",
            "Epoch 165/200\n",
            "17/17 - 139s - 8s/step - accuracy: 0.7960 - loss: 0.5021 - val_accuracy: 0.7705 - val_loss: 0.5456\n",
            "Epoch 166/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.7923 - loss: 0.5138 - val_accuracy: 0.7377 - val_loss: 0.5390\n",
            "Epoch 167/200\n",
            "17/17 - 133s - 8s/step - accuracy: 0.7978 - loss: 0.5277 - val_accuracy: 0.7541 - val_loss: 0.5505\n",
            "Epoch 168/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.7776 - loss: 0.5074 - val_accuracy: 0.7377 - val_loss: 0.5273\n",
            "Epoch 169/200\n",
            "17/17 - 139s - 8s/step - accuracy: 0.7702 - loss: 0.5382 - val_accuracy: 0.7705 - val_loss: 0.5604\n",
            "Epoch 170/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.7849 - loss: 0.5326 - val_accuracy: 0.7213 - val_loss: 0.5552\n",
            "Epoch 171/200\n",
            "17/17 - 139s - 8s/step - accuracy: 0.8088 - loss: 0.5119 - val_accuracy: 0.7377 - val_loss: 0.5461\n",
            "Epoch 172/200\n",
            "17/17 - 139s - 8s/step - accuracy: 0.7776 - loss: 0.5369 - val_accuracy: 0.7213 - val_loss: 0.5318\n",
            "Epoch 173/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.7868 - loss: 0.5315 - val_accuracy: 0.7213 - val_loss: 0.5366\n",
            "Epoch 174/200\n",
            "17/17 - 133s - 8s/step - accuracy: 0.7831 - loss: 0.5513 - val_accuracy: 0.7213 - val_loss: 0.5432\n",
            "Epoch 175/200\n",
            "17/17 - 139s - 8s/step - accuracy: 0.7904 - loss: 0.5253 - val_accuracy: 0.7541 - val_loss: 0.5333\n",
            "Epoch 176/200\n",
            "17/17 - 133s - 8s/step - accuracy: 0.7794 - loss: 0.5408 - val_accuracy: 0.7705 - val_loss: 0.5412\n",
            "Epoch 177/200\n",
            "17/17 - 133s - 8s/step - accuracy: 0.7849 - loss: 0.5250 - val_accuracy: 0.7705 - val_loss: 0.5373\n",
            "Epoch 178/200\n",
            "17/17 - 139s - 8s/step - accuracy: 0.8199 - loss: 0.5142 - val_accuracy: 0.7541 - val_loss: 0.5390\n",
            "Epoch 179/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.8051 - loss: 0.5137 - val_accuracy: 0.7213 - val_loss: 0.5527\n",
            "Epoch 180/200\n",
            "17/17 - 141s - 8s/step - accuracy: 0.8088 - loss: 0.5105 - val_accuracy: 0.7377 - val_loss: 0.5287\n",
            "Epoch 181/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.8015 - loss: 0.4808 - val_accuracy: 0.7377 - val_loss: 0.5342\n",
            "Epoch 182/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.7960 - loss: 0.5185 - val_accuracy: 0.7541 - val_loss: 0.5163\n",
            "Epoch 183/200\n",
            "17/17 - 139s - 8s/step - accuracy: 0.7849 - loss: 0.5030 - val_accuracy: 0.7705 - val_loss: 0.5052\n",
            "Epoch 184/200\n",
            "17/17 - 131s - 8s/step - accuracy: 0.8051 - loss: 0.5052 - val_accuracy: 0.7541 - val_loss: 0.5077\n",
            "Epoch 185/200\n",
            "17/17 - 140s - 8s/step - accuracy: 0.7684 - loss: 0.5618 - val_accuracy: 0.7377 - val_loss: 0.5194\n",
            "Epoch 186/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.8070 - loss: 0.5029 - val_accuracy: 0.7049 - val_loss: 0.5184\n",
            "Epoch 187/200\n",
            "17/17 - 133s - 8s/step - accuracy: 0.7904 - loss: 0.5282 - val_accuracy: 0.7049 - val_loss: 0.5523\n",
            "Epoch 188/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.7978 - loss: 0.5053 - val_accuracy: 0.7213 - val_loss: 0.5344\n",
            "Epoch 189/200\n",
            "17/17 - 139s - 8s/step - accuracy: 0.7592 - loss: 0.5525 - val_accuracy: 0.7705 - val_loss: 0.5112\n",
            "Epoch 190/200\n",
            "17/17 - 133s - 8s/step - accuracy: 0.8217 - loss: 0.4847 - val_accuracy: 0.7869 - val_loss: 0.5077\n",
            "Epoch 191/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.8070 - loss: 0.4870 - val_accuracy: 0.7541 - val_loss: 0.5213\n",
            "Epoch 192/200\n",
            "17/17 - 142s - 8s/step - accuracy: 0.7831 - loss: 0.4915 - val_accuracy: 0.7541 - val_loss: 0.5421\n",
            "Epoch 193/200\n",
            "17/17 - 133s - 8s/step - accuracy: 0.7849 - loss: 0.4975 - val_accuracy: 0.7705 - val_loss: 0.5376\n",
            "Epoch 194/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.7941 - loss: 0.4874 - val_accuracy: 0.7377 - val_loss: 0.5731\n",
            "Epoch 195/200\n",
            "17/17 - 132s - 8s/step - accuracy: 0.8015 - loss: 0.5010 - val_accuracy: 0.7213 - val_loss: 0.5449\n",
            "Epoch 196/200\n",
            "17/17 - 133s - 8s/step - accuracy: 0.8143 - loss: 0.4939 - val_accuracy: 0.7705 - val_loss: 0.5345\n",
            "Epoch 197/200\n",
            "17/17 - 133s - 8s/step - accuracy: 0.7868 - loss: 0.5146 - val_accuracy: 0.7377 - val_loss: 0.5385\n",
            "Epoch 198/200\n",
            "17/17 - 131s - 8s/step - accuracy: 0.7996 - loss: 0.5217 - val_accuracy: 0.7213 - val_loss: 0.5342\n",
            "Epoch 199/200\n",
            "17/17 - 141s - 8s/step - accuracy: 0.7868 - loss: 0.5093 - val_accuracy: 0.7377 - val_loss: 0.5045\n",
            "Epoch 200/200\n",
            "17/17 - 133s - 8s/step - accuracy: 0.8015 - loss: 0.4902 - val_accuracy: 0.7377 - val_loss: 0.5102\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model berhasil disimpan: model_split90_lr0.001_ep200_l20.0001.h5\n"
          ]
        }
      ],
      "source": [
        "split_ratio = 0.9\n",
        "split_percent = round(split_ratio * 100)\n",
        "\n",
        "for lr in [0.001]:\n",
        "    for epoch in [200]:\n",
        "        print(f\"\\n📦 Training model dengan split_ratio={split_percent}%, learning_rate={lr}, epochs={epoch}\")\n",
        "\n",
        "        model, history = train_model(\n",
        "            split_ratio=split_ratio,\n",
        "            lr=lr,\n",
        "            epochs=epoch\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0n2A4eSGm3QJ",
      "metadata": {
        "id": "0n2A4eSGm3QJ"
      },
      "source": [
        "### SPLIT RATIO 0.9 LEARNING RATE 0.0001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Pv7vR-KQmxm0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pv7vR-KQmxm0",
        "outputId": "890ebd18-0332-4c9b-93b2-d742b6a61ab7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📦 Training model dengan split_ratio=90%, learning_rate=0.0001, epochs=50\n",
            "Found 544 images belonging to 3 classes.\n",
            "Found 61 images belonging to 3 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "17/17 - 193s - 11s/step - accuracy: 0.3548 - loss: 2.0821 - val_accuracy: 0.5082 - val_loss: 1.0952\n",
            "Epoch 2/50\n",
            "17/17 - 166s - 10s/step - accuracy: 0.3419 - loss: 1.7955 - val_accuracy: 0.3934 - val_loss: 1.1751\n",
            "Epoch 3/50\n",
            "17/17 - 176s - 10s/step - accuracy: 0.3805 - loss: 1.7707 - val_accuracy: 0.4918 - val_loss: 1.0840\n",
            "Epoch 4/50\n",
            "17/17 - 193s - 11s/step - accuracy: 0.3768 - loss: 1.5979 - val_accuracy: 0.5246 - val_loss: 1.0655\n",
            "Epoch 5/50\n",
            "17/17 - 158s - 9s/step - accuracy: 0.3768 - loss: 1.5724 - val_accuracy: 0.5082 - val_loss: 1.0428\n",
            "Epoch 6/50\n",
            "17/17 - 160s - 9s/step - accuracy: 0.4210 - loss: 1.4449 - val_accuracy: 0.5246 - val_loss: 1.0345\n",
            "Epoch 7/50\n",
            "17/17 - 152s - 9s/step - accuracy: 0.3640 - loss: 1.5938 - val_accuracy: 0.5082 - val_loss: 1.0253\n",
            "Epoch 8/50\n",
            "17/17 - 157s - 9s/step - accuracy: 0.4136 - loss: 1.4292 - val_accuracy: 0.5410 - val_loss: 1.0070\n",
            "Epoch 9/50\n",
            "17/17 - 152s - 9s/step - accuracy: 0.4099 - loss: 1.4169 - val_accuracy: 0.5574 - val_loss: 1.0017\n",
            "Epoch 10/50\n",
            "17/17 - 162s - 10s/step - accuracy: 0.4007 - loss: 1.3922 - val_accuracy: 0.5574 - val_loss: 0.9939\n",
            "Epoch 11/50\n",
            "17/17 - 157s - 9s/step - accuracy: 0.4118 - loss: 1.3177 - val_accuracy: 0.5410 - val_loss: 0.9963\n",
            "Epoch 12/50\n",
            "17/17 - 151s - 9s/step - accuracy: 0.4559 - loss: 1.2776 - val_accuracy: 0.5574 - val_loss: 0.9922\n",
            "Epoch 13/50\n",
            "17/17 - 202s - 12s/step - accuracy: 0.4651 - loss: 1.1987 - val_accuracy: 0.5574 - val_loss: 0.9812\n",
            "Epoch 14/50\n",
            "17/17 - 171s - 10s/step - accuracy: 0.4779 - loss: 1.2134 - val_accuracy: 0.5574 - val_loss: 0.9770\n",
            "Epoch 15/50\n",
            "17/17 - 153s - 9s/step - accuracy: 0.4246 - loss: 1.2791 - val_accuracy: 0.5738 - val_loss: 0.9700\n",
            "Epoch 16/50\n",
            "17/17 - 152s - 9s/step - accuracy: 0.4908 - loss: 1.1535 - val_accuracy: 0.5738 - val_loss: 0.9637\n",
            "Epoch 17/50\n",
            "17/17 - 152s - 9s/step - accuracy: 0.4779 - loss: 1.1942 - val_accuracy: 0.5738 - val_loss: 0.9614\n",
            "Epoch 18/50\n",
            "17/17 - 152s - 9s/step - accuracy: 0.4835 - loss: 1.1566 - val_accuracy: 0.5738 - val_loss: 0.9615\n",
            "Epoch 19/50\n",
            "17/17 - 152s - 9s/step - accuracy: 0.4559 - loss: 1.1857 - val_accuracy: 0.5738 - val_loss: 0.9602\n",
            "Epoch 20/50\n",
            "17/17 - 166s - 10s/step - accuracy: 0.4835 - loss: 1.1464 - val_accuracy: 0.5902 - val_loss: 0.9514\n",
            "Epoch 21/50\n",
            "17/17 - 171s - 10s/step - accuracy: 0.5110 - loss: 1.0951 - val_accuracy: 0.6066 - val_loss: 0.9486\n",
            "Epoch 22/50\n",
            "17/17 - 169s - 10s/step - accuracy: 0.4871 - loss: 1.0897 - val_accuracy: 0.6230 - val_loss: 0.9374\n",
            "Epoch 23/50\n",
            "17/17 - 171s - 10s/step - accuracy: 0.5018 - loss: 1.0684 - val_accuracy: 0.6230 - val_loss: 0.9357\n",
            "Epoch 24/50\n",
            "17/17 - 168s - 10s/step - accuracy: 0.4724 - loss: 1.1367 - val_accuracy: 0.6230 - val_loss: 0.9380\n",
            "Epoch 25/50\n",
            "17/17 - 152s - 9s/step - accuracy: 0.4761 - loss: 1.1417 - val_accuracy: 0.6066 - val_loss: 0.9330\n",
            "Epoch 26/50\n",
            "17/17 - 152s - 9s/step - accuracy: 0.4926 - loss: 1.1212 - val_accuracy: 0.6230 - val_loss: 0.9291\n",
            "Epoch 27/50\n",
            "17/17 - 207s - 12s/step - accuracy: 0.5386 - loss: 1.0510 - val_accuracy: 0.6230 - val_loss: 0.9248\n",
            "Epoch 28/50\n",
            "17/17 - 158s - 9s/step - accuracy: 0.5202 - loss: 1.0498 - val_accuracy: 0.6230 - val_loss: 0.9254\n",
            "Epoch 29/50\n",
            "17/17 - 152s - 9s/step - accuracy: 0.5018 - loss: 1.0841 - val_accuracy: 0.6066 - val_loss: 0.9250\n",
            "Epoch 30/50\n",
            "17/17 - 203s - 12s/step - accuracy: 0.5257 - loss: 1.0569 - val_accuracy: 0.6066 - val_loss: 0.9241\n",
            "Epoch 31/50\n",
            "17/17 - 201s - 12s/step - accuracy: 0.5092 - loss: 1.0864 - val_accuracy: 0.6230 - val_loss: 0.9191\n",
            "Epoch 32/50\n",
            "17/17 - 157s - 9s/step - accuracy: 0.5202 - loss: 1.0379 - val_accuracy: 0.6230 - val_loss: 0.9201\n",
            "Epoch 33/50\n",
            "17/17 - 196s - 12s/step - accuracy: 0.5055 - loss: 1.0567 - val_accuracy: 0.6066 - val_loss: 0.9134\n",
            "Epoch 34/50\n",
            "17/17 - 166s - 10s/step - accuracy: 0.4945 - loss: 1.0939 - val_accuracy: 0.6393 - val_loss: 0.9096\n",
            "Epoch 35/50\n",
            "17/17 - 159s - 9s/step - accuracy: 0.5147 - loss: 1.0434 - val_accuracy: 0.6230 - val_loss: 0.9058\n",
            "Epoch 36/50\n",
            "17/17 - 153s - 9s/step - accuracy: 0.5221 - loss: 1.0659 - val_accuracy: 0.6557 - val_loss: 0.9046\n",
            "Epoch 37/50\n",
            "17/17 - 155s - 9s/step - accuracy: 0.5239 - loss: 1.0357 - val_accuracy: 0.6393 - val_loss: 0.9033\n",
            "Epoch 38/50\n",
            "17/17 - 159s - 9s/step - accuracy: 0.5423 - loss: 1.0223 - val_accuracy: 0.6230 - val_loss: 0.9031\n",
            "Epoch 39/50\n",
            "17/17 - 161s - 9s/step - accuracy: 0.5037 - loss: 1.0337 - val_accuracy: 0.6393 - val_loss: 0.9018\n",
            "Epoch 40/50\n",
            "17/17 - 154s - 9s/step - accuracy: 0.5165 - loss: 1.0454 - val_accuracy: 0.6393 - val_loss: 0.9018\n",
            "Epoch 41/50\n",
            "17/17 - 159s - 9s/step - accuracy: 0.5276 - loss: 1.0211 - val_accuracy: 0.6393 - val_loss: 0.9013\n",
            "Epoch 42/50\n",
            "17/17 - 158s - 9s/step - accuracy: 0.5460 - loss: 0.9956 - val_accuracy: 0.6230 - val_loss: 0.9004\n",
            "Epoch 43/50\n",
            "17/17 - 162s - 10s/step - accuracy: 0.5055 - loss: 1.0438 - val_accuracy: 0.6230 - val_loss: 0.9010\n",
            "Epoch 44/50\n",
            "17/17 - 153s - 9s/step - accuracy: 0.5202 - loss: 1.0471 - val_accuracy: 0.6393 - val_loss: 0.9012\n",
            "Epoch 45/50\n",
            "17/17 - 153s - 9s/step - accuracy: 0.5055 - loss: 1.0010 - val_accuracy: 0.6393 - val_loss: 0.8994\n",
            "Epoch 46/50\n",
            "17/17 - 153s - 9s/step - accuracy: 0.5092 - loss: 1.0487 - val_accuracy: 0.6393 - val_loss: 0.8965\n",
            "Epoch 47/50\n",
            "17/17 - 152s - 9s/step - accuracy: 0.5680 - loss: 0.9827 - val_accuracy: 0.6393 - val_loss: 0.8942\n",
            "Epoch 48/50\n",
            "17/17 - 152s - 9s/step - accuracy: 0.5404 - loss: 1.0130 - val_accuracy: 0.6557 - val_loss: 0.8902\n",
            "Epoch 49/50\n",
            "17/17 - 159s - 9s/step - accuracy: 0.5202 - loss: 1.0098 - val_accuracy: 0.6557 - val_loss: 0.8921\n",
            "Epoch 50/50\n",
            "17/17 - 154s - 9s/step - accuracy: 0.5680 - loss: 0.9543 - val_accuracy: 0.6393 - val_loss: 0.8917\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model berhasil disimpan: model_split90_lr0.0001_ep50_l20.0001.h5\n"
          ]
        }
      ],
      "source": [
        "split_ratio = 0.9\n",
        "split_percent = round(split_ratio * 100)\n",
        "\n",
        "for lr in [0.0001]:\n",
        "    for epoch in [50]:\n",
        "        print(f\"\\n📦 Training model dengan split_ratio={split_percent}%, learning_rate={lr}, epochs={epoch}\")\n",
        "\n",
        "        model, history = train_model(\n",
        "            split_ratio=split_ratio,\n",
        "            lr=lr,\n",
        "            epochs=epoch\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ASEjYSnzfkRJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASEjYSnzfkRJ",
        "outputId": "263a87a2-b515-4c42-a31a-7bda1bb6a8dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📦 Training model dengan split_ratio=90%, learning_rate=0.0001, epochs=100\n",
            "Found 544 images belonging to 3 classes.\n",
            "Found 61 images belonging to 3 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "17/17 - 190s - 11s/step - accuracy: 0.3272 - loss: 2.3495 - val_accuracy: 0.2787 - val_loss: 1.2689\n",
            "Epoch 2/100\n",
            "17/17 - 169s - 10s/step - accuracy: 0.3548 - loss: 1.8690 - val_accuracy: 0.2951 - val_loss: 1.2981\n",
            "Epoch 3/100\n",
            "17/17 - 172s - 10s/step - accuracy: 0.3254 - loss: 1.9012 - val_accuracy: 0.3115 - val_loss: 1.2031\n",
            "Epoch 4/100\n",
            "17/17 - 171s - 10s/step - accuracy: 0.3695 - loss: 1.6723 - val_accuracy: 0.3115 - val_loss: 1.1316\n",
            "Epoch 5/100\n",
            "17/17 - 167s - 10s/step - accuracy: 0.3732 - loss: 1.6144 - val_accuracy: 0.3443 - val_loss: 1.0948\n",
            "Epoch 6/100\n",
            "17/17 - 200s - 12s/step - accuracy: 0.3787 - loss: 1.5380 - val_accuracy: 0.3443 - val_loss: 1.0848\n",
            "Epoch 7/100\n",
            "17/17 - 191s - 11s/step - accuracy: 0.4044 - loss: 1.4364 - val_accuracy: 0.3770 - val_loss: 1.0625\n",
            "Epoch 8/100\n",
            "17/17 - 173s - 10s/step - accuracy: 0.4173 - loss: 1.4271 - val_accuracy: 0.3770 - val_loss: 1.0486\n",
            "Epoch 9/100\n",
            "17/17 - 167s - 10s/step - accuracy: 0.3860 - loss: 1.3848 - val_accuracy: 0.3770 - val_loss: 1.0308\n",
            "Epoch 10/100\n",
            "17/17 - 202s - 12s/step - accuracy: 0.4283 - loss: 1.2861 - val_accuracy: 0.3770 - val_loss: 1.0254\n",
            "Epoch 11/100\n",
            "17/17 - 176s - 10s/step - accuracy: 0.4688 - loss: 1.2375 - val_accuracy: 0.3770 - val_loss: 1.0281\n",
            "Epoch 12/100\n",
            "17/17 - 167s - 10s/step - accuracy: 0.4467 - loss: 1.2619 - val_accuracy: 0.3934 - val_loss: 1.0147\n",
            "Epoch 13/100\n",
            "17/17 - 167s - 10s/step - accuracy: 0.4522 - loss: 1.2078 - val_accuracy: 0.4426 - val_loss: 1.0032\n",
            "Epoch 14/100\n",
            "17/17 - 169s - 10s/step - accuracy: 0.4577 - loss: 1.2333 - val_accuracy: 0.4262 - val_loss: 1.0005\n",
            "Epoch 15/100\n",
            "17/17 - 202s - 12s/step - accuracy: 0.4945 - loss: 1.1338 - val_accuracy: 0.4426 - val_loss: 0.9901\n",
            "Epoch 16/100\n",
            "17/17 - 164s - 10s/step - accuracy: 0.4504 - loss: 1.2263 - val_accuracy: 0.4754 - val_loss: 0.9935\n",
            "Epoch 17/100\n",
            "17/17 - 208s - 12s/step - accuracy: 0.4651 - loss: 1.1821 - val_accuracy: 0.4918 - val_loss: 0.9879\n",
            "Epoch 18/100\n",
            "17/17 - 165s - 10s/step - accuracy: 0.4393 - loss: 1.1907 - val_accuracy: 0.4918 - val_loss: 0.9799\n",
            "Epoch 19/100\n",
            "17/17 - 167s - 10s/step - accuracy: 0.4504 - loss: 1.1089 - val_accuracy: 0.5246 - val_loss: 0.9737\n",
            "Epoch 20/100\n",
            "17/17 - 165s - 10s/step - accuracy: 0.5037 - loss: 1.1320 - val_accuracy: 0.5410 - val_loss: 0.9688\n",
            "Epoch 21/100\n",
            "17/17 - 166s - 10s/step - accuracy: 0.4724 - loss: 1.1397 - val_accuracy: 0.5246 - val_loss: 0.9651\n",
            "Epoch 22/100\n",
            "17/17 - 166s - 10s/step - accuracy: 0.4926 - loss: 1.1288 - val_accuracy: 0.5410 - val_loss: 0.9678\n",
            "Epoch 23/100\n",
            "17/17 - 167s - 10s/step - accuracy: 0.4798 - loss: 1.1022 - val_accuracy: 0.5246 - val_loss: 0.9610\n",
            "Epoch 24/100\n",
            "17/17 - 165s - 10s/step - accuracy: 0.5037 - loss: 1.0681 - val_accuracy: 0.5574 - val_loss: 0.9564\n",
            "Epoch 25/100\n",
            "17/17 - 167s - 10s/step - accuracy: 0.5055 - loss: 1.0428 - val_accuracy: 0.5410 - val_loss: 0.9522\n",
            "Epoch 26/100\n",
            "17/17 - 165s - 10s/step - accuracy: 0.4982 - loss: 1.0502 - val_accuracy: 0.5082 - val_loss: 0.9503\n",
            "Epoch 27/100\n",
            "17/17 - 167s - 10s/step - accuracy: 0.4982 - loss: 1.0846 - val_accuracy: 0.5246 - val_loss: 0.9503\n",
            "Epoch 28/100\n",
            "17/17 - 165s - 10s/step - accuracy: 0.4871 - loss: 1.1150 - val_accuracy: 0.5574 - val_loss: 0.9503\n",
            "Epoch 29/100\n",
            "17/17 - 171s - 10s/step - accuracy: 0.5110 - loss: 1.0919 - val_accuracy: 0.5574 - val_loss: 0.9484\n",
            "Epoch 30/100\n",
            "17/17 - 196s - 12s/step - accuracy: 0.5000 - loss: 1.0554 - val_accuracy: 0.5574 - val_loss: 0.9457\n",
            "Epoch 31/100\n",
            "17/17 - 169s - 10s/step - accuracy: 0.4835 - loss: 1.0823 - val_accuracy: 0.5574 - val_loss: 0.9426\n",
            "Epoch 32/100\n",
            "17/17 - 165s - 10s/step - accuracy: 0.5165 - loss: 1.0325 - val_accuracy: 0.5574 - val_loss: 0.9420\n",
            "Epoch 33/100\n",
            "17/17 - 171s - 10s/step - accuracy: 0.5625 - loss: 0.9834 - val_accuracy: 0.5574 - val_loss: 0.9414\n",
            "Epoch 34/100\n",
            "17/17 - 169s - 10s/step - accuracy: 0.4890 - loss: 1.0703 - val_accuracy: 0.5574 - val_loss: 0.9401\n",
            "Epoch 35/100\n",
            "17/17 - 165s - 10s/step - accuracy: 0.4779 - loss: 1.0568 - val_accuracy: 0.5574 - val_loss: 0.9372\n",
            "Epoch 36/100\n",
            "17/17 - 166s - 10s/step - accuracy: 0.5147 - loss: 1.0398 - val_accuracy: 0.5574 - val_loss: 0.9378\n",
            "Epoch 37/100\n",
            "17/17 - 165s - 10s/step - accuracy: 0.5276 - loss: 1.0221 - val_accuracy: 0.5574 - val_loss: 0.9398\n",
            "Epoch 38/100\n",
            "17/17 - 166s - 10s/step - accuracy: 0.5018 - loss: 1.0481 - val_accuracy: 0.5410 - val_loss: 0.9367\n",
            "Epoch 39/100\n",
            "17/17 - 164s - 10s/step - accuracy: 0.5202 - loss: 0.9927 - val_accuracy: 0.5410 - val_loss: 0.9354\n",
            "Epoch 40/100\n",
            "17/17 - 167s - 10s/step - accuracy: 0.5312 - loss: 0.9946 - val_accuracy: 0.5410 - val_loss: 0.9339\n",
            "Epoch 41/100\n",
            "17/17 - 202s - 12s/step - accuracy: 0.5184 - loss: 1.0030 - val_accuracy: 0.5410 - val_loss: 0.9338\n",
            "Epoch 42/100\n",
            "17/17 - 171s - 10s/step - accuracy: 0.4926 - loss: 1.0125 - val_accuracy: 0.5410 - val_loss: 0.9308\n",
            "Epoch 43/100\n",
            "17/17 - 169s - 10s/step - accuracy: 0.5368 - loss: 0.9702 - val_accuracy: 0.5410 - val_loss: 0.9267\n",
            "Epoch 44/100\n",
            "17/17 - 165s - 10s/step - accuracy: 0.5312 - loss: 0.9849 - val_accuracy: 0.5410 - val_loss: 0.9256\n",
            "Epoch 45/100\n",
            "17/17 - 168s - 10s/step - accuracy: 0.5478 - loss: 0.9788 - val_accuracy: 0.5574 - val_loss: 0.9213\n",
            "Epoch 46/100\n",
            "17/17 - 165s - 10s/step - accuracy: 0.5165 - loss: 1.0102 - val_accuracy: 0.5574 - val_loss: 0.9225\n",
            "Epoch 47/100\n",
            "17/17 - 168s - 10s/step - accuracy: 0.5404 - loss: 0.9481 - val_accuracy: 0.5574 - val_loss: 0.9240\n",
            "Epoch 48/100\n",
            "17/17 - 165s - 10s/step - accuracy: 0.5772 - loss: 0.9970 - val_accuracy: 0.5410 - val_loss: 0.9242\n",
            "Epoch 49/100\n",
            "17/17 - 204s - 12s/step - accuracy: 0.5276 - loss: 1.0200 - val_accuracy: 0.5246 - val_loss: 0.9264\n",
            "Epoch 50/100\n",
            "17/17 - 201s - 12s/step - accuracy: 0.5276 - loss: 0.9741 - val_accuracy: 0.5410 - val_loss: 0.9252\n",
            "Epoch 51/100\n",
            "17/17 - 165s - 10s/step - accuracy: 0.5588 - loss: 0.9630 - val_accuracy: 0.5410 - val_loss: 0.9217\n",
            "Epoch 52/100\n",
            "17/17 - 171s - 10s/step - accuracy: 0.5607 - loss: 0.9525 - val_accuracy: 0.5246 - val_loss: 0.9213\n",
            "Epoch 53/100\n",
            "17/17 - 170s - 10s/step - accuracy: 0.5460 - loss: 0.9491 - val_accuracy: 0.5246 - val_loss: 0.9186\n",
            "Epoch 54/100\n",
            "17/17 - 165s - 10s/step - accuracy: 0.5515 - loss: 0.9519 - val_accuracy: 0.5410 - val_loss: 0.9189\n",
            "Epoch 55/100\n",
            "17/17 - 208s - 12s/step - accuracy: 0.5386 - loss: 0.9959 - val_accuracy: 0.5574 - val_loss: 0.9196\n",
            "Epoch 56/100\n",
            "17/17 - 169s - 10s/step - accuracy: 0.5460 - loss: 0.9622 - val_accuracy: 0.5574 - val_loss: 0.9167\n",
            "Epoch 57/100\n",
            "17/17 - 165s - 10s/step - accuracy: 0.5533 - loss: 0.9576 - val_accuracy: 0.6230 - val_loss: 0.9142\n",
            "Epoch 58/100\n",
            "17/17 - 168s - 10s/step - accuracy: 0.5496 - loss: 0.9755 - val_accuracy: 0.6066 - val_loss: 0.9132\n",
            "Epoch 59/100\n",
            "17/17 - 169s - 10s/step - accuracy: 0.5423 - loss: 0.9951 - val_accuracy: 0.6066 - val_loss: 0.9150\n",
            "Epoch 60/100\n",
            "17/17 - 165s - 10s/step - accuracy: 0.5551 - loss: 0.9457 - val_accuracy: 0.6066 - val_loss: 0.9127\n",
            "Epoch 61/100\n",
            "17/17 - 170s - 10s/step - accuracy: 0.5625 - loss: 0.9762 - val_accuracy: 0.6066 - val_loss: 0.9129\n",
            "Epoch 62/100\n",
            "17/17 - 164s - 10s/step - accuracy: 0.5735 - loss: 0.9426 - val_accuracy: 0.6066 - val_loss: 0.9124\n",
            "Epoch 63/100\n",
            "17/17 - 166s - 10s/step - accuracy: 0.5312 - loss: 0.9398 - val_accuracy: 0.6066 - val_loss: 0.9109\n",
            "Epoch 64/100\n",
            "17/17 - 164s - 10s/step - accuracy: 0.5735 - loss: 0.9249 - val_accuracy: 0.6066 - val_loss: 0.9096\n",
            "Epoch 65/100\n",
            "17/17 - 167s - 10s/step - accuracy: 0.5846 - loss: 0.9366 - val_accuracy: 0.5902 - val_loss: 0.9070\n",
            "Epoch 66/100\n",
            "17/17 - 164s - 10s/step - accuracy: 0.5790 - loss: 0.9185 - val_accuracy: 0.5902 - val_loss: 0.9077\n",
            "Epoch 67/100\n",
            "17/17 - 170s - 10s/step - accuracy: 0.5423 - loss: 0.9569 - val_accuracy: 0.5902 - val_loss: 0.9064\n",
            "Epoch 68/100\n",
            "17/17 - 170s - 10s/step - accuracy: 0.5846 - loss: 0.9344 - val_accuracy: 0.6066 - val_loss: 0.9025\n",
            "Epoch 69/100\n",
            "17/17 - 165s - 10s/step - accuracy: 0.5588 - loss: 0.9499 - val_accuracy: 0.6066 - val_loss: 0.9006\n",
            "Epoch 70/100\n",
            "17/17 - 206s - 12s/step - accuracy: 0.5938 - loss: 0.9080 - val_accuracy: 0.6066 - val_loss: 0.8979\n",
            "Epoch 71/100\n",
            "17/17 - 164s - 10s/step - accuracy: 0.5790 - loss: 0.9327 - val_accuracy: 0.6066 - val_loss: 0.8949\n",
            "Epoch 72/100\n",
            "17/17 - 167s - 10s/step - accuracy: 0.5717 - loss: 0.9415 - val_accuracy: 0.6066 - val_loss: 0.8917\n",
            "Epoch 73/100\n",
            "17/17 - 164s - 10s/step - accuracy: 0.5717 - loss: 0.9427 - val_accuracy: 0.6066 - val_loss: 0.8921\n",
            "Epoch 74/100\n",
            "17/17 - 168s - 10s/step - accuracy: 0.5956 - loss: 0.8875 - val_accuracy: 0.5902 - val_loss: 0.8895\n",
            "Epoch 75/100\n",
            "17/17 - 167s - 10s/step - accuracy: 0.5938 - loss: 0.9335 - val_accuracy: 0.5902 - val_loss: 0.8888\n",
            "Epoch 76/100\n",
            "17/17 - 167s - 10s/step - accuracy: 0.5809 - loss: 0.8996 - val_accuracy: 0.5902 - val_loss: 0.8874\n",
            "Epoch 77/100\n",
            "17/17 - 171s - 10s/step - accuracy: 0.5956 - loss: 0.9079 - val_accuracy: 0.5738 - val_loss: 0.8896\n",
            "Epoch 78/100\n",
            "17/17 - 165s - 10s/step - accuracy: 0.5570 - loss: 0.9414 - val_accuracy: 0.5574 - val_loss: 0.8882\n",
            "Epoch 79/100\n",
            "17/17 - 166s - 10s/step - accuracy: 0.5809 - loss: 0.9427 - val_accuracy: 0.5738 - val_loss: 0.8844\n",
            "Epoch 80/100\n",
            "17/17 - 202s - 12s/step - accuracy: 0.5680 - loss: 0.9558 - val_accuracy: 0.5738 - val_loss: 0.8840\n",
            "Epoch 81/100\n",
            "17/17 - 169s - 10s/step - accuracy: 0.5809 - loss: 0.9261 - val_accuracy: 0.5738 - val_loss: 0.8851\n",
            "Epoch 82/100\n",
            "17/17 - 167s - 10s/step - accuracy: 0.5974 - loss: 0.9270 - val_accuracy: 0.5902 - val_loss: 0.8862\n",
            "Epoch 83/100\n",
            "17/17 - 167s - 10s/step - accuracy: 0.5864 - loss: 0.9241 - val_accuracy: 0.5902 - val_loss: 0.8873\n",
            "Epoch 84/100\n",
            "17/17 - 173s - 10s/step - accuracy: 0.5699 - loss: 0.9384 - val_accuracy: 0.5738 - val_loss: 0.8859\n",
            "Epoch 85/100\n",
            "17/17 - 170s - 10s/step - accuracy: 0.5717 - loss: 0.9140 - val_accuracy: 0.5902 - val_loss: 0.8833\n",
            "Epoch 86/100\n",
            "17/17 - 166s - 10s/step - accuracy: 0.5625 - loss: 0.9256 - val_accuracy: 0.5902 - val_loss: 0.8810\n",
            "Epoch 87/100\n",
            "17/17 - 172s - 10s/step - accuracy: 0.5993 - loss: 0.8813 - val_accuracy: 0.5738 - val_loss: 0.8787\n",
            "Epoch 88/100\n",
            "17/17 - 171s - 10s/step - accuracy: 0.6250 - loss: 0.8802 - val_accuracy: 0.5574 - val_loss: 0.8775\n",
            "Epoch 89/100\n",
            "17/17 - 170s - 10s/step - accuracy: 0.5680 - loss: 0.9105 - val_accuracy: 0.5574 - val_loss: 0.8781\n",
            "Epoch 90/100\n",
            "17/17 - 168s - 10s/step - accuracy: 0.5993 - loss: 0.8973 - val_accuracy: 0.5574 - val_loss: 0.8749\n",
            "Epoch 91/100\n",
            "17/17 - 206s - 12s/step - accuracy: 0.5754 - loss: 0.9283 - val_accuracy: 0.5574 - val_loss: 0.8733\n",
            "Epoch 92/100\n",
            "17/17 - 170s - 10s/step - accuracy: 0.5717 - loss: 0.9029 - val_accuracy: 0.5574 - val_loss: 0.8703\n",
            "Epoch 93/100\n",
            "17/17 - 164s - 10s/step - accuracy: 0.5864 - loss: 0.8827 - val_accuracy: 0.5738 - val_loss: 0.8679\n",
            "Epoch 94/100\n",
            "17/17 - 166s - 10s/step - accuracy: 0.6158 - loss: 0.9007 - val_accuracy: 0.5738 - val_loss: 0.8673\n",
            "Epoch 95/100\n",
            "17/17 - 165s - 10s/step - accuracy: 0.6029 - loss: 0.8988 - val_accuracy: 0.5738 - val_loss: 0.8667\n",
            "Epoch 96/100\n",
            "17/17 - 209s - 12s/step - accuracy: 0.5551 - loss: 0.9529 - val_accuracy: 0.5738 - val_loss: 0.8677\n",
            "Epoch 97/100\n",
            "17/17 - 170s - 10s/step - accuracy: 0.6048 - loss: 0.9017 - val_accuracy: 0.5738 - val_loss: 0.8669\n",
            "Epoch 98/100\n",
            "17/17 - 175s - 10s/step - accuracy: 0.5864 - loss: 0.8994 - val_accuracy: 0.5738 - val_loss: 0.8671\n",
            "Epoch 99/100\n",
            "17/17 - 169s - 10s/step - accuracy: 0.6140 - loss: 0.8827 - val_accuracy: 0.5738 - val_loss: 0.8674\n",
            "Epoch 100/100\n",
            "17/17 - 166s - 10s/step - accuracy: 0.5938 - loss: 0.8989 - val_accuracy: 0.5738 - val_loss: 0.8674\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model berhasil disimpan: model_split90_lr0.0001_ep100_l20.0001.h5\n"
          ]
        }
      ],
      "source": [
        "split_ratio = 0.9\n",
        "split_percent = round(split_ratio * 100)\n",
        "\n",
        "for lr in [0.0001]:\n",
        "    for epoch in [100]:\n",
        "        print(f\"\\n📦 Training model dengan split_ratio={split_percent}%, learning_rate={lr}, epochs={epoch}\")\n",
        "\n",
        "        model, history = train_model(\n",
        "            split_ratio=split_ratio,\n",
        "            lr=lr,\n",
        "            epochs=epoch\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fTBmOFb1Ogi",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fTBmOFb1Ogi",
        "outputId": "9ae9694e-bef3-4a21-ac15-a2d926899a0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📦 Training model dengan split_ratio=90%, learning_rate=0.0001, epochs=200\n",
            "Found 544 images belonging to 3 classes.\n",
            "Found 61 images belonging to 3 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "17/17 - 172s - 10s/step - accuracy: 0.3180 - loss: 2.0867 - val_accuracy: 0.3770 - val_loss: 1.2420\n",
            "Epoch 2/200\n",
            "17/17 - 151s - 9s/step - accuracy: 0.3493 - loss: 1.7645 - val_accuracy: 0.3279 - val_loss: 1.1723\n",
            "Epoch 3/200\n",
            "17/17 - 159s - 9s/step - accuracy: 0.3621 - loss: 1.6984 - val_accuracy: 0.2787 - val_loss: 1.1392\n",
            "Epoch 4/200\n",
            "17/17 - 155s - 9s/step - accuracy: 0.3805 - loss: 1.6035 - val_accuracy: 0.3607 - val_loss: 1.1220\n",
            "Epoch 5/200\n",
            "17/17 - 156s - 9s/step - accuracy: 0.3842 - loss: 1.5394 - val_accuracy: 0.3770 - val_loss: 1.1036\n",
            "Epoch 6/200\n",
            "17/17 - 151s - 9s/step - accuracy: 0.3658 - loss: 1.4673 - val_accuracy: 0.4098 - val_loss: 1.0888\n",
            "Epoch 7/200\n",
            "17/17 - 207s - 12s/step - accuracy: 0.4210 - loss: 1.3715 - val_accuracy: 0.3934 - val_loss: 1.0805\n",
            "Epoch 8/200\n",
            "17/17 - 152s - 9s/step - accuracy: 0.4118 - loss: 1.3824 - val_accuracy: 0.3934 - val_loss: 1.0717\n",
            "Epoch 9/200\n",
            "17/17 - 164s - 10s/step - accuracy: 0.4118 - loss: 1.3524 - val_accuracy: 0.3934 - val_loss: 1.0617\n",
            "Epoch 10/200\n",
            "17/17 - 159s - 9s/step - accuracy: 0.4338 - loss: 1.3053 - val_accuracy: 0.4262 - val_loss: 1.0478\n",
            "Epoch 11/200\n",
            "17/17 - 153s - 9s/step - accuracy: 0.4154 - loss: 1.2411 - val_accuracy: 0.4426 - val_loss: 1.0392\n",
            "Epoch 12/200\n",
            "17/17 - 207s - 12s/step - accuracy: 0.3934 - loss: 1.3103 - val_accuracy: 0.4590 - val_loss: 1.0278\n",
            "Epoch 13/200\n",
            "17/17 - 150s - 9s/step - accuracy: 0.4449 - loss: 1.2353 - val_accuracy: 0.4590 - val_loss: 1.0173\n",
            "Epoch 14/200\n",
            "17/17 - 151s - 9s/step - accuracy: 0.4210 - loss: 1.2698 - val_accuracy: 0.4590 - val_loss: 1.0120\n",
            "Epoch 15/200\n",
            "17/17 - 160s - 9s/step - accuracy: 0.4522 - loss: 1.1571 - val_accuracy: 0.4918 - val_loss: 1.0028\n",
            "Epoch 16/200\n",
            "17/17 - 151s - 9s/step - accuracy: 0.4504 - loss: 1.1704 - val_accuracy: 0.4754 - val_loss: 0.9942\n",
            "Epoch 17/200\n",
            "17/17 - 152s - 9s/step - accuracy: 0.4081 - loss: 1.2303 - val_accuracy: 0.4754 - val_loss: 0.9864\n",
            "Epoch 18/200\n",
            "17/17 - 157s - 9s/step - accuracy: 0.4577 - loss: 1.1819 - val_accuracy: 0.4918 - val_loss: 0.9821\n",
            "Epoch 19/200\n",
            "17/17 - 162s - 10s/step - accuracy: 0.4559 - loss: 1.1507 - val_accuracy: 0.5246 - val_loss: 0.9758\n",
            "Epoch 20/200\n",
            "17/17 - 195s - 11s/step - accuracy: 0.4522 - loss: 1.1175 - val_accuracy: 0.5410 - val_loss: 0.9686\n",
            "Epoch 21/200\n",
            "17/17 - 154s - 9s/step - accuracy: 0.4522 - loss: 1.1278 - val_accuracy: 0.5246 - val_loss: 0.9646\n",
            "Epoch 22/200\n",
            "17/17 - 150s - 9s/step - accuracy: 0.4706 - loss: 1.0897 - val_accuracy: 0.5246 - val_loss: 0.9634\n",
            "Epoch 23/200\n",
            "17/17 - 152s - 9s/step - accuracy: 0.4688 - loss: 1.1356 - val_accuracy: 0.5410 - val_loss: 0.9597\n",
            "Epoch 24/200\n",
            "17/17 - 157s - 9s/step - accuracy: 0.4577 - loss: 1.1357 - val_accuracy: 0.5410 - val_loss: 0.9577\n",
            "Epoch 25/200\n",
            "17/17 - 152s - 9s/step - accuracy: 0.4522 - loss: 1.1304 - val_accuracy: 0.5574 - val_loss: 0.9540\n",
            "Epoch 26/200\n",
            "17/17 - 151s - 9s/step - accuracy: 0.5147 - loss: 1.0815 - val_accuracy: 0.5574 - val_loss: 0.9500\n",
            "Epoch 27/200\n",
            "17/17 - 158s - 9s/step - accuracy: 0.5423 - loss: 1.0467 - val_accuracy: 0.5738 - val_loss: 0.9447\n",
            "Epoch 28/200\n",
            "17/17 - 151s - 9s/step - accuracy: 0.4853 - loss: 1.1171 - val_accuracy: 0.5738 - val_loss: 0.9424\n",
            "Epoch 29/200\n",
            "17/17 - 153s - 9s/step - accuracy: 0.4926 - loss: 1.0684 - val_accuracy: 0.5738 - val_loss: 0.9404\n",
            "Epoch 30/200\n",
            "17/17 - 199s - 12s/step - accuracy: 0.5110 - loss: 1.0625 - val_accuracy: 0.5902 - val_loss: 0.9383\n",
            "Epoch 31/200\n",
            "17/17 - 151s - 9s/step - accuracy: 0.4706 - loss: 1.0955 - val_accuracy: 0.5902 - val_loss: 0.9357\n",
            "Epoch 32/200\n",
            "17/17 - 152s - 9s/step - accuracy: 0.5018 - loss: 1.0616 - val_accuracy: 0.5902 - val_loss: 0.9338\n",
            "Epoch 33/200\n",
            "17/17 - 209s - 12s/step - accuracy: 0.5165 - loss: 1.0063 - val_accuracy: 0.6066 - val_loss: 0.9328\n",
            "Epoch 34/200\n",
            "17/17 - 151s - 9s/step - accuracy: 0.5257 - loss: 1.0134 - val_accuracy: 0.6230 - val_loss: 0.9306\n",
            "Epoch 35/200\n",
            "17/17 - 152s - 9s/step - accuracy: 0.5202 - loss: 1.0222 - val_accuracy: 0.6393 - val_loss: 0.9303\n",
            "Epoch 36/200\n",
            "17/17 - 150s - 9s/step - accuracy: 0.5294 - loss: 0.9897 - val_accuracy: 0.5902 - val_loss: 0.9314\n",
            "Epoch 37/200\n",
            "17/17 - 159s - 9s/step - accuracy: 0.5368 - loss: 1.0308 - val_accuracy: 0.5902 - val_loss: 0.9309\n",
            "Epoch 38/200\n",
            "17/17 - 149s - 9s/step - accuracy: 0.5202 - loss: 1.0231 - val_accuracy: 0.5738 - val_loss: 0.9303\n",
            "Epoch 39/200\n",
            "17/17 - 204s - 12s/step - accuracy: 0.5092 - loss: 1.0185 - val_accuracy: 0.5574 - val_loss: 0.9292\n",
            "Epoch 40/200\n",
            "17/17 - 155s - 9s/step - accuracy: 0.5147 - loss: 1.0301 - val_accuracy: 0.5574 - val_loss: 0.9296\n",
            "Epoch 41/200\n",
            "17/17 - 153s - 9s/step - accuracy: 0.5147 - loss: 1.0422 - val_accuracy: 0.5410 - val_loss: 0.9284\n",
            "Epoch 42/200\n",
            "17/17 - 151s - 9s/step - accuracy: 0.5184 - loss: 1.0368 - val_accuracy: 0.5574 - val_loss: 0.9265\n",
            "Epoch 43/200\n",
            "17/17 - 158s - 9s/step - accuracy: 0.5423 - loss: 0.9670 - val_accuracy: 0.5902 - val_loss: 0.9238\n",
            "Epoch 44/200\n",
            "17/17 - 152s - 9s/step - accuracy: 0.5110 - loss: 1.0308 - val_accuracy: 0.5902 - val_loss: 0.9226\n",
            "Epoch 45/200\n",
            "17/17 - 152s - 9s/step - accuracy: 0.5423 - loss: 1.0032 - val_accuracy: 0.6066 - val_loss: 0.9207\n",
            "Epoch 46/200\n",
            "17/17 - 203s - 12s/step - accuracy: 0.5478 - loss: 0.9952 - val_accuracy: 0.5902 - val_loss: 0.9183\n",
            "Epoch 47/200\n",
            "17/17 - 155s - 9s/step - accuracy: 0.5478 - loss: 0.9950 - val_accuracy: 0.5902 - val_loss: 0.9181\n",
            "Epoch 48/200\n",
            "17/17 - 151s - 9s/step - accuracy: 0.5294 - loss: 1.0231 - val_accuracy: 0.5902 - val_loss: 0.9169\n",
            "Epoch 49/200\n",
            "17/17 - 159s - 9s/step - accuracy: 0.5276 - loss: 1.0060 - val_accuracy: 0.5738 - val_loss: 0.9177\n",
            "Epoch 50/200\n",
            "17/17 - 151s - 9s/step - accuracy: 0.5055 - loss: 1.0092 - val_accuracy: 0.6066 - val_loss: 0.9173\n",
            "Epoch 51/200\n",
            "17/17 - 151s - 9s/step - accuracy: 0.5460 - loss: 0.9643 - val_accuracy: 0.6066 - val_loss: 0.9168\n",
            "Epoch 52/200\n",
            "17/17 - 155s - 9s/step - accuracy: 0.5147 - loss: 1.0079 - val_accuracy: 0.6230 - val_loss: 0.9140\n",
            "Epoch 53/200\n",
            "17/17 - 150s - 9s/step - accuracy: 0.5257 - loss: 0.9977 - val_accuracy: 0.6393 - val_loss: 0.9124\n",
            "Epoch 54/200\n",
            "17/17 - 154s - 9s/step - accuracy: 0.5496 - loss: 0.9919 - val_accuracy: 0.6393 - val_loss: 0.9105\n",
            "Epoch 55/200\n",
            "17/17 - 150s - 9s/step - accuracy: 0.5423 - loss: 0.9584 - val_accuracy: 0.6230 - val_loss: 0.9102\n",
            "Epoch 56/200\n",
            "17/17 - 153s - 9s/step - accuracy: 0.5625 - loss: 0.9655 - val_accuracy: 0.6393 - val_loss: 0.9081\n",
            "Epoch 57/200\n",
            "17/17 - 150s - 9s/step - accuracy: 0.5717 - loss: 0.9557 - val_accuracy: 0.6393 - val_loss: 0.9065\n",
            "Epoch 58/200\n",
            "17/17 - 153s - 9s/step - accuracy: 0.5588 - loss: 0.9692 - val_accuracy: 0.6393 - val_loss: 0.9065\n",
            "Epoch 59/200\n",
            "17/17 - 161s - 9s/step - accuracy: 0.5331 - loss: 0.9722 - val_accuracy: 0.6393 - val_loss: 0.9068\n",
            "Epoch 60/200\n",
            "17/17 - 155s - 9s/step - accuracy: 0.5570 - loss: 0.9844 - val_accuracy: 0.6393 - val_loss: 0.9046\n",
            "Epoch 61/200\n",
            "17/17 - 152s - 9s/step - accuracy: 0.5221 - loss: 0.9801 - val_accuracy: 0.6393 - val_loss: 0.9045\n",
            "Epoch 62/200\n",
            "17/17 - 155s - 9s/step - accuracy: 0.5239 - loss: 0.9868 - val_accuracy: 0.6230 - val_loss: 0.9058\n",
            "Epoch 63/200\n",
            "17/17 - 157s - 9s/step - accuracy: 0.5496 - loss: 0.9699 - val_accuracy: 0.6230 - val_loss: 0.9056\n",
            "Epoch 64/200\n",
            "17/17 - 198s - 12s/step - accuracy: 0.5846 - loss: 0.9597 - val_accuracy: 0.6393 - val_loss: 0.9060\n",
            "Epoch 65/200\n",
            "17/17 - 152s - 9s/step - accuracy: 0.5184 - loss: 0.9871 - val_accuracy: 0.6066 - val_loss: 0.9056\n",
            "Epoch 66/200\n",
            "17/17 - 152s - 9s/step - accuracy: 0.5625 - loss: 0.9629 - val_accuracy: 0.6230 - val_loss: 0.9047\n",
            "Epoch 67/200\n",
            "17/17 - 150s - 9s/step - accuracy: 0.5533 - loss: 0.9425 - val_accuracy: 0.6230 - val_loss: 0.9039\n",
            "Epoch 68/200\n",
            "17/17 - 153s - 9s/step - accuracy: 0.5221 - loss: 0.9862 - val_accuracy: 0.6230 - val_loss: 0.9031\n",
            "Epoch 69/200\n",
            "17/17 - 157s - 9s/step - accuracy: 0.5735 - loss: 0.9465 - val_accuracy: 0.6066 - val_loss: 0.9033\n",
            "Epoch 70/200\n",
            "17/17 - 151s - 9s/step - accuracy: 0.5570 - loss: 0.9586 - val_accuracy: 0.6066 - val_loss: 0.9033\n",
            "Epoch 71/200\n",
            "17/17 - 152s - 9s/step - accuracy: 0.5551 - loss: 0.9578 - val_accuracy: 0.6230 - val_loss: 0.9006\n",
            "Epoch 72/200\n",
            "17/17 - 206s - 12s/step - accuracy: 0.5699 - loss: 0.9221 - val_accuracy: 0.6230 - val_loss: 0.8978\n",
            "Epoch 73/200\n",
            "17/17 - 199s - 12s/step - accuracy: 0.5515 - loss: 0.9178 - val_accuracy: 0.6393 - val_loss: 0.8967\n",
            "Epoch 74/200\n",
            "17/17 - 153s - 9s/step - accuracy: 0.5588 - loss: 0.9765 - val_accuracy: 0.6393 - val_loss: 0.8963\n",
            "Epoch 75/200\n",
            "17/17 - 152s - 9s/step - accuracy: 0.5680 - loss: 0.9491 - val_accuracy: 0.6230 - val_loss: 0.8938\n",
            "Epoch 76/200\n",
            "17/17 - 203s - 12s/step - accuracy: 0.5515 - loss: 0.9203 - val_accuracy: 0.6393 - val_loss: 0.8912\n",
            "Epoch 77/200\n",
            "17/17 - 156s - 9s/step - accuracy: 0.5312 - loss: 0.9896 - val_accuracy: 0.6393 - val_loss: 0.8915\n",
            "Epoch 78/200\n",
            "17/17 - 153s - 9s/step - accuracy: 0.5386 - loss: 0.9595 - val_accuracy: 0.6230 - val_loss: 0.8921\n",
            "Epoch 79/200\n",
            "17/17 - 152s - 9s/step - accuracy: 0.5515 - loss: 0.9526 - val_accuracy: 0.6230 - val_loss: 0.8902\n",
            "Epoch 80/200\n",
            "17/17 - 151s - 9s/step - accuracy: 0.5919 - loss: 0.9171 - val_accuracy: 0.6230 - val_loss: 0.8874\n",
            "Epoch 81/200\n",
            "17/17 - 153s - 9s/step - accuracy: 0.5460 - loss: 0.9687 - val_accuracy: 0.6230 - val_loss: 0.8847\n",
            "Epoch 82/200\n",
            "17/17 - 155s - 9s/step - accuracy: 0.5515 - loss: 0.9582 - val_accuracy: 0.6393 - val_loss: 0.8829\n",
            "Epoch 83/200\n",
            "17/17 - 152s - 9s/step - accuracy: 0.5643 - loss: 0.9195 - val_accuracy: 0.6393 - val_loss: 0.8834\n",
            "Epoch 84/200\n",
            "17/17 - 151s - 9s/step - accuracy: 0.5919 - loss: 0.9279 - val_accuracy: 0.6393 - val_loss: 0.8802\n",
            "Epoch 85/200\n",
            "17/17 - 202s - 12s/step - accuracy: 0.5882 - loss: 0.9157 - val_accuracy: 0.6393 - val_loss: 0.8763\n",
            "Epoch 86/200\n",
            "17/17 - 203s - 12s/step - accuracy: 0.5864 - loss: 0.8943 - val_accuracy: 0.6393 - val_loss: 0.8753\n",
            "Epoch 87/200\n",
            "17/17 - 151s - 9s/step - accuracy: 0.5551 - loss: 0.9606 - val_accuracy: 0.6557 - val_loss: 0.8744\n",
            "Epoch 88/200\n",
            "17/17 - 159s - 9s/step - accuracy: 0.5662 - loss: 0.9483 - val_accuracy: 0.6557 - val_loss: 0.8735\n",
            "Epoch 89/200\n",
            "17/17 - 160s - 9s/step - accuracy: 0.5662 - loss: 0.8901 - val_accuracy: 0.6557 - val_loss: 0.8725\n",
            "Epoch 90/200\n",
            "17/17 - 152s - 9s/step - accuracy: 0.5680 - loss: 0.9212 - val_accuracy: 0.6721 - val_loss: 0.8695\n",
            "Epoch 91/200\n",
            "17/17 - 204s - 12s/step - accuracy: 0.6011 - loss: 0.8938 - val_accuracy: 0.6557 - val_loss: 0.8665\n",
            "Epoch 92/200\n",
            "17/17 - 206s - 12s/step - accuracy: 0.5919 - loss: 0.9118 - val_accuracy: 0.6557 - val_loss: 0.8636\n",
            "Epoch 93/200\n",
            "17/17 - 156s - 9s/step - accuracy: 0.5717 - loss: 0.8941 - val_accuracy: 0.6557 - val_loss: 0.8633\n",
            "Epoch 94/200\n",
            "17/17 - 153s - 9s/step - accuracy: 0.5368 - loss: 0.9502 - val_accuracy: 0.6721 - val_loss: 0.8634\n",
            "Epoch 95/200\n",
            "17/17 - 153s - 9s/step - accuracy: 0.5699 - loss: 0.9172 - val_accuracy: 0.6721 - val_loss: 0.8643\n",
            "Epoch 96/200\n",
            "17/17 - 152s - 9s/step - accuracy: 0.5735 - loss: 0.9325 - val_accuracy: 0.6721 - val_loss: 0.8646\n",
            "Epoch 97/200\n",
            "17/17 - 153s - 9s/step - accuracy: 0.5956 - loss: 0.9107 - val_accuracy: 0.6721 - val_loss: 0.8638\n",
            "Epoch 98/200\n",
            "17/17 - 150s - 9s/step - accuracy: 0.5754 - loss: 0.9162 - val_accuracy: 0.6721 - val_loss: 0.8606\n",
            "Epoch 99/200\n",
            "17/17 - 152s - 9s/step - accuracy: 0.5974 - loss: 0.9112 - val_accuracy: 0.6721 - val_loss: 0.8598\n",
            "Epoch 100/200\n",
            "17/17 - 153s - 9s/step - accuracy: 0.5938 - loss: 0.9005 - val_accuracy: 0.6721 - val_loss: 0.8584\n",
            "Epoch 101/200\n",
            "17/17 - 156s - 9s/step - accuracy: 0.5790 - loss: 0.9033 - val_accuracy: 0.6721 - val_loss: 0.8588\n",
            "Epoch 102/200\n",
            "17/17 - 153s - 9s/step - accuracy: 0.5846 - loss: 0.9168 - val_accuracy: 0.6721 - val_loss: 0.8567\n",
            "Epoch 103/200\n",
            "17/17 - 155s - 9s/step - accuracy: 0.5938 - loss: 0.9124 - val_accuracy: 0.6721 - val_loss: 0.8545\n",
            "Epoch 104/200\n",
            "17/17 - 159s - 9s/step - accuracy: 0.5680 - loss: 0.9129 - val_accuracy: 0.6721 - val_loss: 0.8543\n",
            "Epoch 105/200\n",
            "17/17 - 160s - 9s/step - accuracy: 0.6250 - loss: 0.8709 - val_accuracy: 0.6721 - val_loss: 0.8521\n",
            "Epoch 106/200\n",
            "17/17 - 155s - 9s/step - accuracy: 0.5864 - loss: 0.9109 - val_accuracy: 0.6721 - val_loss: 0.8514\n",
            "Epoch 107/200\n",
            "17/17 - 159s - 9s/step - accuracy: 0.6011 - loss: 0.8862 - val_accuracy: 0.6721 - val_loss: 0.8483\n",
            "Epoch 108/200\n",
            "17/17 - 153s - 9s/step - accuracy: 0.5901 - loss: 0.8861 - val_accuracy: 0.6721 - val_loss: 0.8473\n",
            "Epoch 109/200\n",
            "17/17 - 151s - 9s/step - accuracy: 0.5864 - loss: 0.9179 - val_accuracy: 0.6721 - val_loss: 0.8455\n",
            "Epoch 110/200\n",
            "17/17 - 153s - 9s/step - accuracy: 0.6140 - loss: 0.8913 - val_accuracy: 0.6721 - val_loss: 0.8452\n",
            "Epoch 111/200\n",
            "17/17 - 153s - 9s/step - accuracy: 0.6048 - loss: 0.9074 - val_accuracy: 0.6721 - val_loss: 0.8432\n",
            "Epoch 112/200\n",
            "17/17 - 205s - 12s/step - accuracy: 0.6011 - loss: 0.9155 - val_accuracy: 0.6557 - val_loss: 0.8420\n",
            "Epoch 113/200\n",
            "17/17 - 152s - 9s/step - accuracy: 0.5974 - loss: 0.8657 - val_accuracy: 0.6557 - val_loss: 0.8410\n",
            "Epoch 114/200\n",
            "17/17 - 151s - 9s/step - accuracy: 0.6011 - loss: 0.8803 - val_accuracy: 0.6557 - val_loss: 0.8403\n",
            "Epoch 115/200\n",
            "17/17 - 156s - 9s/step - accuracy: 0.5809 - loss: 0.8777 - val_accuracy: 0.6557 - val_loss: 0.8394\n",
            "Epoch 116/200\n",
            "17/17 - 196s - 12s/step - accuracy: 0.5588 - loss: 0.9170 - val_accuracy: 0.6557 - val_loss: 0.8401\n",
            "Epoch 117/200\n",
            "17/17 - 152s - 9s/step - accuracy: 0.5974 - loss: 0.8946 - val_accuracy: 0.6557 - val_loss: 0.8383\n",
            "Epoch 118/200\n",
            "17/17 - 152s - 9s/step - accuracy: 0.5901 - loss: 0.8767 - val_accuracy: 0.6557 - val_loss: 0.8372\n",
            "Epoch 119/200\n",
            "17/17 - 202s - 12s/step - accuracy: 0.6066 - loss: 0.8690 - val_accuracy: 0.6557 - val_loss: 0.8368\n",
            "Epoch 120/200\n",
            "17/17 - 159s - 9s/step - accuracy: 0.5754 - loss: 0.9308 - val_accuracy: 0.6557 - val_loss: 0.8386\n",
            "Epoch 121/200\n",
            "17/17 - 194s - 11s/step - accuracy: 0.6029 - loss: 0.8868 - val_accuracy: 0.6557 - val_loss: 0.8379\n",
            "Epoch 122/200\n",
            "17/17 - 153s - 9s/step - accuracy: 0.6195 - loss: 0.8856 - val_accuracy: 0.6557 - val_loss: 0.8370\n",
            "Epoch 123/200\n",
            "17/17 - 200s - 12s/step - accuracy: 0.5938 - loss: 0.8964 - val_accuracy: 0.6721 - val_loss: 0.8363\n",
            "Epoch 124/200\n",
            "17/17 - 150s - 9s/step - accuracy: 0.5846 - loss: 0.8849 - val_accuracy: 0.6721 - val_loss: 0.8369\n",
            "Epoch 125/200\n",
            "17/17 - 153s - 9s/step - accuracy: 0.5993 - loss: 0.8730 - val_accuracy: 0.6721 - val_loss: 0.8355\n",
            "Epoch 126/200\n",
            "17/17 - 153s - 9s/step - accuracy: 0.6176 - loss: 0.8610 - val_accuracy: 0.6557 - val_loss: 0.8313\n",
            "Epoch 127/200\n",
            "17/17 - 201s - 12s/step - accuracy: 0.6158 - loss: 0.8905 - val_accuracy: 0.6557 - val_loss: 0.8282\n",
            "Epoch 128/200\n",
            "17/17 - 207s - 12s/step - accuracy: 0.6103 - loss: 0.8658 - val_accuracy: 0.6393 - val_loss: 0.8276\n",
            "Epoch 129/200\n",
            "17/17 - 150s - 9s/step - accuracy: 0.5974 - loss: 0.8848 - val_accuracy: 0.6393 - val_loss: 0.8268\n",
            "Epoch 130/200\n",
            "17/17 - 151s - 9s/step - accuracy: 0.5754 - loss: 0.9082 - val_accuracy: 0.6557 - val_loss: 0.8242\n",
            "Epoch 131/200\n",
            "17/17 - 151s - 9s/step - accuracy: 0.6176 - loss: 0.8571 - val_accuracy: 0.6557 - val_loss: 0.8219\n",
            "Epoch 132/200\n",
            "17/17 - 155s - 9s/step - accuracy: 0.5974 - loss: 0.8734 - val_accuracy: 0.6557 - val_loss: 0.8223\n",
            "Epoch 133/200\n",
            "17/17 - 152s - 9s/step - accuracy: 0.6526 - loss: 0.8232 - val_accuracy: 0.6393 - val_loss: 0.8218\n",
            "Epoch 134/200\n",
            "17/17 - 156s - 9s/step - accuracy: 0.6195 - loss: 0.8690 - val_accuracy: 0.6393 - val_loss: 0.8253\n",
            "Epoch 135/200\n",
            "17/17 - 199s - 12s/step - accuracy: 0.6085 - loss: 0.8403 - val_accuracy: 0.6393 - val_loss: 0.8266\n",
            "Epoch 136/200\n",
            "17/17 - 152s - 9s/step - accuracy: 0.6250 - loss: 0.8504 - val_accuracy: 0.6393 - val_loss: 0.8264\n",
            "Epoch 137/200\n",
            "17/17 - 158s - 9s/step - accuracy: 0.5974 - loss: 0.8924 - val_accuracy: 0.6230 - val_loss: 0.8253\n",
            "Epoch 138/200\n",
            "17/17 - 153s - 9s/step - accuracy: 0.6324 - loss: 0.8679 - val_accuracy: 0.6557 - val_loss: 0.8220\n",
            "Epoch 139/200\n",
            "17/17 - 152s - 9s/step - accuracy: 0.6176 - loss: 0.8495 - val_accuracy: 0.6557 - val_loss: 0.8204\n",
            "Epoch 140/200\n",
            "17/17 - 155s - 9s/step - accuracy: 0.5699 - loss: 0.9115 - val_accuracy: 0.6557 - val_loss: 0.8193\n",
            "Epoch 141/200\n",
            "17/17 - 152s - 9s/step - accuracy: 0.6176 - loss: 0.8666 - val_accuracy: 0.6557 - val_loss: 0.8180\n",
            "Epoch 142/200\n",
            "17/17 - 157s - 9s/step - accuracy: 0.6195 - loss: 0.8408 - val_accuracy: 0.6557 - val_loss: 0.8151\n",
            "Epoch 143/200\n",
            "17/17 - 202s - 12s/step - accuracy: 0.6158 - loss: 0.8580 - val_accuracy: 0.6557 - val_loss: 0.8139\n",
            "Epoch 144/200\n",
            "17/17 - 152s - 9s/step - accuracy: 0.5938 - loss: 0.9066 - val_accuracy: 0.6557 - val_loss: 0.8125\n",
            "Epoch 145/200\n",
            "17/17 - 156s - 9s/step - accuracy: 0.6103 - loss: 0.8414 - val_accuracy: 0.6557 - val_loss: 0.8117\n",
            "Epoch 146/200\n",
            "17/17 - 150s - 9s/step - accuracy: 0.6379 - loss: 0.8263 - val_accuracy: 0.6557 - val_loss: 0.8093\n",
            "Epoch 147/200\n",
            "17/17 - 150s - 9s/step - accuracy: 0.5974 - loss: 0.8936 - val_accuracy: 0.6557 - val_loss: 0.8091\n",
            "Epoch 148/200\n",
            "17/17 - 151s - 9s/step - accuracy: 0.6250 - loss: 0.8463 - val_accuracy: 0.6557 - val_loss: 0.8070\n",
            "Epoch 149/200\n",
            "17/17 - 206s - 12s/step - accuracy: 0.6103 - loss: 0.8625 - val_accuracy: 0.6557 - val_loss: 0.8043\n",
            "Epoch 150/200\n",
            "17/17 - 157s - 9s/step - accuracy: 0.6471 - loss: 0.8452 - val_accuracy: 0.6557 - val_loss: 0.8040\n",
            "Epoch 151/200\n",
            "17/17 - 158s - 9s/step - accuracy: 0.6324 - loss: 0.8471 - val_accuracy: 0.6557 - val_loss: 0.8036\n",
            "Epoch 152/200\n",
            "17/17 - 153s - 9s/step - accuracy: 0.6250 - loss: 0.8280 - val_accuracy: 0.6557 - val_loss: 0.8026\n",
            "Epoch 153/200\n",
            "17/17 - 150s - 9s/step - accuracy: 0.6434 - loss: 0.8548 - val_accuracy: 0.6393 - val_loss: 0.8024\n",
            "Epoch 154/200\n",
            "17/17 - 152s - 9s/step - accuracy: 0.5974 - loss: 0.8768 - val_accuracy: 0.6393 - val_loss: 0.8034\n",
            "Epoch 155/200\n",
            "17/17 - 152s - 9s/step - accuracy: 0.6232 - loss: 0.8551 - val_accuracy: 0.6393 - val_loss: 0.8049\n",
            "Epoch 156/200\n",
            "17/17 - 152s - 9s/step - accuracy: 0.6213 - loss: 0.8635 - val_accuracy: 0.6393 - val_loss: 0.8058\n",
            "Epoch 157/200\n",
            "17/17 - 150s - 9s/step - accuracy: 0.6305 - loss: 0.8577 - val_accuracy: 0.6393 - val_loss: 0.8046\n",
            "Epoch 158/200\n",
            "17/17 - 203s - 12s/step - accuracy: 0.6324 - loss: 0.8547 - val_accuracy: 0.6393 - val_loss: 0.8029\n",
            "Epoch 159/200\n",
            "17/17 - 155s - 9s/step - accuracy: 0.6011 - loss: 0.8737 - val_accuracy: 0.6393 - val_loss: 0.8002\n",
            "Epoch 160/200\n",
            "17/17 - 152s - 9s/step - accuracy: 0.6140 - loss: 0.8394 - val_accuracy: 0.6393 - val_loss: 0.7967\n",
            "Epoch 161/200\n",
            "17/17 - 152s - 9s/step - accuracy: 0.6085 - loss: 0.8491 - val_accuracy: 0.6393 - val_loss: 0.7974\n",
            "Epoch 162/200\n",
            "17/17 - 152s - 9s/step - accuracy: 0.6085 - loss: 0.8714 - val_accuracy: 0.6393 - val_loss: 0.7972\n",
            "Epoch 163/200\n",
            "17/17 - 153s - 9s/step - accuracy: 0.6305 - loss: 0.8403 - val_accuracy: 0.6557 - val_loss: 0.7971\n",
            "Epoch 164/200\n",
            "17/17 - 150s - 9s/step - accuracy: 0.6011 - loss: 0.8792 - val_accuracy: 0.6557 - val_loss: 0.7969\n",
            "Epoch 165/200\n",
            "17/17 - 212s - 12s/step - accuracy: 0.6103 - loss: 0.8597 - val_accuracy: 0.6393 - val_loss: 0.7975\n",
            "Epoch 166/200\n",
            "17/17 - 149s - 9s/step - accuracy: 0.6140 - loss: 0.8309 - val_accuracy: 0.6393 - val_loss: 0.7970\n",
            "Epoch 167/200\n",
            "17/17 - 155s - 9s/step - accuracy: 0.6342 - loss: 0.8393 - val_accuracy: 0.6393 - val_loss: 0.7978\n",
            "Epoch 168/200\n",
            "17/17 - 151s - 9s/step - accuracy: 0.5827 - loss: 0.8460 - val_accuracy: 0.6393 - val_loss: 0.7958\n",
            "Epoch 169/200\n",
            "17/17 - 158s - 9s/step - accuracy: 0.5901 - loss: 0.8943 - val_accuracy: 0.6393 - val_loss: 0.7969\n",
            "Epoch 170/200\n",
            "17/17 - 161s - 9s/step - accuracy: 0.6213 - loss: 0.8397 - val_accuracy: 0.6393 - val_loss: 0.7960\n",
            "Epoch 171/200\n",
            "17/17 - 151s - 9s/step - accuracy: 0.6176 - loss: 0.8449 - val_accuracy: 0.6393 - val_loss: 0.7944\n",
            "Epoch 172/200\n",
            "17/17 - 149s - 9s/step - accuracy: 0.6581 - loss: 0.8119 - val_accuracy: 0.6230 - val_loss: 0.7921\n",
            "Epoch 173/200\n",
            "17/17 - 152s - 9s/step - accuracy: 0.6011 - loss: 0.8502 - val_accuracy: 0.6230 - val_loss: 0.7900\n",
            "Epoch 174/200\n",
            "17/17 - 156s - 9s/step - accuracy: 0.6379 - loss: 0.7970 - val_accuracy: 0.6393 - val_loss: 0.7889\n",
            "Epoch 175/200\n",
            "17/17 - 154s - 9s/step - accuracy: 0.6232 - loss: 0.8314 - val_accuracy: 0.6393 - val_loss: 0.7854\n",
            "Epoch 176/200\n",
            "17/17 - 152s - 9s/step - accuracy: 0.6379 - loss: 0.8304 - val_accuracy: 0.6393 - val_loss: 0.7825\n",
            "Epoch 177/200\n",
            "17/17 - 153s - 9s/step - accuracy: 0.6232 - loss: 0.8277 - val_accuracy: 0.6393 - val_loss: 0.7824\n",
            "Epoch 178/200\n",
            "17/17 - 152s - 9s/step - accuracy: 0.6342 - loss: 0.8334 - val_accuracy: 0.6557 - val_loss: 0.7809\n",
            "Epoch 179/200\n",
            "17/17 - 150s - 9s/step - accuracy: 0.6489 - loss: 0.8468 - val_accuracy: 0.6557 - val_loss: 0.7824\n",
            "Epoch 180/200\n",
            "17/17 - 149s - 9s/step - accuracy: 0.6232 - loss: 0.8304 - val_accuracy: 0.6557 - val_loss: 0.7816\n",
            "Epoch 181/200\n",
            "17/17 - 149s - 9s/step - accuracy: 0.6287 - loss: 0.8056 - val_accuracy: 0.6557 - val_loss: 0.7801\n",
            "Epoch 182/200\n",
            "17/17 - 154s - 9s/step - accuracy: 0.6507 - loss: 0.8275 - val_accuracy: 0.6557 - val_loss: 0.7779\n",
            "Epoch 183/200\n",
            "17/17 - 150s - 9s/step - accuracy: 0.6415 - loss: 0.8297 - val_accuracy: 0.6557 - val_loss: 0.7786\n",
            "Epoch 184/200\n",
            "17/17 - 151s - 9s/step - accuracy: 0.6213 - loss: 0.8290 - val_accuracy: 0.6557 - val_loss: 0.7769\n",
            "Epoch 185/200\n",
            "17/17 - 152s - 9s/step - accuracy: 0.6360 - loss: 0.8530 - val_accuracy: 0.6721 - val_loss: 0.7760\n",
            "Epoch 186/200\n",
            "17/17 - 157s - 9s/step - accuracy: 0.6434 - loss: 0.7972 - val_accuracy: 0.6557 - val_loss: 0.7753\n",
            "Epoch 187/200\n",
            "17/17 - 151s - 9s/step - accuracy: 0.6654 - loss: 0.8268 - val_accuracy: 0.6557 - val_loss: 0.7743\n",
            "Epoch 188/200\n",
            "17/17 - 150s - 9s/step - accuracy: 0.6452 - loss: 0.8015 - val_accuracy: 0.6557 - val_loss: 0.7739\n",
            "Epoch 189/200\n",
            "17/17 - 150s - 9s/step - accuracy: 0.6654 - loss: 0.7759 - val_accuracy: 0.6393 - val_loss: 0.7718\n",
            "Epoch 190/200\n",
            "17/17 - 150s - 9s/step - accuracy: 0.6452 - loss: 0.8017 - val_accuracy: 0.6393 - val_loss: 0.7714\n",
            "Epoch 191/200\n",
            "17/17 - 150s - 9s/step - accuracy: 0.6489 - loss: 0.8109 - val_accuracy: 0.6393 - val_loss: 0.7704\n",
            "Epoch 192/200\n",
            "17/17 - 151s - 9s/step - accuracy: 0.6342 - loss: 0.8106 - val_accuracy: 0.6393 - val_loss: 0.7720\n",
            "Epoch 193/200\n",
            "17/17 - 151s - 9s/step - accuracy: 0.6434 - loss: 0.8053 - val_accuracy: 0.6557 - val_loss: 0.7717\n",
            "Epoch 194/200\n",
            "17/17 - 149s - 9s/step - accuracy: 0.6489 - loss: 0.8008 - val_accuracy: 0.6393 - val_loss: 0.7700\n",
            "Epoch 195/200\n",
            "17/17 - 151s - 9s/step - accuracy: 0.6507 - loss: 0.7880 - val_accuracy: 0.6393 - val_loss: 0.7686\n",
            "Epoch 196/200\n",
            "17/17 - 151s - 9s/step - accuracy: 0.6213 - loss: 0.8555 - val_accuracy: 0.6557 - val_loss: 0.7679\n",
            "Epoch 197/200\n",
            "17/17 - 151s - 9s/step - accuracy: 0.6103 - loss: 0.8588 - val_accuracy: 0.6393 - val_loss: 0.7697\n",
            "Epoch 198/200\n",
            "17/17 - 149s - 9s/step - accuracy: 0.6452 - loss: 0.8121 - val_accuracy: 0.6393 - val_loss: 0.7676\n",
            "Epoch 199/200\n",
            "17/17 - 150s - 9s/step - accuracy: 0.6489 - loss: 0.8209 - val_accuracy: 0.6393 - val_loss: 0.7675\n",
            "Epoch 200/200\n",
            "17/17 - 208s - 12s/step - accuracy: 0.6397 - loss: 0.8092 - val_accuracy: 0.6393 - val_loss: 0.7692\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model berhasil disimpan: model_split90_lr0.0001_ep200_l20.0001.h5\n"
          ]
        }
      ],
      "source": [
        "split_ratio = 0.9\n",
        "split_percent = round(split_ratio * 100)\n",
        "\n",
        "for lr in [0.0001]:\n",
        "    for epoch in [200]:\n",
        "        print(f\"\\n📦 Training model dengan split_ratio={split_percent}%, learning_rate={lr}, epochs={epoch}\")\n",
        "\n",
        "        model, history = train_model(\n",
        "            split_ratio=split_ratio,\n",
        "            lr=lr,\n",
        "            epochs=epoch\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6963137-823f-491a-b3e7-d50ab835c071",
      "metadata": {
        "id": "a6963137-823f-491a-b3e7-d50ab835c071"
      },
      "source": [
        "# Fine tuning Transfer Learning model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "94a12451-615e-43c7-a6f5-4d2ffa85e7cd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94a12451-615e-43c7-a6f5-4d2ffa85e7cd",
        "outputId": "fc68d130-876c-4d17-e46c-567b54e70b9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 423 images belonging to 3 classes.\n",
            "Found 182 images belonging to 3 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 14s/step - accuracy: 0.3262 - loss: 1.3435 - val_accuracy: 0.3938 - val_loss: 1.1866\n",
            "Epoch 2/200\n",
            "\u001b[1m 1/13\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:53\u001b[0m 9s/step - accuracy: 0.5000 - loss: 0.9141"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3s/step - accuracy: 0.5000 - loss: 0.9141 - val_accuracy: 0.4187 - val_loss: 1.1616\n",
            "Epoch 3/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 16s/step - accuracy: 0.6563 - loss: 0.7749 - val_accuracy: 0.5875 - val_loss: 0.9684\n",
            "Epoch 4/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3s/step - accuracy: 0.6562 - loss: 0.7415 - val_accuracy: 0.5938 - val_loss: 0.9814\n",
            "Epoch 5/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 13s/step - accuracy: 0.8075 - loss: 0.5430 - val_accuracy: 0.5750 - val_loss: 0.9699\n",
            "Epoch 6/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 6s/step - accuracy: 0.8750 - loss: 0.4551 - val_accuracy: 0.5688 - val_loss: 0.9666\n",
            "Epoch 7/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 14s/step - accuracy: 0.8347 - loss: 0.4427 - val_accuracy: 0.6313 - val_loss: 0.8978\n",
            "Epoch 8/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 4s/step - accuracy: 0.8125 - loss: 0.4262 - val_accuracy: 0.6375 - val_loss: 0.8622\n",
            "Epoch 9/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 17s/step - accuracy: 0.8859 - loss: 0.3253 - val_accuracy: 0.6875 - val_loss: 0.8626\n",
            "Epoch 10/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 6s/step - accuracy: 0.9375 - loss: 0.2387 - val_accuracy: 0.6875 - val_loss: 0.8677\n",
            "Epoch 11/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 16s/step - accuracy: 0.8994 - loss: 0.3218 - val_accuracy: 0.7000 - val_loss: 0.8840\n",
            "Epoch 12/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 4s/step - accuracy: 1.0000 - loss: 0.2123 - val_accuracy: 0.7000 - val_loss: 0.8879\n",
            "Epoch 13/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 15s/step - accuracy: 0.9248 - loss: 0.2509 - val_accuracy: 0.7375 - val_loss: 0.7156\n",
            "Epoch 14/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 3s/step - accuracy: 0.9062 - loss: 0.2483 - val_accuracy: 0.7437 - val_loss: 0.7089\n",
            "Epoch 15/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 15s/step - accuracy: 0.9708 - loss: 0.1829 - val_accuracy: 0.7563 - val_loss: 0.6173\n",
            "Epoch 16/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3s/step - accuracy: 0.9688 - loss: 0.1206 - val_accuracy: 0.7625 - val_loss: 0.6106\n",
            "Epoch 17/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 15s/step - accuracy: 0.9728 - loss: 0.1761 - val_accuracy: 0.8000 - val_loss: 0.5400\n",
            "Epoch 18/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 3s/step - accuracy: 0.9375 - loss: 0.1744 - val_accuracy: 0.8000 - val_loss: 0.5324\n",
            "Epoch 19/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 16s/step - accuracy: 0.9676 - loss: 0.1458 - val_accuracy: 0.8000 - val_loss: 0.5150\n",
            "Epoch 20/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 3s/step - accuracy: 0.8750 - loss: 0.3281 - val_accuracy: 0.8062 - val_loss: 0.5140\n",
            "Epoch 21/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 16s/step - accuracy: 0.9223 - loss: 0.1870 - val_accuracy: 0.8125 - val_loss: 0.5382\n",
            "Epoch 22/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 7s/step - accuracy: 0.9688 - loss: 0.1079 - val_accuracy: 0.8125 - val_loss: 0.5258\n",
            "Epoch 23/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 13s/step - accuracy: 0.9733 - loss: 0.1219 - val_accuracy: 0.8313 - val_loss: 0.4684\n",
            "Epoch 24/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0751 - val_accuracy: 0.8313 - val_loss: 0.4661\n",
            "Epoch 25/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 16s/step - accuracy: 0.9629 - loss: 0.1494 - val_accuracy: 0.8188 - val_loss: 0.4337\n",
            "Epoch 26/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 3s/step - accuracy: 0.5714 - loss: 0.6668 - val_accuracy: 0.8125 - val_loss: 0.4364\n",
            "Epoch 27/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14s/step - accuracy: 0.9841 - loss: 0.0899 - val_accuracy: 0.8062 - val_loss: 0.4799\n",
            "Epoch 28/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 6s/step - accuracy: 0.9688 - loss: 0.1045 - val_accuracy: 0.8062 - val_loss: 0.4770\n",
            "Epoch 29/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 13s/step - accuracy: 0.9905 - loss: 0.0784 - val_accuracy: 0.8250 - val_loss: 0.4603\n",
            "Epoch 30/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0347 - val_accuracy: 0.8250 - val_loss: 0.4595\n",
            "Epoch 31/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 14s/step - accuracy: 0.9972 - loss: 0.0661 - val_accuracy: 0.8313 - val_loss: 0.4554\n",
            "Epoch 32/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0674 - val_accuracy: 0.8313 - val_loss: 0.4550\n",
            "Epoch 33/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 16s/step - accuracy: 0.9806 - loss: 0.0699 - val_accuracy: 0.8438 - val_loss: 0.4384\n",
            "Epoch 34/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0326 - val_accuracy: 0.8438 - val_loss: 0.4388\n",
            "Epoch 35/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 15s/step - accuracy: 0.9807 - loss: 0.0696 - val_accuracy: 0.8438 - val_loss: 0.4539\n",
            "Epoch 36/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0368 - val_accuracy: 0.8438 - val_loss: 0.4536\n",
            "Epoch 37/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 18s/step - accuracy: 0.9897 - loss: 0.0632 - val_accuracy: 0.8500 - val_loss: 0.4278\n",
            "Epoch 38/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3s/step - accuracy: 0.7143 - loss: 0.4228 - val_accuracy: 0.8500 - val_loss: 0.4237\n",
            "Epoch 39/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 16s/step - accuracy: 1.0000 - loss: 0.0422 - val_accuracy: 0.8500 - val_loss: 0.4367\n",
            "Epoch 40/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 6s/step - accuracy: 0.9375 - loss: 0.1096 - val_accuracy: 0.8500 - val_loss: 0.4309\n",
            "Epoch 41/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 17s/step - accuracy: 0.9981 - loss: 0.0354 - val_accuracy: 0.8375 - val_loss: 0.4167\n",
            "Epoch 42/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.1224 - val_accuracy: 0.8188 - val_loss: 0.4181\n",
            "Epoch 43/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 13s/step - accuracy: 0.9836 - loss: 0.0502 - val_accuracy: 0.8250 - val_loss: 0.4163\n",
            "Epoch 44/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.8250 - val_loss: 0.4075\n",
            "Epoch 45/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 13s/step - accuracy: 0.9971 - loss: 0.0383 - val_accuracy: 0.8375 - val_loss: 0.3952\n",
            "Epoch 46/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0206 - val_accuracy: 0.8375 - val_loss: 0.3955\n",
            "Epoch 47/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 13s/step - accuracy: 0.9960 - loss: 0.0343 - val_accuracy: 0.8438 - val_loss: 0.4151\n",
            "Epoch 48/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0467 - val_accuracy: 0.8438 - val_loss: 0.4165\n",
            "Epoch 49/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 15s/step - accuracy: 0.9976 - loss: 0.0307 - val_accuracy: 0.8375 - val_loss: 0.4311\n",
            "Epoch 50/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0837 - val_accuracy: 0.8375 - val_loss: 0.4338\n",
            "Epoch 51/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 0.0317 - val_accuracy: 0.7937 - val_loss: 0.4843\n",
            "Epoch 52/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0237 - val_accuracy: 0.8000 - val_loss: 0.4848\n",
            "Epoch 53/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 14s/step - accuracy: 0.9844 - loss: 0.0492 - val_accuracy: 0.8375 - val_loss: 0.4430\n",
            "Epoch 54/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0809 - val_accuracy: 0.8375 - val_loss: 0.4443\n",
            "Epoch 55/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 13s/step - accuracy: 0.9907 - loss: 0.0302 - val_accuracy: 0.8375 - val_loss: 0.4619\n",
            "Epoch 56/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0158 - val_accuracy: 0.8375 - val_loss: 0.4618\n",
            "Epoch 57/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 16s/step - accuracy: 1.0000 - loss: 0.0209 - val_accuracy: 0.8438 - val_loss: 0.4644\n",
            "Epoch 58/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0312 - val_accuracy: 0.8438 - val_loss: 0.4629\n",
            "Epoch 59/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 0.0200 - val_accuracy: 0.8438 - val_loss: 0.4753\n",
            "Epoch 60/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0443 - val_accuracy: 0.8500 - val_loss: 0.4759\n",
            "Epoch 61/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 13s/step - accuracy: 0.9964 - loss: 0.0179 - val_accuracy: 0.8562 - val_loss: 0.4818\n",
            "Epoch 62/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0203 - val_accuracy: 0.8562 - val_loss: 0.4811\n",
            "Epoch 63/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 0.0190 - val_accuracy: 0.8438 - val_loss: 0.4723\n",
            "Epoch 64/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0190 - val_accuracy: 0.8438 - val_loss: 0.4722\n",
            "Epoch 65/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 13s/step - accuracy: 0.9967 - loss: 0.0185 - val_accuracy: 0.8375 - val_loss: 0.4591\n",
            "Epoch 66/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0085 - val_accuracy: 0.8438 - val_loss: 0.4585\n",
            "Epoch 67/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 13s/step - accuracy: 0.9973 - loss: 0.0200 - val_accuracy: 0.8375 - val_loss: 0.4622\n",
            "Epoch 68/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0241 - val_accuracy: 0.8375 - val_loss: 0.4607\n",
            "Epoch 69/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 13s/step - accuracy: 1.0000 - loss: 0.0127 - val_accuracy: 0.8438 - val_loss: 0.4601\n",
            "Epoch 70/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0132 - val_accuracy: 0.8438 - val_loss: 0.4601\n",
            "Epoch 71/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 17s/step - accuracy: 0.9943 - loss: 0.0331 - val_accuracy: 0.8438 - val_loss: 0.4708\n",
            "Epoch 72/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0169 - val_accuracy: 0.8375 - val_loss: 0.4706\n",
            "Epoch 73/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 17s/step - accuracy: 0.9912 - loss: 0.0240 - val_accuracy: 0.8375 - val_loss: 0.4732\n",
            "Epoch 74/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.8375 - val_loss: 0.4727\n",
            "Epoch 75/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 16s/step - accuracy: 0.9990 - loss: 0.0144 - val_accuracy: 0.8313 - val_loss: 0.4914\n",
            "Epoch 76/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 0.8313 - val_loss: 0.4923\n",
            "Epoch 77/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 14s/step - accuracy: 1.0000 - loss: 0.0212 - val_accuracy: 0.8250 - val_loss: 0.4948\n",
            "Epoch 78/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0547 - val_accuracy: 0.8250 - val_loss: 0.4941\n",
            "Epoch 79/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 0.0138 - val_accuracy: 0.8313 - val_loss: 0.4786\n",
            "Epoch 80/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0082 - val_accuracy: 0.8313 - val_loss: 0.4788\n",
            "Epoch 81/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 16s/step - accuracy: 1.0000 - loss: 0.0165 - val_accuracy: 0.8313 - val_loss: 0.4768\n",
            "Epoch 82/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0144 - val_accuracy: 0.8313 - val_loss: 0.4777\n",
            "Epoch 83/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 14s/step - accuracy: 1.0000 - loss: 0.0097 - val_accuracy: 0.8313 - val_loss: 0.4819\n",
            "Epoch 84/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0101 - val_accuracy: 0.8375 - val_loss: 0.4839\n",
            "Epoch 85/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 16s/step - accuracy: 1.0000 - loss: 0.0112 - val_accuracy: 0.8375 - val_loss: 0.5100\n",
            "Epoch 86/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.8313 - val_loss: 0.5125\n",
            "Epoch 87/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 14s/step - accuracy: 0.9990 - loss: 0.0170 - val_accuracy: 0.8375 - val_loss: 0.4847\n",
            "Epoch 88/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0095 - val_accuracy: 0.8375 - val_loss: 0.4817\n",
            "Epoch 89/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 16s/step - accuracy: 1.0000 - loss: 0.0128 - val_accuracy: 0.8500 - val_loss: 0.4797\n",
            "Epoch 90/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 0.8500 - val_loss: 0.4800\n",
            "Epoch 91/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 16s/step - accuracy: 0.9996 - loss: 0.0065 - val_accuracy: 0.8500 - val_loss: 0.4933\n",
            "Epoch 92/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.8500 - val_loss: 0.4944\n",
            "Epoch 93/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 16s/step - accuracy: 0.9973 - loss: 0.0127 - val_accuracy: 0.8375 - val_loss: 0.5252\n",
            "Epoch 94/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0087 - val_accuracy: 0.8375 - val_loss: 0.5287\n",
            "Epoch 95/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 17s/step - accuracy: 1.0000 - loss: 0.0066 - val_accuracy: 0.8375 - val_loss: 0.5334\n",
            "Epoch 96/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.8375 - val_loss: 0.5317\n",
            "Epoch 97/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 16s/step - accuracy: 1.0000 - loss: 0.0100 - val_accuracy: 0.8313 - val_loss: 0.5115\n",
            "Epoch 98/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0100 - val_accuracy: 0.8313 - val_loss: 0.5105\n",
            "Epoch 99/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 16s/step - accuracy: 0.9941 - loss: 0.0118 - val_accuracy: 0.8313 - val_loss: 0.5162\n",
            "Epoch 100/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 0.8313 - val_loss: 0.5169\n",
            "Epoch 101/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 17s/step - accuracy: 0.9955 - loss: 0.0156 - val_accuracy: 0.8313 - val_loss: 0.5148\n",
            "Epoch 102/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0192 - val_accuracy: 0.8313 - val_loss: 0.5142\n",
            "Epoch 103/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 16s/step - accuracy: 1.0000 - loss: 0.0104 - val_accuracy: 0.8500 - val_loss: 0.4901\n",
            "Epoch 104/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.8500 - val_loss: 0.4868\n",
            "Epoch 105/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 0.0111 - val_accuracy: 0.8500 - val_loss: 0.4699\n",
            "Epoch 106/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0105 - val_accuracy: 0.8500 - val_loss: 0.4695\n",
            "Epoch 107/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 13s/step - accuracy: 1.0000 - loss: 0.0113 - val_accuracy: 0.8375 - val_loss: 0.4916\n",
            "Epoch 108/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.8375 - val_loss: 0.4961\n",
            "Epoch 109/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 17s/step - accuracy: 1.0000 - loss: 0.0126 - val_accuracy: 0.8313 - val_loss: 0.5647\n",
            "Epoch 110/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.8313 - val_loss: 0.5652\n",
            "Epoch 111/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 0.8250 - val_loss: 0.5976\n",
            "Epoch 112/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0226 - val_accuracy: 0.8250 - val_loss: 0.5875\n",
            "Epoch 113/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 13s/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 0.8250 - val_loss: 0.6380\n",
            "Epoch 114/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0217 - val_accuracy: 0.8250 - val_loss: 0.6458\n",
            "Epoch 115/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 15s/step - accuracy: 0.9975 - loss: 0.0083 - val_accuracy: 0.8313 - val_loss: 0.6631\n",
            "Epoch 116/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0238 - val_accuracy: 0.8313 - val_loss: 0.6580\n",
            "Epoch 117/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 16s/step - accuracy: 0.9984 - loss: 0.0124 - val_accuracy: 0.8250 - val_loss: 0.5582\n",
            "Epoch 118/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0096 - val_accuracy: 0.8250 - val_loss: 0.5557\n",
            "Epoch 119/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 17s/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 0.8375 - val_loss: 0.5200\n",
            "Epoch 120/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.8375 - val_loss: 0.5199\n",
            "Epoch 121/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 16s/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 0.8438 - val_loss: 0.5385\n",
            "Epoch 122/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.8375 - val_loss: 0.5390\n",
            "Epoch 123/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 0.0084 - val_accuracy: 0.8375 - val_loss: 0.5514\n",
            "Epoch 124/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.8375 - val_loss: 0.5517\n",
            "Epoch 125/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 13s/step - accuracy: 1.0000 - loss: 0.0119 - val_accuracy: 0.8500 - val_loss: 0.5320\n",
            "Epoch 126/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.8500 - val_loss: 0.5304\n",
            "Epoch 127/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 16s/step - accuracy: 0.9992 - loss: 0.0082 - val_accuracy: 0.8500 - val_loss: 0.5058\n",
            "Epoch 128/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.8500 - val_loss: 0.5055\n",
            "Epoch 129/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 15s/step - accuracy: 0.9909 - loss: 0.0129 - val_accuracy: 0.8500 - val_loss: 0.5403\n",
            "Epoch 130/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.8500 - val_loss: 0.5451\n",
            "Epoch 131/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 13s/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.8500 - val_loss: 0.5778\n",
            "Epoch 132/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.8500 - val_loss: 0.5791\n",
            "Epoch 133/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 16s/step - accuracy: 1.0000 - loss: 0.0102 - val_accuracy: 0.8500 - val_loss: 0.6033\n",
            "Epoch 134/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.8500 - val_loss: 0.6022\n",
            "Epoch 135/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 13s/step - accuracy: 1.0000 - loss: 0.0085 - val_accuracy: 0.8438 - val_loss: 0.5876\n",
            "Epoch 136/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.8438 - val_loss: 0.5858\n",
            "Epoch 137/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 14s/step - accuracy: 0.9833 - loss: 0.0208 - val_accuracy: 0.8375 - val_loss: 0.6126\n",
            "Epoch 138/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.8375 - val_loss: 0.6116\n",
            "Epoch 139/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 17s/step - accuracy: 0.9976 - loss: 0.0101 - val_accuracy: 0.8438 - val_loss: 0.5593\n",
            "Epoch 140/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.8438 - val_loss: 0.5565\n",
            "Epoch 141/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 16s/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 0.8500 - val_loss: 0.5247\n",
            "Epoch 142/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 6s/step - accuracy: 0.9688 - loss: 0.0404 - val_accuracy: 0.8500 - val_loss: 0.5213\n",
            "Epoch 143/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 13s/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.8438 - val_loss: 0.5205\n",
            "Epoch 144/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.8438 - val_loss: 0.5222\n",
            "Epoch 145/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 13s/step - accuracy: 0.9996 - loss: 0.0062 - val_accuracy: 0.8313 - val_loss: 0.5324\n",
            "Epoch 146/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.8313 - val_loss: 0.5347\n",
            "Epoch 147/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.8188 - val_loss: 0.5716\n",
            "Epoch 148/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.8188 - val_loss: 0.5713\n",
            "Epoch 149/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 13s/step - accuracy: 0.9987 - loss: 0.0063 - val_accuracy: 0.8375 - val_loss: 0.5334\n",
            "Epoch 150/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.8375 - val_loss: 0.5318\n",
            "Epoch 151/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 16s/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.8375 - val_loss: 0.5149\n",
            "Epoch 152/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.8375 - val_loss: 0.5150\n",
            "Epoch 153/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 14s/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.8375 - val_loss: 0.5374\n",
            "Epoch 154/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0107 - val_accuracy: 0.8375 - val_loss: 0.5384\n",
            "Epoch 155/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 13s/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 0.8375 - val_loss: 0.5253\n",
            "Epoch 156/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.8375 - val_loss: 0.5179\n",
            "Epoch 157/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 16s/step - accuracy: 0.9980 - loss: 0.0049 - val_accuracy: 0.8625 - val_loss: 0.5182\n",
            "Epoch 158/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0217 - val_accuracy: 0.8687 - val_loss: 0.5257\n",
            "Epoch 159/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.8625 - val_loss: 0.5712\n",
            "Epoch 160/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.8625 - val_loss: 0.5712\n",
            "Epoch 161/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 17s/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.8625 - val_loss: 0.5723\n",
            "Epoch 162/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.8625 - val_loss: 0.5733\n",
            "Epoch 163/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 16s/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.8687 - val_loss: 0.5415\n",
            "Epoch 164/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.8687 - val_loss: 0.5412\n",
            "Epoch 165/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 18s/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.8625 - val_loss: 0.5364\n",
            "Epoch 166/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.8625 - val_loss: 0.5370\n",
            "Epoch 167/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 14s/step - accuracy: 1.0000 - loss: 0.0247 - val_accuracy: 0.8687 - val_loss: 0.5542\n",
            "Epoch 168/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.8687 - val_loss: 0.5547\n",
            "Epoch 169/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 17s/step - accuracy: 0.9959 - loss: 0.0098 - val_accuracy: 0.8687 - val_loss: 0.5358\n",
            "Epoch 170/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.8687 - val_loss: 0.5337\n",
            "Epoch 171/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 14s/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.8687 - val_loss: 0.5384\n",
            "Epoch 172/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.8687 - val_loss: 0.5397\n",
            "Epoch 173/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 16s/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.8625 - val_loss: 0.5504\n",
            "Epoch 174/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 0.8625 - val_loss: 0.5505\n",
            "Epoch 175/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 14s/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.8625 - val_loss: 0.5449\n",
            "Epoch 176/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.8625 - val_loss: 0.5453\n",
            "Epoch 177/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 16s/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.8625 - val_loss: 0.5471\n",
            "Epoch 178/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.8625 - val_loss: 0.5483\n",
            "Epoch 179/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 14s/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.8562 - val_loss: 0.5487\n",
            "Epoch 180/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0247 - val_accuracy: 0.8562 - val_loss: 0.5491\n",
            "Epoch 181/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 15s/step - accuracy: 0.9990 - loss: 0.0082 - val_accuracy: 0.8687 - val_loss: 0.6431\n",
            "Epoch 182/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.8625 - val_loss: 0.6564\n",
            "Epoch 183/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 13s/step - accuracy: 0.9949 - loss: 0.0110 - val_accuracy: 0.8625 - val_loss: 0.6695\n",
            "Epoch 184/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.8625 - val_loss: 0.6659\n",
            "Epoch 185/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 16s/step - accuracy: 0.9982 - loss: 0.0154 - val_accuracy: 0.8687 - val_loss: 0.5931\n",
            "Epoch 186/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.8687 - val_loss: 0.5892\n",
            "Epoch 187/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 17s/step - accuracy: 0.9927 - loss: 0.0116 - val_accuracy: 0.8625 - val_loss: 0.5381\n",
            "Epoch 188/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3s/step - accuracy: 0.9688 - loss: 0.0512 - val_accuracy: 0.8625 - val_loss: 0.5319\n",
            "Epoch 189/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 13s/step - accuracy: 1.0000 - loss: 0.0085 - val_accuracy: 0.8500 - val_loss: 0.5739\n",
            "Epoch 190/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.8438 - val_loss: 0.5768\n",
            "Epoch 191/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 17s/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.8562 - val_loss: 0.5995\n",
            "Epoch 192/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0205 - val_accuracy: 0.8562 - val_loss: 0.5990\n",
            "Epoch 193/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 16s/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.8500 - val_loss: 0.6112\n",
            "Epoch 194/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0097 - val_accuracy: 0.8562 - val_loss: 0.6107\n",
            "Epoch 195/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.8438 - val_loss: 0.5923\n",
            "Epoch 196/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.8438 - val_loss: 0.5904\n",
            "Epoch 197/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 13s/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.8375 - val_loss: 0.5559\n",
            "Epoch 198/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.8375 - val_loss: 0.5512\n",
            "Epoch 199/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 15s/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 0.8500 - val_loss: 0.5572\n",
            "Epoch 200/200\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.8562 - val_loss: 0.5607\n",
            "✅ Model disimpan sebagai resnet_split70_sgd_lr0.001_ep200.keras\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "# Parameter\n",
        "IMAGE_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 200\n",
        "split_ratio = 0.7\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Dataset path (70:30 split)\n",
        "base_dir = f'/content/split_dataset_{int(split_ratio*100)}'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "val_dir = os.path.join(base_dir, 'val')\n",
        "\n",
        "# Data generator\n",
        "train_generator = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ").flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input\n",
        ").flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Model ResNet50\n",
        "def get_model():\n",
        "    base_model = tf.keras.applications.ResNet50(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)\n",
        "    )\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "    output = tf.keras.layers.Dense(train_generator.num_classes, activation='softmax')(x)\n",
        "    model = tf.keras.Model(inputs=base_model.input, outputs=output)\n",
        "    return model\n",
        "\n",
        "# Build model\n",
        "model = get_model()\n",
        "\n",
        "# Fine-tuning mulai layer ke-140\n",
        "split_at = 140\n",
        "for layer in model.layers[:split_at]:\n",
        "    layer.trainable = False\n",
        "for layer in model.layers[split_at:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Optimizer SGD dengan lr=0.001\n",
        "sgd = optimizers.SGD(learning_rate=learning_rate, momentum=0.9, nesterov=True)\n",
        "\n",
        "# Compile model\n",
        "model.compile(\n",
        "    optimizer=sgd,\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Training\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.n // BATCH_SIZE,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=val_generator.n // BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Simpan model dengan nama tetap (tanpa mapping tabel)\n",
        "filename = \"resnet_split70_sgd_lr0.001_ep200.keras\"\n",
        "model.save(filename)\n",
        "print(f\"✅ Model disimpan sebagai {filename}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "403d8194-f896-4a2a-b448-3fc6a0967e06",
      "metadata": {
        "id": "403d8194-f896-4a2a-b448-3fc6a0967e06"
      },
      "source": [
        "# Save the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "925439b5-9e3a-4959-9987-129411286d13",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "925439b5-9e3a-4959-9987-129411286d13",
        "outputId": "b325025b-f3e1-497a-c004-3975ef610e9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model disimpan sebagai resnet_split70_lr0.001_ep200.keras\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_cf3112ae-b218-4f9a-ac2d-9701c3183ba5\", \"resnet_split70_lr0.001_ep200.keras\", 154978210)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Simpan model tanpa training ulang\n",
        "filename = f'resnet_split70_lr0.001_ep200.keras'\n",
        "model.save(filename)\n",
        "print(f\"✅ Model disimpan sebagai {filename}\")\n",
        "\n",
        "# Kalau di Google Colab, bisa diunduh langsung:\n",
        "from google.colab import files\n",
        "files.download(filename)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "AqaLJdmb6l5d"
      },
      "id": "AqaLJdmb6l5d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "1a121c8f-859c-4ed7-9ead-4ef3eff26c68",
      "metadata": {
        "id": "1a121c8f-859c-4ed7-9ead-4ef3eff26c68"
      },
      "source": [
        "# Evaluate Model to Get Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "46426fff-90c8-4e1b-9662-ea2f6e928a25",
      "metadata": {
        "id": "46426fff-90c8-4e1b-9662-ea2f6e928a25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2f92339-74ff-4b40-ccfa-0fbc5cdb790b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 7s/step - accuracy: 1.0000 - loss: 0.0010\n",
            "Test Loss: 0.0010\n",
            "Test Accuracy: 100.00%\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_accuracy = model.evaluate(\n",
        "    train_generator,\n",
        "    steps=train_generator.n // BATCH_SIZE,\n",
        "    verbose=1\n",
        ")\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f13c9abd-9571-4f98-a561-df30075e1acf",
      "metadata": {
        "id": "f13c9abd-9571-4f98-a561-df30075e1acf"
      },
      "source": [
        "# Create confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "2f56cfbb-8e10-40c1-8585-11cae30cdf8e",
      "metadata": {
        "id": "2f56cfbb-8e10-40c1-8585-11cae30cdf8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "outputId": "98d7efb1-2891-487a-b39c-83acfc6afd8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 7s/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Prediksi probabilitas untuk semua data di train_generator\n",
        "predictions = model.predict(\n",
        "    train_generator,\n",
        "    steps=train_generator.n // BATCH_SIZE + 1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Ambil kelas prediksi dengan nilai probabilitas tertinggi\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Label asli dari generator\n",
        "true_classes = train_generator.classes\n",
        "class_labels = list(train_generator.class_indices.keys())\n",
        "\n",
        "# Hitung confusion matrix\n",
        "cm = confusion_matrix(true_classes, predicted_classes)\n",
        "\n",
        "# Tampilkan confusion matrix dengan label kelas\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xticks(rotation=90, ha='right')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "# Hitung jumlah data per kelas (label asli dan prediksi)\n",
        "true_counts = np.bincount(true_classes, minlength=len(class_labels))\n",
        "pred_counts = np.bincount(predicted_classes, minlength=len(class_labels))\n",
        "\n",
        "# === 1. Grafik Batang: Jumlah Prediksi Benar/Salah per Kelas ===\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(x=class_labels, y=np.diag(cm))  # nilai diagonal CM = prediksi benar\n",
        "plt.title(\"Jumlah Prediksi Benar per Kelas\")\n",
        "plt.ylabel(\"Jumlah Benar\")\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()\n",
        "\n",
        "# === 2. Grafik Garis: Perbandingan Label Asli vs Prediksi per Kelas ===\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(class_labels, true_counts, marker='o', label=\"Label Asli\")\n",
        "plt.plot(class_labels, pred_counts, marker='s', label=\"Prediksi\")\n",
        "plt.title(\"Perbandingan Jumlah Label Asli vs Prediksi per Kelas\")\n",
        "plt.ylabel(\"Jumlah Data\")\n",
        "plt.xticks(rotation=90)\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "S0z2foFEzqw1",
        "outputId": "d7351c19-c34c-4528-bb19-b6e14fa59a2c"
      },
      "id": "S0z2foFEzqw1",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32043433-7450-4394-86da-863d2c0c9702",
      "metadata": {
        "id": "32043433-7450-4394-86da-863d2c0c9702"
      },
      "source": [
        "# Plotting Model Accuracy and Loss:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "3760be3e-4649-45b7-bb0e-222177ffac25",
      "metadata": {
        "id": "3760be3e-4649-45b7-bb0e-222177ffac25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "58d2bd02-e0dc-4d32-d920-1d4a1b437fe9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Misal hasil evaluasi model\n",
        "metrics = ['Test Loss', 'Test Accuracy']\n",
        "values = [test_loss, test_accuracy]  # pastikan test_loss dan test_accuracy sudah di-set dari model.evaluate()\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(metrics, values, color=['red', 'green'])\n",
        "plt.ylim(0, 1)  # range 0 sampai 1 karena accuracy dan loss biasanya di sini\n",
        "plt.title('Model Evaluation Metrics')\n",
        "plt.ylabel('Value')\n",
        "plt.xlabel('Metrics')\n",
        "plt.grid(axis='y')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "449f3087-2e24-4e18-875e-7d3a71993501",
      "metadata": {
        "id": "449f3087-2e24-4e18-875e-7d3a71993501"
      },
      "source": [
        "# Visualize Test Loss and Accuracy Using Line Graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "eae67acd-9640-4f32-a977-f450ed38b192",
      "metadata": {
        "id": "eae67acd-9640-4f32-a977-f450ed38b192",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "outputId": "e8f7ef39-f175-4171-b47b-2d41344a5854"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA9wAAAHqCAYAAAD27EaEAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAewpJREFUeJzt3Xd4FNXbxvF7E1IJCSVACC30oghIExABpYQqvUvHAkiJBbFQVVSkKWJBmlJCR0qIFEUQUFFERRHpKBI6BAgkIZn3j3nZn0sSSJ9s8v1cVy5mz055dhPm2WfnzDk2wzAMAQAAAACAdOVidQAAAAAAAGRHFNwAAAAAAGQACm4AAAAAADIABTcAAAAAABmAghsAAAAAgAxAwQ0AAAAAQAag4AYAAAAAIANQcAMAAAAAkAEouAEAAAAAyAAU3ABSLCgoSH379rU6DABANmSz2TRu3LgUb3f8+HHZbDbNnz8/3WNKL1bmT2d4fzJb3759FRQUZHUYyOYouJEl2Gy2ZP1s27YtzceKiorSuHHjkr2vbdu2yWazacWKFWk+dk51+fJleXp6ymaz6cCBA1aHAwC4h/nz59tz77fffpvgecMwVLx4cdlsNrVu3dqCCFPvdl5P6ic0NNTqENNk8eLFmj59utVhOOjbt69sNpt8fX1148aNBM8fOnTI/v6/++67Kd5/Sj/bAZkpl9UBAJL0+eefOzz+7LPPtHnz5gTtlSpVSvOxoqKiNH78eElSo0aN0rw/3Nvy5ctls9kUEBCgRYsW6fXXX7c6JABAMnh6emrx4sV6+OGHHdq/+eYb/fPPP/Lw8LAosrQbNmyYatWqlaC9bt26FkSTfhYvXqz9+/drxIgRDu0lS5bUjRs35ObmZklcuXLlUlRUlNatW6cuXbo4PLdo0SJ5enrq5s2bqdp3aj/bzZ49W/Hx8ak6JpBcFNzIEnr16uXw+LvvvtPmzZsTtMM5LVy4UC1btlTJkiW1ePHiLFtw37x5U+7u7nJxofMPAEhSy5YttXz5cr333nvKlet/HxsXL16sGjVq6Pz58xZGlzYNGjRQp06drA4j09hsNnl6elp2fA8PD9WvX19LlixJUHAvXrxYrVq10sqVKzMlluvXryt37tyWffmAnIVPlXAa8fHxmj59uu677z55enqqcOHCeuqpp3Tp0iWH9X788Uc1b95c/v7+8vLyUqlSpdS/f39J5v1LBQsWlCSNHz/e3n0pNfeK3eno0aPq3Lmz8ufPL29vbz300EPasGFDgvXef/993XffffL29la+fPlUs2ZNLV682P781atXNWLECAUFBcnDw0OFChVS06ZNtXfv3rse/8SJExo8eLAqVKggLy8vFShQQJ07d9bx48cd1rvdTXDnzp0KCQlRwYIFlTt3brVv317nzp1zWNcwDL3++usqVqyYvL291bhxY/3+++8pel9OnjypHTt2qFu3burWrZuOHTumXbt2JbruwoULVbt2bft788gjj2jTpk0O62zcuFENGzZUnjx55Ovrq1q1ajm8f0ndH9eoUSOHb71vdykMDQ3Vq6++qqJFi8rb21uRkZG6ePGinn/+eVWpUkU+Pj7y9fVVixYt9MsvvyTY782bNzVu3DiVL19enp6eKlKkiDp06KAjR47IMAwFBQXp8ccfT3Q7Pz8/PfXUU8l8JwEg83Xv3l0XLlzQ5s2b7W0xMTFasWKFevTokeg2169f13PPPafixYvLw8NDFSpU0LvvvivDMBzWi46O1siRI1WwYEHlyZNHbdu21T///JPoPk+dOqX+/furcOHC8vDw0H333ae5c+em3wtNxP3336/GjRsnaI+Pj1fRokUdivV3331X9erVU4ECBeTl5aUaNWok61a0cePGyWazJWi/nav/m8O/+OILtWrVSoGBgfLw8FCZMmU0ceJExcXF2ddp1KiRNmzYoBMnTtg/49y+Rzmpe7i/+uorNWjQQLlz51bevHn1+OOPJ7j963achw8fVt++fZU3b175+fmpX79+ioqKuufrvK1Hjx7auHGjLl++bG/bs2ePDh06lOTf0+XLlzVixAj731PZsmX19ttv269M3+uzXd++feXj46MjR46oZcuWypMnj3r27Gl/7s57uOPj4zVjxgxVqVJFnp6eKliwoIKDg/Xjjz/a19m8ebMefvhh5c2bVz4+PqpQoYJefvnlZL8PyFm4wg2n8dRTT2n+/Pnq16+fhg0bpmPHjmnmzJn6+eeftXPnTrm5uens2bNq1qyZChYsqJdeekl58+bV8ePHtWrVKklSwYIF9eGHH+qZZ55R+/bt1aFDB0nSAw88kKbYzpw5o3r16ikqKkrDhg1TgQIFtGDBArVt21YrVqxQ+/btJZldl4YNG6ZOnTpp+PDhunnzpn799Vd9//339kTz9NNPa8WKFRo6dKgqV66sCxcu6Ntvv9WBAwf04IMPJhnDnj17tGvXLnXr1k3FihXT8ePH9eGHH6pRo0b6448/5O3t7bD+s88+q3z58mns2LE6fvy4pk+frqFDh2rp0qX2dcaMGaPXX39dLVu2VMuWLbV37141a9ZMMTExyX5vlixZoty5c6t169by8vJSmTJltGjRItWrV89hvfHjx2vcuHGqV6+eJkyYIHd3d33//ff66quv1KxZM0nmB5D+/fvrvvvu0+jRo5U3b179/PPPCg8PTzJR38vEiRPl7u6u559/XtHR0XJ3d9cff/yhNWvWqHPnzipVqpTOnDmjjz/+WA0bNtQff/yhwMBASVJcXJxat26trVu3qlu3bho+fLiuXr2qzZs3a//+/SpTpox69eqld955RxcvXlT+/Pntx123bp0iIyPpxQEgSwsKClLdunW1ZMkStWjRQpL5xeeVK1fUrVs3vffeew7rG4ahtm3b6uuvv9aAAQNUrVo1ffnll3rhhRd06tQpTZs2zb7uwIEDtXDhQvXo0UP16tXTV199pVatWiWI4cyZM3rooYdks9k0dOhQFSxYUBs3btSAAQMUGRmZoOt0cl29ejXRK/QFChSQzWZT165dNW7cOEVERCggIMD+/Lfffqt///1X3bp1s7fNmDFDbdu2Vc+ePRUTE6PQ0FB17txZ69evT/Q1pcb8+fPl4+OjkJAQ+fj46KuvvtKYMWMUGRmpyZMnS5JeeeUVXblyRf/884/9vfbx8Ulyn1u2bFGLFi1UunRpjRs3Tjdu3ND777+v+vXra+/evQmK0S5duqhUqVKaNGmS9u7dq08//VSFChXS22+/nazX0KFDBz399NNatWqV/WLI4sWLVbFixUQ/40RFRalhw4Y6deqUnnrqKZUoUUK7du3S6NGjdfr0aU2fPj1Zn+1u3bql5s2b6+GHH9a7776b4DPRfw0YMEDz589XixYtNHDgQN26dUs7duzQd999p5o1a+r3339X69at9cADD2jChAny8PDQ4cOHtXPnzmS9B8iBDCALGjJkiPHfP88dO3YYkoxFixY5rBceHu7Qvnr1akOSsWfPniT3fe7cOUOSMXbs2GTF8vXXXxuSjOXLlye5zogRIwxJxo4dO+xtV69eNUqVKmUEBQUZcXFxhmEYxuOPP27cd999dz2en5+fMWTIkGTF9l9RUVEJ2nbv3m1IMj777DN727x58wxJRpMmTYz4+Hh7+8iRIw1XV1fj8uXLhmEYxtmzZw13d3ejVatWDuu9/PLLhiSjT58+yYqrSpUqRs+ePR229/f3N2JjY+1thw4dMlxcXIz27dvb36vbbh/78uXLRp48eYw6deoYN27cSHQdwzCMkiVLJhpbw4YNjYYNG9of3/69li5dOsF7d/PmzQRxHDt2zPDw8DAmTJhgb5s7d64hyZg6dWqC492O6eDBg4Yk48MPP3R4vm3btkZQUJBD7ACQVdzOFXv27DFmzpxp5MmTx36u7Ny5s9G4cWPDMMxzbqtWrezbrVmzxpBkvP766w7769Spk2Gz2YzDhw8bhmEY+/btMyQZgwcPdlivR48eCXL0gAEDjCJFihjnz593WLdbt26Gn5+fPa5jx44Zkox58+bd9bXdPv8n9XP69GnDMP53/n7//fcdth88eLDh4+PjkDvuzCMxMTHG/fffbzz66KMO7XfmqLFjxxqJfRy//f4fO3YsyWMYhmE89dRThre3t3Hz5k17W6tWrYySJUsmWDex96datWpGoUKFjAsXLtjbfvnlF8PFxcXo3bt3gjj79+/vsM/27dsbBQoUSHCsO/Xp08fInTu3YRjm38Jjjz1mGIZhxMXFGQEBAcb48ePt8U2ePNm+3cSJE43cuXMbf/31l8P+XnrpJcPV1dU4efKkYRh3/2zXp08fQ5Lx0ksvJfrcf9+rr776ypBkDBs2LMG6t/P1tGnTDEnGuXPn7vm6AcMwDLqUwyksX75cfn5+atq0qc6fP2//qVGjhnx8fPT1119LkvLmzStJWr9+vWJjYzMtvrCwMNWuXdthUBkfHx89+eSTOn78uP744w97fP/884/27NmT5L7y5s2r77//Xv/++2+KYvDy8rIvx8bG6sKFCypbtqzy5s2baHf0J5980qEbW4MGDRQXF6cTJ05IMr/1jomJ0bPPPuuwXkquJPz666/67bff1L17d3tb9+7ddf78eX355Zf2tjVr1ig+Pl5jxoxJcP/07WNv3rxZV69e1UsvvZTgHrTEuuMlV58+fRzeO8m8z+x2HHFxcbpw4YK9y9h/38uVK1fK399fzz77bIL93o6pfPnyqlOnjhYtWmR/7uLFi9q4caN69uyZptgBIDN06dJFN27c0Pr163X16lWtX78+yV5FYWFhcnV11bBhwxzan3vuORmGoY0bN9rXk5RgvTtzjGEYWrlypdq0aSPDMBw+AzRv3lxXrly55y1XSRkzZow2b96c4Od2b6Ty5curWrVqDj2/4uLitGLFCrVp08Yhd/x3+dKlS7py5YoaNGiQ6tgS899j3L4636BBA0VFRenPP/9M8f5Onz6tffv2qW/fvg49sB544AE1bdrU/jv6r6efftrhcYMGDXThwgVFRkYm+7g9evTQtm3bFBERoa+++koRERFJ/j0tX75cDRo0UL58+Rx+902aNFFcXJy2b9+e7OM+88wz91xn5cqVstlsGjt2bILnbufr2581v/jiCwZcQ7JQcMMpHDp0SFeuXFGhQoVUsGBBh59r167p7NmzkqSGDRuqY8eOGj9+vPz9/fX4449r3rx5io6OztD4Tpw4oQoVKiRovz2q+u0idtSoUfLx8VHt2rVVrlw5DRkyJEEXpHfeeUf79+9X8eLFVbt2bY0bN05Hjx69Zww3btzQmDFj7Pc4+fv7q2DBgrp8+bKuXLmSYP0SJUo4PM6XL58k2e+Jvx1zuXLlHNYrWLCgfd17WbhwoXLnzq3SpUvr8OHDOnz4sDw9PRUUFORQgB45ckQuLi6qXLlykvs6cuSIJPOeuvRUqlSpBG3x8fGaNm2aypUr5/Be/vrrrw7v5ZEjR1ShQgWHgYQS07t3b+3cudP+ni5fvlyxsbF64okn0vW1AEBGKFiwoJo0aaLFixdr1apViouLS3KwsRMnTigwMFB58uRxaL8zH544cUIuLi4qU6aMw3p35tJz587p8uXL+uSTTxLk/379+kmS/TNASlWpUkVNmjRJ8OPu7m5fp2vXrtq5c6dOnTolyRz/4+zZs+ratavDvtavX6+HHnpInp6eyp8/v72bc2L5N7V+//13tW/fXn5+fvL19VXBggXttyWl5ji3fxdJfX45f/68rl+/7tB+r88OyXH7PuqlS5dq0aJFqlWrlsqWLZvouocOHVJ4eHiC332TJk0kJf93nytXLhUrVuye6x05ckSBgYEOX0DcqWvXrqpfv74GDhyowoULq1u3blq2bBnFN5LEPdxwCvHx8SpUqJBDkfZftwfLuD1f9nfffad169bpyy+/VP/+/TVlyhR99913d72PKTNUqlRJBw8e1Pr16xUeHq6VK1dq1qxZGjNmjH06iy5duqhBgwZavXq1Nm3apMmTJ+vtt9/WqlWr7PfPJebZZ5/VvHnzNGLECNWtW1d+fn6y2Wzq1q1boknA1dU10f0Ydwxqk1qGYWjJkiW6fv16ooX02bNnde3atXT/nSR1xTguLi7R13zn1W1JevPNN/Xaa6+pf//+mjhxovLnzy8XFxeNGDEiVQm1W7duGjlypBYtWqSXX35ZCxcuVM2aNRP9kAMAWVGPHj00aNAgRUREqEWLFvarfBnt9jm3V69e6tOnT6LrpHUclrvp2rWrRo8ereXLl2vEiBFatmyZ/Pz8FBwcbF9nx44datu2rR555BHNmjVLRYoUkZubm+bNm+cwqGdi7paz/uvy5ctq2LChfH19NWHCBJUpU0aenp7au3evRo0alWnFXnp8dvDw8FCHDh20YMECHT169K4D18bHx6tp06Z68cUXE32+fPnyyT5mes1A4uXlpe3bt+vrr7/Whg0bFB4erqVLl+rRRx/Vpk2bknyPkHNRcMMplClTRlu2bFH9+vUTLZDu9NBDD+mhhx7SG2+8ocWLF6tnz54KDQ3VwIEDM6QLb8mSJXXw4MEE7be7eJUsWdLeljt3bnXt2lVdu3ZVTEyMOnTooDfeeEOjR4+2d5UuUqSIBg8erMGDB+vs2bN68MEH9cYbb9y14F6xYoX69OmjKVOm2Ntu3rzpMBJoSl+TZH67XLp0aXv7uXPnkvVN9u05WidMmJBg/vRLly7pySef1Jo1a9SrVy+VKVNG8fHx+uOPP1StWrVE93f7Ksj+/fuT/CZcMr9tT+w1nzhxwuF13M2KFSvUuHFjzZkzx6H98uXL8vf3d4jp+++/V2xs7F2nFsmfP79atWqlRYsWqWfPntq5c6emT5+erFgAICto3769nnrqKX333XcOXazvVLJkSW3ZskVXr151uMp9Zz4sWbKk4uPj7T2Fbrszl94ewTwuLs5+VTMzlSpVSrVr19bSpUs1dOhQrVq1Su3atXOYf3zlypXy9PTUl19+6dA+b968e+7/9hXiy5cvO3yJcfvq823btm3ThQsXtGrVKj3yyCP29mPHjiXYZ3I/59z+XST1+cXf31+5c+dO1r5SqkePHpo7d65cXFwcBp+7U5kyZXTt2rV7/u7T67NdmTJl9OWXXyYY6PROLi4ueuyxx/TYY49p6tSpevPNN/XKK6/o66+/tuTvFFkbXcrhFLp06aK4uDhNnDgxwXO3bt2yF1iXLl1K8C3r7QLudrfy2yNTprYQTUzLli31ww8/aPfu3fa269ev65NPPlFQUJD9Cu+FCxcctnN3d1flypVlGIZiY2MVFxeXoFtYoUKFFBgYeM9u8a6urgle+/vvv5/gW/LkatKkidzc3PT+++877De5heLt7uQvvPCCOnXq5PAzaNAglStXzt5joV27dnJxcdGECRMSfEt/+9jNmjVTnjx5NGnSJN28eTPRdSQzWX733XcOI6mvX79ef//9d7Jfe2Lv5fLly+1dCm/r2LGjzp8/r5kzZybYx53bP/HEE/rjjz/0wgsvyNXV9a4fMAAgq/Hx8dGHH36ocePGqU2bNkmu17JlS8XFxSU4L06bNk02m83+xfHtf+8c5fzOHOPq6qqOHTtq5cqV2r9/f4Lj3TmdZUbo2rWrvvvuO82dO1fnz59P0J3c1dVVNpvNId8eP35ca9asuee+b3+Z/N97ka9fv64FCxYkOIbkmFtiYmI0a9asBPvMnTt3srqYFylSRNWqVdOCBQscPhPt379fmzZtUsuWLe+5j9Rq3LixJk6cqJkzZzqMAH+nLl26aPfu3Q7jvtx2+fJl3bp1S1L6fbbr2LGjDMOw9zr8r9vv/cWLFxM8d+dnTeC/uMINp9CwYUM99dRTmjRpkvbt26dmzZrJzc1Nhw4d0vLlyzVjxgx16tRJCxYs0KxZs9S+fXuVKVNGV69e1ezZs+Xr62tPHF5eXqpcubKWLl2q8uXLK3/+/Lr//vvveW/wypUrEx2UpE+fPnrppZfsU6YMGzZM+fPn14IFC3Ts2DGtXLnS3o2pWbNmCggIUP369VW4cGEdOHBAM2fOVKtWrZQnTx5dvnxZxYoVU6dOnVS1alX5+Phoy5Yt2rNnj8OV68S0bt1an3/+ufz8/FS5cmXt3r1bW7ZsUYECBVL1nhcsWFDPP/+8Jk2apNatW6tly5b6+eeftXHjRoervImJjo7WypUr1bRp0wQDnN3Wtm1bzZgxQ2fPnlXZsmX1yiuvaOLEiWrQoIE6dOggDw8P7dmzR4GBgZo0aZJ8fX01bdo0DRw4ULVq1VKPHj2UL18+/fLLL4qKirJ/OBk4cKBWrFih4OBgdenSRUeOHNHChQsT3Cd4N61bt9aECRPUr18/1atXT7/99psWLVqU4Ap579699dlnnykkJEQ//PCDGjRooOvXr2vLli0aPHiww/zbrVq1UoECBbR8+XK1aNFChQoVSnY8AJAVJNWl+7/atGmjxo0b65VXXtHx48dVtWpVbdq0SV988YVGjBhhPxdXq1ZN3bt316xZs3TlyhXVq1dPW7du1eHDhxPs86233tLXX3+tOnXqaNCgQapcubIuXryovXv3asuWLYkWQMmxY8eOBF/gSmYX9f92U+/SpYuef/55Pf/888qfP3+CK5itWrXS1KlTFRwcrB49eujs2bP64IMPVLZsWf366693jaFZs2YqUaKEBgwYYP9Cdu7cuSpYsKBOnjxpX69evXrKly+f+vTpo2HDhslms+nzzz9PtCt3jRo1tHTpUoWEhKhWrVry8fFJ8kuSyZMnq0WLFqpbt64GDBhgnxbMz8/vrl2908rFxUWvvvrqPdd74YUXtHbtWrVu3Vp9+/ZVjRo1dP36df32229asWKFjh8/Ln9//1R/trtT48aN9cQTT+i9997ToUOHFBwcrPj4eO3YsUONGzfW0KFDNWHCBG3fvl2tWrVSyZIldfbsWc2aNUvFihVzGDwXsMvsYdGB5LhzWrDbPvnkE6NGjRqGl5eXkSdPHqNKlSrGiy++aPz777+GYRjG3r17je7duxslSpQwPDw8jEKFChmtW7c2fvzxR4f97Nq1y6hRo4bh7u5+zynC7jV9yO2pwI4cOWJ06tTJyJs3r+Hp6WnUrl3bWL9+vcO+Pv74Y+ORRx4xChQoYHh4eBhlypQxXnjhBePKlSuGYRhGdHS08cILLxhVq1Y18uTJY+TOnduoWrWqMWvWrHu+Z5cuXTL69etn+Pv7Gz4+Pkbz5s2NP//8M8EUJP+d6iWx1/n111/b2+Li4ozx48cbRYoUMby8vIxGjRoZ+/fvT3LqrdtWrlxpSDLmzJmT5Drbtm0zJBkzZsywt82dO9eoXr264eHhYeTLl89o2LChsXnzZoft1q5da9SrV8/w8vIyfH19jdq1axtLlixxWGfKlClG0aJFDQ8PD6N+/frGjz/+mOS0YIlN93bz5k3jueees7/u+vXrG7t3706wD8Mwp2l55ZVXjFKlShlubm5GQECA0alTJ+PIkSMJ9jt48GBDkrF48eIk3xcAyAqSyhV3unNaMMMwp8UcOXKkERgYaLi5uRnlypUzJk+enGAaxBs3bhjDhg0zChQoYOTOndto06aN8ffffyeal8+cOWMMGTLEKF68uP1c+9hjjxmffPKJfZ30mhYssc8E9evXNyQZAwcOTHSfc+bMMcqVK2d4eHgYFStWNObNm5folF+J5c+ffvrJqFOnjuHu7m6UKFHCmDp1aqLTgu3cudN46KGHDC8vLyMwMNB48cUXjS+//DJB7r527ZrRo0cPI2/evIYk+7RXSb0/W7ZsMerXr2/Pq23atDH++OMPh3Vuv5Y7p8JKLM7E/HdasKQkNi2YYZh/T6NHjzbKli1ruLu7G/7+/ka9evWMd99914iJibGvl9Rnu7sd+85pwQzDMG7dumVMnjzZqFixouHu7m4ULFjQaNGihfHTTz8ZhmEYW7duNR5//HEjMDDQcHd3NwIDA43u3bsnmLoMuM1mGOk0QhIA4K5GjhypOXPmKCIiwt79DQAAANkX93ADQCa4efOmFi5cqI4dO1JsAwAA5BDcww0AGejs2bPasmWLVqxYoQsXLmj48OFWhwQAAIBMQsENABnojz/+UM+ePVWoUCG99957SU57BgAAgOzH0i7l27dvV5s2bRQYGCibzZas6RO2bdumBx98UB4eHipbtqzmz5+f4XECQGo1atRIhmHozJkzGjp0qNXhAKlGzgYAIOUsLbivX7+uqlWr6oMPPkjW+seOHVOrVq3UuHFj7du3TyNGjNDAgQMTnZsPAACkH3I2AAApl2VGKbfZbFq9erXatWuX5DqjRo3Shg0btH//fntbt27ddPnyZYWHh2dClAAAgJwNAEDyONU93Lt371aTJk0c2po3b64RI0YkuU10dLSio6Ptj+Pj43Xx4kUVKFBANpsto0IFADgxwzB09epVBQYGysWFCT1Sg5wNAMhozpCvnargjoiIUOHChR3aChcurMjISN24cUNeXl4Jtpk0aZLGjx+fWSECALKRv//+W8WKFbM6DKdEzgYAZJasnK+dquBOjdGjRyskJMT++MqVKypRooSOHTumPHnypHq/sbGx+vrrr9W4cWO5ubmlR6gAgBSyffutct2lW/Ntt9askfHww8ne79WrV1WqVKk05QmkHDkbALKvb09+q3bL2t1zvTVd1ujhEsnL2c6Qr52q4A4ICNCZM2cc2s6cOSNfX99EvymXJA8PD3l4eCRoz58/v3x9fVMdS2xsrLy9vVWgQAGSNwBYpXVrqUAB6cKFxJ+32aRixcz1XF2Tvdvb53W6MaceORsA8F+t87VWsW3FdCrylAwlHEbMJpuK+RZT66qt5eqSvJztDPk6a3Z0T0LdunW1detWh7bNmzerbt26FkUEALDU7t3SlSuJP3c7+U6fnqJiG+mDnA0A+C9XF1fNCJ4hySyu/+v24+nB05NdbDsLSwvua9euad++fdq3b58kcwqRffv26eTJk5LMrmW9e/e2r//000/r6NGjevHFF/Xnn39q1qxZWrZsmUaOHGlF+AAAKx04ILVtK926JdWsaV7J/q9ixaQVK6QOHayJL5shZwMA0qpDpQ5a0WWFivoWdWgv5ltMK7qsUIdK2S9nW9ql/Mcff1Tjxo3tj2/ft9WnTx/Nnz9fp0+ftidySSpVqpQ2bNigkSNHasaMGSpWrJg+/fRTNW/ePNNjBwBY6N9/peBg6dIl6aGHpK1bJQ8P3fr6a+3buFHVWrRQrsaNubKdjsjZAID00KFSBz1e4XF9ffRrbfx2o1o83EKNSzfOdle2b7O04G7UqJHuNg34/PnzE93m559/zsCoAABZWmSk1LKldPKkVK6ctG6d5O0tSTIaNtSp69dVtWFDiu10Rs4GkFZxcXGKjY21OgxkEXUK11F0wWjVKVxHsTGxilXifxtubm5ydeKc7lSDpgEAcriYGKljR+mXX6RChaTwcMnf3+qoAAB3YRiGIiIidPnyZatDQRZiGIYCAgL0999/33PQs7x58yogICBLD46WFApuAIBzMAxpwABpyxYpd24pLEwqXdrqqAAA93C72C5UqJC8vb2dsmhC+ouPj9e1a9fk4+MjF5fEhxYzDENRUVE6e/asJKlIkSKZGWK6oOAGADiHl1+WFi40u4qvWCHVqGF1RACAe4iLi7MX2wUKFLA6HGQh8fHxiomJkaenZ5IFtyT7VJJnz55VoUKFnK57uVNNCwYAyKFmzZLeestc/vRTc8A0AECWd/uebe//H2sDSI3bfz/OOAYABTcAIGtbvVoaOtRcnjhR6tvX0nAAAClHN3KkhTP//VBwAwCyrl27pB49zPu3n3xSeuUVqyMCAABINgpuAEDWdPCg1KaNdPOm+e8HH0hO/A03AADIeSi4AQBZz+nT5n3aFy9KdepIS5ZIuRjnEwBytLg4ads2Myds22Y+ziA2m+2uP+PGjUvTvtesWZNu6yFr49MLACBruXpVatVKOn5cKltWWrfOnAYMAJBzrVolDR8u/fPP/9qKFZNmzJA6dEj3w50+fdq+vHTpUo0ZM0YHDx60t/n4+KT7MZE9cYUbAJB1xMRInTpJP/8sFSokhYdLBQtaHRUAwEqrVpm54b/FtiSdOmW2r1qV7ocMCAiw//j5+clmszm0hYaGqlKlSvL09FTFihU1a9Ys+7YxMTEaOnSoihQpIk9PT5UsWVKTJk2SJAUFBUmS2rdvL5vNZn+cUvHx8ZowYYKKFSsmDw8PVatWTeHh4cmKwTAMjRs3TiVKlJCHh4cCAwM1bNiw1L1RuCeucAMAsgbDkAYNkjZtMq9ob9gglSljdVQAgPRmGFJUVPLWjYuThg0zt0lsPzabeeW7SRMpOfMze3uneTyQRYsWacyYMZo5c6aqV6+un3/+WYMGDVLu3LnVp08fvffee1q7dq2WLVumEiVK6O+//9bff/8tSdqzZ48KFSqkefPmKTg4ONVzSs+YMUNTpkzRxx9/rOrVq2vu3Llq27atfv/9d5UrV+6uMaxcuVLTpk1TaGio7rvvPkVEROiXX35J03uCpFFwAwCyhldflT77zPzAtHy5VLOm1REBADJCVJSUXl2yDcO88u3nl7z1r11L821KY8eO1ZQpU9Th/7uylypVSn/88Yc+/vhj9enTRydPnlS5cuX08MMPy2azqWTJkvZtC/5/r628efMqICAg1TG8++67GjVqlLp16yZJevvtt/X1119r+vTp+uCDD+4aw8mTJxUQEKAmTZrIzc1NJUqUUO3atVMdC+6OLuUAAOt9+KH05pvm8iefSC1aWBsPAACJuH79uo4cOaIBAwbIx8fH/vP666/ryJEjkqS+fftq3759qlChgoYNG6ZNmzalawyRkZH6999/Vb9+fYf2+vXr68CBA/eMoXPnzrpx44ZKly6tQYMGafXq1bp161a6xoj/oeAGAFjriy+koUPN5fHjpf79rY0HAJCxvL3NK83J+QkLS94+w8KStz9v7zSFfu3aNUnS7NmztW/fPvvP/v379d1330mSHnzwQR07dkwTJ07UjRs31KVLF3Xq1ClNx02pu8VQvHhxHTx4ULNmzZKXl5cGDx6sRx55RLGxsZkaY05Bl3IAgHV275a6dZPi4837t197zeqIAAAZzWZLfrfuZs3M0chPnUr8Pm6bzXy+WbPk3cOdRoULF1ZgYKCOHj2qnj17Jrmer6+vunbtqq5du6pTp04KDg7WxYsXlT9/frm5uSkuDVOa+fr6KjAwUDt37lTDhg3t7Tt37nToGn63GLy8vNSmTRu1adNGQ4YMUcWKFfXbb7/pwQcfTHVcSBwFNwDAGgcPSm3aSDdvmtOAzZqV5oFsAADZjKurOfVXp05mjvhv0X07Z0yfninF9m3jx4/XsGHD5Ofnp+DgYEVHR+vHH3/UpUuXFBISoqlTp6pIkSKqXr26XFxctHz5cgUEBChv3rySzJHKt27dqvr168vDw0P58uVL8ljHjh3Tvn37HNrKlSunF154QWPHjlWZMmVUrVo1zZs3T/v27dOiRYsk6a4xzJ8/X3FxcapTp468vb21cOFCeXl5OdznjfRDwQ0AyHwREVJwsHThglS7trR0qZSLlAQASESHDtKKFYnPwz19eobMw303AwcOlLe3tyZPnqwXXnhBuXPnVpUqVTRixAhJUp48efTOO+/o0KFDcnV1Va1atRQWFiYXF/Nu3ilTpigkJESzZ89W0aJFdfz48SSPFRISkqBtx44dGjZsmK5cuaLnnntOZ8+eVeXKlbV27VqVK1funjHkzZtXb731lkJCQhQXF6cqVapo3bp1KlCgQLq/V5BshpFY34zsKzIyUn5+frpy5Yp8fX1TvZ/Y2FiFhYWpZcuWcnNzS8cIASCbu3pVatRI2rvXnPZr1y5zzu10kF7n5vTKFUgbcjbg/G7evKljx46pVKlS8vT0TNvO4uKkHTuk06elIkWkBg0y9co20ld8fLwiIyPl6+tr/zIiKUn9HTlDvuZyAgAg88TGSp07m8V2wYJSeHi6FdsAgGzO1dX8whZwIoxSDgDIHIZhDoz25ZfmKLEbNkhly1odFQAAQIah4AYAZI4xY6QFC8wrFMuWSbVqWR0RAABAhqLgBgBkvI8/ll5/3Vz+6CNzVHIAAIBsjoIbAJCx1q6VBg82l8eOlQYOtDYeAACATELBDQDION99J3XrJsXHSwMGmAU3AABADkHBDQDIGH/9JbVpI924IbVsKX34oWSzWR0VAABApqHgBgCkvzNnpOBg6fx5qWZNaelSifmPAQBADkPBDQBIX9eumYOiHTsmlSljTv/l42N1VAAAAJmOghsAkH5iY6XOnaWffpL8/aXwcKlQIaujAgAAsAQFNwAgfRiG9NRTZpHt5SWtXy+VLWt1VACAbCIuPk7bjm/Tkt+WaNvxbYqLj8uwY9lstrv+jBs3Lk37XrNmTbLXf+qpp+Tq6qrly5en+piwTi6rAwAAZBPjxknz5kkuLtKyZVKdOlZHBADIJlYdWKXh4cP1T+Q/9rZivsU0I3iGOlTqkO7HO336tH156dKlGjNmjA4ePGhv88mkW6WioqIUGhqqF198UXPnzlXnzp0z5bhJiYmJkbu7u6UxOBuucAMA0u6TT6QJE8zljz6SWre2Nh4AQLax6sAqdVrWyaHYlqRTkafUaVknrTqwKt2PGRAQYP/x8/OTzWZzaAsNDVWlSpXk6empihUratasWfZtY2JiNHToUBUpUkSenp4qWbKkJk2aJEkKCgqSJLVv3142m83+OCnLly9X5cqV9dJLL2n79u36+++/HZ6Pjo7WqFGjVLx4cXl4eKhs2bKaM2eO/fnff/9drVu3lq+vr/LkyaMGDRroyJEjkqRGjRppxIgRDvtr166d+vbta38cFBSkiRMnqnfv3vL19dWTTz4pSRo1apTKly8vb29vlS5dWq+99ppiY2Md9rVu3TrVqlVLnp6e8vf3V/v27SVJEyZM0P3335/gtVarVk2vvfbaXd8PZ8QVbgBA2qxfLz3zjLn82mvSoEHWxgMAyNIMw1BUbFSy1o2Lj9OwjcNkyEi4HxmyyabhG4erSakmcnVxvef+vN28ZUvjFJWLFi3SmDFjNHPmTFWvXl0///yzBg0apNy5c6tPnz567733tHbtWi1btkwlSpTQ33//bS+U9+zZo0KFCmnevHkKDg6Wq+vdY54zZ4569eolPz8/tWjRQvPnz3coSnv37q3du3frvffeU9WqVXXs2DGdP39eknTq1Ck98sgjatSokb766iv5+vpq586dunXrVope77vvvqsxY8Zo7Nix9rY8efJo/vz5CgwM1G+//aZBgwYpT548evHFFyVJGzZsUPv27fXKK6/os88+U0xMjMLCwiRJ/fv31/jx47Vnzx5VqFBBkvTzzz/r119/1apV6f/lidUouAEAqff991KXLlJ8vNSvnzR+vNURAQCyuKjYKPlMSp8u2YYM/XP1H/m97Zes9a+Nvqbc7rnTdMyxY8dqypQp6tDB7MpeqlQp/fHHH/r444/Vp08fnTx5UuXKldPDDz8sm82mkiVL2rctWLCgJClv3rwKCAi463EOHTqk7777zl6E9urVSyEhIXr11Vdls9n0119/admyZdq8ebOaNGkiSSpdurR9+w8++EB+fn4KDQ2V2/9PzVm+fPkUv95HH31Uzz33nEPbq6++al8OCgrS888/b+/6LklvvPGGunXrpvH/+VxQtWpVSVKxYsXUvHlzzZ8/337lf968eWrYsKFD/NkFXcoBAKlz6JDZdfzGDXPO7Y8/ltJ41QAAgKzs+vXrOnLkiAYMGCAfHx/7z+uvv27vqt23b1/t27dPFSpU0LBhw7Rp06ZUHWvu3Llq3ry5/P39JUktW7bUlStX9NVXX0mS9u3bJ1dXVzVs2DDR7fft26cGDRrYi+3UqlmzZoK2pUuXqn79+goICJCPj49effVVnTx50uHYjz32WJL7HDRokEJDQ3Xz5k3FxMRo8eLF6t+/f5rizKq4wg0ASLmzZ6UWLaTz56UaNaTly6U0JnQAQM7g7eata6OvJWvd7Se2q+XilvdcL6xHmB4p+Uiyjp0W166Zcc+ePVt17hgc9Hb38AcffFDHjh3Txo0btWXLFnXp0kVNmjTRihUrkn2cuLg4LViwQBEREcqVK5dD+9y5c/XYY4/Jy8vrrvu41/MuLi4yDMeu+nfehy1JuXM79gjYvXu3evbsqfHjx6t58+b2q+hTpkxJ9rHbtGkjDw8PrV+/Xn5+foqNjVWnTp3uuo2zouAGAKTMtWtSq1bSkSNSqVLShg1SJo3WCgBwfjabLdndupuVaaZivsV0KvJUovdx22RTMd9ialamWbLu4U6rwoULKzAwUEePHlXPnj2TXM/X11ddu3ZV165d1alTJwUHB+vixYvKnz+/3NzcFBd39ynNwsLCdPXqVf38888O93nv379f/fr10+XLl1WlShXFx8frm2++sXcp/68HHnhACxYsUGxsbKJXuQsWLOgwGntcXJz279+vxo0b3zW2Xbt2qWTJknrllVfsbSdOnEhw7K1bt6pfv36J7iNXrlzq3bu3Fi9eLC8vL3Xr1u2eRbqzoks5ACD5bt2SunaVfvxRKlDAnHO7cGGrowIAZFOuLq6aETxDkllc/9ftx9ODp2dKsX3b+PHjNWnSJL333nv666+/9Ntvv2nevHmaOnWqJGnq1KlasmSJ/vzzT/31119avny5AgIClDdvXknmPc9bt25VRESELl26lOgx5syZo1atWqlq1aq6//777T9dunRR3rx5tWjRIgUFBalPnz7q37+/1qxZo2PHjmnbtm1atmyZJGno0KGKjIxUt27d9OOPP+rQoUP6/PPP7dObPfroo9qwYYM2bNigP//8U88884wuX758z9dfrlw5nTx5UqGhoTpy5Ijee+89rV692mGdsWPHasmSJRo7dqwOHDig3377TW+//bbDOgMGDND27dv15ZdfZtvu5BIFNwAguQxDevppKSxM8vIyRydPxeArAACkRIdKHbSiywoV9S3q0F7Mt5hWdFmRIfNw383AgQP16aefat68eapSpYoaNmyo+fPnq1SpUpLMEbzfeecd1axZU7Vq1dLx48cVFhYmFxez9JoyZYo2b96s4sWLq3r16gn2f+bMGW3YsEEdO3ZM8JyLi4vat29vn/rrww8/VKdOnTR48GBVrFhRgwYN0vXr1yVJBQoU0FdffaVr166pYcOGqlGjhmbPnm2/2t2/f3/16dNHvXv3tg9Ydq+r25LUtm1bjRw5UkOHDlW1atW0a9euBNN5NWrUSMuXL9fatWtVrVo1Pfroo/rhhx8c1ilXrpxq166tihUrJuien53YjDs77mdzkZGR8vPz05UrV+Tr65vq/cTGxiosLEwtW7ZM80AEAOAUxo+Xxo2TXFyk1aultm2tjiiB9Do3p1euQNqQswHnd/PmTR07dkylSpWSp6dnmvYVFx+nHSd36PTV0yqSp4galGiQqVe2kb7i4uJUrlw5DRkyJMEo6HdK6u/IGfI193ADAO7t00/NYluSZs3KksU2ACB7c3VxVaOgRlaHgXRw7tw5LVmyRGfPnlXfvn2tDidDUXADAO5uwwazK7kkvfKK9NRT1sYDAACcWqFCheTv769p06YpX758VoeToSi4AQBJ27NH6tJFiouT+vSRJk60OiIAAODkDMNQfHy8IiMjrQ4lwzFoGgAgcYcPm9N/RUVJzZtLs2dLNtu9twMAAIAkCm4AQGLOnpWCg6Vz56QHH5SWL5cYbAoAACBFKLgBAI6uX5dat5aOHJGCgsx7uPPksToqAIATi4+PtzoEODFn/vvhHm4AwP/cuiV17Wreu12ggBQeLgUEWB0VAMBJubu7y8XFRf/++68KFiwod3d32bg9CTKL6JiYGN28edM+R/mdDMNQTEyMzp07JxcXF7m7u2dylGlHwQ0AMBmGNHiweUXb01Nat06qUMHqqAAATszFxUWlSpXS6dOn9e+//1odDrIQwzB048YNeXl53fNLGG9vb5UoUSLJwjwro+AGAJgmTjQHRnNxkUJDpbp1rY4IAJANuLu7q0SJErp165bi4uKsDgdZRGxsrLZv365HHnlEbncZJ8bV1VW5cuVy2p4RFNwAAGnuXGnsWHN55kzp8cetjQcAkK3YbDa5ubndtbBCzuLq6qpbt27J09MzW/9dON81eQBA+tq4UXrySXP55ZelZ56xNh4AAIBsgoIbAHKyH3+UOnWS4uKk3r2l11+3OiIAAIBsg4IbAHKqo0elVq2kqCipaVPz/m0nvT8KAAAgK6LgBoCc6Nw5KThYOntWql5dWrlScsKpNgAAALIyCm4AyGmioqQ2baRDh6SSJc1pwPLksToqAACAbIeCGwByklu3pG7dpO+/l/Lnl8LDpSJFrI4KAAAgW6LgBoCcwjCkIUOkdeskT09p7VqpYkWrowIAAMi2KLgBIKd44w3pk0/MgdEWL5bq17c6IgAAgGyNghsAcoL586XXXjOX339fat/e0nAAAAByAgpuAMjuwsOlgQPN5ZdeMruVAwAAIMNRcANAdvbTT1KnTlJcnNSrl/Tmm1ZHBAAAkGNQcANAdnX0qNSypXT9utSkiTRnjnn/NgAAADIFBTcAZEfnz0vBwdLZs1K1atLKlZK7u9VRAQAA5CgU3ACQ3URFSW3aSIcOSSVKSBs2SL6+VkcFAACQ41BwA0B2cuuW1L279N13Ur585oBpgYFWRwUAAJAjUXADQHZhGNKzz0pr10oeHtK6dVKlSlZHBQAAkGNRcANAdjFpkvTRR+bAaIsXS/XrWx0RAABAjkbBDQDZwYIF0iuvmMvvvSd16GBtPAAAAKDgBgCnt2mTNHCgufzii9LQodbGAwAAAEkU3ADg3PbulTp2NAdL69nT7FYOAACALIGCGwCc1bFjUqtW0rVr0mOPSXPnSi6c1gEAALIKyz+ZffDBBwoKCpKnp6fq1KmjH3744a7rT58+XRUqVJCXl5eKFy+ukSNH6ubNm5kULQBkERcuSC1aSBER0gMPSCtXSu7uVkeFbI6cDQBAylhacC9dulQhISEaO3as9u7dq6pVq6p58+Y6e/ZsousvXrxYL730ksaOHasDBw5ozpw5Wrp0qV5++eVMjhwALHTjhtSmjXTwoFS8uLRxo+TnZ3VUyObI2QAApJylBffUqVM1aNAg9evXT5UrV9ZHH30kb29vzZ07N9H1d+3apfr166tHjx4KCgpSs2bN1L1793t+ww4A2UZcnNSjh7R7t5Q3rxQeLgUGWh0VcgByNgAAKZfLqgPHxMTop59+0ujRo+1tLi4uatKkiXbv3p3oNvXq1dPChQv1ww8/qHbt2jp69KjCwsL0xBNPJHmc6OhoRUdH2x9HRkZKkmJjYxUbG5vq+G9vm5Z9AECKGIZchg+X65o1Mjw8FLdqlYxy5STOQ3bpdW7m3O6InA0ASG/pcW52hvO6ZQX3+fPnFRcXp8KFCzu0Fy5cWH/++Wei2/To0UPnz5/Xww8/LMMwdOvWLT399NN37Z42adIkjR8/PkH7pk2b5O3tnbYXIWnz5s1p3gcAJEe5lStV+fPPZdhs2jN8uE5HRkphYVaHlSWl9dwcFRWVTpFkD+RsAEBGScu52RnytWUFd2ps27ZNb775pmbNmqU6dero8OHDGj58uCZOnKjXXnst0W1Gjx6tkJAQ++PIyEgVL15czZo1k6+vb6pjiY2N1ebNm9W0aVO5ubmlej8AkBy2hQuV6/PPJUnxU6ao+tChqm5xTFlRep2bb19ZReqRswEAd5Me52ZnyNeWFdz+/v5ydXXVmTNnHNrPnDmjgICARLd57bXX9MQTT2jgwIGSpCpVquj69et68skn9corr8glkelwPDw85OHhkaDdzc0tXZJueu0HAJK0ebP05JPm8vPPy3XkSLlaG1GWl9ZzM+d1R+RsAEBGScu52RnO6ZYNmubu7q4aNWpo69at9rb4+Hht3bpVdevWTXSbqKioBAna1dX82GkYRsYFCwBW+flnqUMH6dYtqXt36e23rY4IORA5GwCA1LG0S3lISIj69OmjmjVrqnbt2po+fbquX7+ufv36SZJ69+6tokWLatKkSZKkNm3aaOrUqapevbq9e9prr72mNm3a2JM4AGQbx49LLVtK165JjRtL8+ZJiVwVBDIDORsAgJSztODu2rWrzp07pzFjxigiIkLVqlVTeHi4fVCWkydPOnw7/uqrr8pms+nVV1/VqVOnVLBgQbVp00ZvvPGGVS8BADLGxYtSixZSRIRUpYq0erWUSFdbILOQswEASDmbkcP6dUVGRsrPz09XrlxJ8wAsYWFhatmypVPcOwDAidy4ITVtKu3cKRUvbs65XbSo1VE5hfQ6N6dXrkDakLMBIPtKj3OzM+Rr+iYCQFYSFyf17GkW23nzShs3UmwDAAA4KQpuAMgqDEMaMcLsPu7uLq1ZI913n9VRAQAAIJUouAEgq5g8WZo5U7LZpM8/lxo2tDoiAAAApAEFNwBkBYsWSaNGmctTp0pdulgbDwAAANKMghsArLZ1q/T/UyspJMTsVg4AAACnR8ENAFb65RepfXspNlbq2tXsVg4AAIBsgYIbAKxy4oQ51/bVq1KjRtKCBZILp2UAAIDsgk92AGCFixfNYvv0aen++82RyT08rI4KAAAA6YiCGwAy282b0uOPSwcOSMWKmXNt581rdVQAAABIZxTcAJCZ4uKkXr2kb7+V/PzMYrtYMaujAgAAQAag4AaAzGIY0siR0sqVkru7tGaN2Z0cAAAA2RIFNwBklnffld5/31z+7DNzoDQAAABkWxTcAJAZFi+WXnzRXJ4yxZwCDAAAANkaBTcAZLSvvpL69jWXR46UQkIsDQcAAACZg4IbADLSr79K7dtLsbFSly5mt3IAAADkCBTcAJBRTp4059qOjJQeeURasEBy4bQLAACQU/DJDwAywqVLZrH977/SffeZI5J7elodFQAAADIRBTcApLebN6XHH5f++EMqWtScaztfPqujAgAAQCaj4AaA9BQfL/XuLe3YIfn6msV28eJWRwUAAAALUHADQHoxDHME8uXLJTc3sxt5lSpWRwUAAACLUHADQHqZOlWaMcNc/uwzqXFja+MBAACApSi4ASA9hIZKzz9vLk+eLHXrZm08AAAAsBwFNwCk1ddfS336mMvDh0vPPWdtPAAAAMgSKLgBIC1++01q106KiZE6dTK7ldtsVkcFAACALICCGwBS6++/zbm2IyOlBg2kzz+XXDitAgAAwMQnQwBIjcuXzWL71CmpcmXpiy8kT0+rowIAAEAWQsENACkVHW12I//9dykw0JxrO18+q6MCAABAFkPBDQApER8v9e4tffONlCePFBYmlShhdVQAAADIgii4ASAlnn9eWrZMcnOTVq+Wqla1OiIAAABkURTcAJBc06aZP5I0f7702GOWhgMAAICsjYIbAJJj6VIpJMRcfucdqUcPa+MBAABAlkfBDQD3sm2bed+2JD37rNmtHAAAALgHCm4AuJv9+80RyWNipA4dzC7lNpvVUQEAAMAJUHADQFL++ceca/vKFenhh6WFCyVXV6ujAgAAgJOg4AaAxFy+bBbb//wjVaokffGF5OVldVQAAABwIhTcAHCn6GipfXuzO3mRItLGjVL+/FZHBQAAACdDwQ0A/xUfL/Xtaw6UliePFBYmlSxpdVQAAABwQhTcAPBfL74ohYZKuXJJq1ZJ1apZHREAAACcFAU3ANw2Y4Y0ZYq5PG+e1KSJtfEAAADAqVFwA4AkLV8ujRxpLr/1ltSrl7XxAAAAwOlRcAPA9u1mgW0Y0pAhZrdyAAAAII0ouAHkbL//Lj3+uBQTY45MPmOGZLNZHRUAAACyAQpuADnXqVNScLA553a9etKiRZKrq9VRAQAAIJug4AaQM125IrVoIf3zj1ShgrR2reTlZXVUAAAAyEYouAHkPNHRZvfx336TAgKk8HCpQAGrowIAAEA2Q8ENIGeJj5f69ZO+/lry8ZHCwqSgIKujAgAAQDZEwQ0gZ3npJWnJEilXLmnVKql6dasjAgAAQDZFwQ0g53jvPWnyZHN57lypaVNr4wEAAEC2RsENIGdYuVIaMcJcfvNN6YknLA0HAAAA2R8FN4Dsb8cOqWdPyTCkZ54xu5UDAAAAGYyCG0D29scf0uOPmyOTt2snvf++ZLNZHRUAAAByAApuANnXv/+ac21fuiTVrSstXiy5ulodFQAAAHIICm4A2VNkpFlsnzwplS8vrVsneXlZHRUAAAByEApuANlPTIzUoYP0669S4cJSeLhUoIDVUQEAACCHoeAGkL3Ex0v9+0tbt0o+PlJYmFSqlNVRAQAAIAei4AaQvbz8srRokZQrl7RihfTgg1ZHBAAAgByKghtA9jFzpvT22+byp59KzZtbGw8AAAByNApuANnDqlXSsGHm8uuvS336WBsPAAAAcjwKbgDO79tvpR49JMOQnnrK7FYOAAAAWIyCG4BzO3BAattWio42/505U7LZrI4KAAAAoOAG4MROnzbn2r50SXroIWnJEnOwNAAAACALoOAG4JwiI6WWLaUTJ6Ry5aR16yRvb6ujAgAAAOwouAE4n5gYqWNHad8+qVAhKTxc8ve3OioAAADAAQU3AOdiGNLAgdKWLVLu3FJYmFS6tNVRAQAAAAlQcANwLq+8In3+ueTqKq1YIdWoYXVEAAAAQKIouAE4j1mzpEmTzOVPP5WCg62NBwAAALgLCm4AzmHNGmnoUHN5wgSpb18rowEAAADuiYIbQNa3a5fUvbt5//aTT0qvvmp1RAAAAMA9UXADyNoOHpTatJFu3jT//eADyWazOioAAADgnii4AWRdERHmfdoXL0q1a0tLlki5clkdFQAAAJAslhfcH3zwgYKCguTp6ak6derohx9+uOv6ly9f1pAhQ1SkSBF5eHiofPnyCgsLy6RoAWSaq1elli2l48elsmWl9evNacAAWIacDQBAylh6qWjp0qUKCQnRRx99pDp16mj69Olq3ry5Dh48qEKFCiVYPyYmRk2bNlWhQoW0YsUKFS1aVCdOnFDevHkzP3gAGSc2VurUSfr5Z6lQISk8XCpY0OqogByNnA0AQMpZWnBPnTpVgwYNUr9+/SRJH330kTZs2KC5c+fqpZdeSrD+3LlzdfHiRe3atUtubm6SpKCgoMwMGUBGMwxp4EBp0ybJ29u8sl2mjNVRATkeORsAgJSzrOCOiYnRTz/9pNGjR9vbXFxc1KRJE+3evTvRbdauXau6detqyJAh+uKLL1SwYEH16NFDo0aNkqura6LbREdHKzo62v44MjJSkhQbG6vY2NhUx39727TsA0BCLq+9JtfPPpPh6qq4JUtkVKtmXvEGkiG9zs2c2x2RswEA6S09zs3OcF63rOA+f/684uLiVLhwYYf2woUL688//0x0m6NHj+qrr75Sz549FRYWpsOHD2vw4MGKjY3V2LFjE91m0qRJGj9+fIL2TZs2ydvbO82vY/PmzWneBwBTUHi4qn70kSRp3zPP6KRhSNzviVRI67k5KioqnSLJHsjZAICMkpZzszPka6ca7jc+Pl6FChXSJ598IldXV9WoUUOnTp3S5MmTk0zeo0ePVkhIiP1xZGSkihcvrmbNmsnX1zfVscTGxmrz5s1q2rSpvascgNSzrV0r108+kSTFvfaa7n/tNd1vcUxwPul1br59ZRWpR84GANxNepybnSFfW1Zw+/v7y9XVVWfOnHFoP3PmjAICAhLdpkiRInJzc3PoilapUiVFREQoJiZG7u7uCbbx8PCQh4dHgnY3N7d0SbrptR8gR9u9W+rVS4qPlwYOlOv48XJlrm2kQVrPzZzXHZGzAQAZJS3nZmc4p1s2LZi7u7tq1KihrVu32tvi4+O1detW1a1bN9Ft6tevr8OHDys+Pt7e9tdff6lIkSKJJm4ATuCvv6Q2baSbN6VWraQPP5QotoEshZwNAEDqWDoPd0hIiGbPnq0FCxbowIEDeuaZZ3T9+nX7CKi9e/d2GKDlmWee0cWLFzV8+HD99ddf2rBhg958800NGTLEqpcAIC0iIqTgYOnCBalWLWnpUimXU93pAuQY5GwAAFLO0k+2Xbt21blz5zRmzBhFRESoWrVqCg8Ptw/KcvLkSbm4/O87geLFi+vLL7/UyJEj9cADD6ho0aIaPny4Ro0aZdVLAJBaV6+aV7SPHTOn/Vq/Xsqd2+qoACSBnA0AQMpZfilp6NChGjp0aKLPbdu2LUFb3bp19d1332VwVAAyVGys1LmztHevVLCgFB4uFSpkdVQA7oGcDQBAyljapRxADmQY0pNPSl9+KXl7m1e2y5a1OioAAAAg3VFwA8hcY8ZI8+dLrq7SsmVS7dpWRwQAAABkCApuAJnn44+l1183lz/6yLyHGwAAAMimKLgBZI5166TBg83lsWOlgQOtjQcAAADIYBTcADLed99JXbtK8fHSgAFmwQ0AAABkcxTcADLWoUNSmzbSjRtSixbShx9KNpvVUQEAAAAZjoIbQMY5c0YKDpbOn5dq1jQHSXNzszoqAAAAIFNQcAPIGNeumYOiHT0qlS4tbdgg+fhYHRUAAACQaSi4AaS/2FipSxfpp58kf38pPFwqVMjqqAAAAIBMRcENIH0ZhvTUU9LGjZKXl7R+vVSunNVRAQAAAJmOghtA+ho3Tpo3T3JxMe/ZrlPH6ogAAAAAS1BwA0g/s2dLEyaYyx9+KLVubW08AAAAgIUouAGkj/XrpaefNpdfe0168klr4wEAAAAsRsENIO1++EHq2lWKj5f69ZPGj7c6IgAAAMByFNwA0ubwYXP6r6goc87tjz+WbDarowIAAAAsR8ENIPXOnjWL7PPnpRo1pOXLJTc3q6MCAAAAsgQKbgCpc/26OSjakSNSqVLShg2Sj4/VUQEAAABZRqoK7lu3bmnLli36+OOPdfXqVUnSv//+q2vXrqVrcACyqFu3pC5dpD17pAIFpPBwqXBhq6MCkAhyNgAA1smV0g1OnDih4OBgnTx5UtHR0WratKny5Mmjt99+W9HR0froo48yIk4AWYVhmKORh4VJXl7m6OTly1sdFYBEkLMBALBWiq9wDx8+XDVr1tSlS5fk5eVlb2/fvr22bt2arsEByIImTJDmzJFcXKTQUOmhh6yOCEASyNkAAFgrxVe4d+zYoV27dsnd3d2hPSgoSKdOnUq3wABkQXPmSOPGmcuzZklt21oaDoC7I2cDAGCtFF/hjo+PV1xcXIL2f/75R3ny5EmXoABkQWFh0lNPmcuvvPK/ZQBZFjkbAABrpbjgbtasmaZPn25/bLPZdO3aNY0dO1YtW7ZMz9gAZBV79kidO0txcVKfPtLEiVZHBCAZyNkAAFgrxV3Kp0yZoubNm6ty5cq6efOmevTooUOHDsnf319LlizJiBgBWOnwYalVKykqSmreXJo9W7LZrI4KQDKQswEAsFaKC+5ixYrpl19+UWhoqH799Vddu3ZNAwYMUM+ePR0GZAGQDZw7J7VoYf774IPS8uWSm5vVUQFIJnI2AADWSnHBLUm5cuVSr1690jsWAFnJ9etS69bmFe6gIGnDBol7PgGnQ84GAMA6KS64P/vss7s+37t371QHAyCLuHVL6tpV+uEHKX9+KTxcCgiwOioAKUTOBgDAWikuuIcPH+7wODY2VlFRUXJ3d5e3tzfJG3B2hiENHmxe0fb0lNavlypUsDoqAKlAzgYAwFopHqX80qVLDj/Xrl3TwYMH9fDDDzMAC5AdvP66OTCai4u0ZIlUt67VEQFIJXI2AADWSnHBnZhy5crprbfeSvBNOgAnM3euNGaMuTxzptSunaXhAEh/5GwAADJPuhTckjkoy7///pteuwOQ2TZulJ580lwePVp65hlr4wGQYcjZAABkjhTfw7127VqHx4Zh6PTp05o5c6bq16+fboEByEQ//ih17izFxUlPPCG98YbVEQFIB+RsAACsleKCu90dXUxtNpsKFiyoRx99VFOmTEmvuABklqNHpVatzGnAmjaVPv1UstmsjgpAOiBnAwBgrRQX3PHx8RkRBwArnDsnBQdLZ89K1apJK1dK7u5WRwUgnZCzAQCwVrrdww3AyURFSW3aSIcOSSVLSmFhUp48VkcFAAAAZBvJusIdEhKS7B1OnTo11cEAyCS3bknduknffy/lzy+Fh0tFilgdFYB0QM4GACDrSFbB/fPPPydrZzbu+wSyPsOQhg6V1q2TPD2ltWulihWtjgpAOiFnAwCQdSSr4P76668zOg4AmeXNN6WPPzYHRlu8WGKkYiBbIWcDAJB1cA83kJPMny+9+qq5/P77Uvv2loYDAAAAZGcpHqVckn788UctW7ZMJ0+eVExMjMNzq1atSpfAAKSz8HBp4EBzedQoacgQa+MBkCnI2QAAWCfFV7hDQ0NVr149HThwQKtXr1ZsbKx+//13ffXVV/Lz88uIGAGk1U8/SZ06SXFxUq9eZrdyANkeORsAAGuluOB+8803NW3aNK1bt07u7u6aMWOG/vzzT3Xp0kUlSpTIiBgBpMWxY1KrVtL161KTJtKcOZILd5MAOQE5GwAAa6X4U/eRI0fUqlUrSZK7u7uuX78um82mkSNH6pNPPkn3AAGkwfnzUnCwdOaMVLWqtHKl5O5udVQAMgk5GwAAa6W44M6XL5+uXr0qSSpatKj2798vSbp8+bKioqLSNzoAqRcVJbVpI/31l1SihBQWJvn6Wh0VgExEzgYAwFrJLrhvJ+lHHnlEmzdvliR17txZw4cP16BBg9S9e3c99thjGRMlgJSJi5N69JC++07Kl88cMC0w0OqoAGQScjYAAFlDskcpf+CBB1SrVi21a9dOnTt3liS98sorcnNz065du9SxY0e9enu6IQDWMQzp2WelL76QPDyktWulSpWsjgpAJiJnAwCQNSS74P7mm280b948TZo0SW+88YY6duyogQMH6qWXXsrI+ACk1KRJ0ocfSjabtGiR9PDDVkcEIJORswEAyBqS3aW8QYMGmjt3rk6fPq33339fx48fV8OGDVW+fHm9/fbbioiIyMg4ASTHZ59Jr7xiLs+YIXXsaG08ACxBzgYAIGtI8aBpuXPnVr9+/fTNN9/or7/+UufOnfXBBx+oRIkSatu2bUbECCA5Nm2SBgwwl194wexWDiBHI2cDAGCtNE3GW7ZsWb388st69dVXlSdPHm3YsCG94gKQEnv3mlezb90yB0t76y2rIwKQxZCzAQDIfMm+h/tO27dv19y5c7Vy5Uq5uLioS5cuGnD76hqAzHP8uNSqlXTtmvToo9K8eZJLmr5LA5DNkLMBALBGigruf//9V/Pnz9f8+fN1+PBh1atXT++99566dOmi3LlzZ1SMAJJy4YIUHCxFREgPPCCtWiW5u1sdFYAsgJwNAID1kl1wt2jRQlu2bJG/v7969+6t/v37q0KFChkZG4C7uXFDatNGOnhQKl5c2rhR8vOzOioAWQA5GwCArCHZBbebm5tWrFih1q1by9XVNSNjAnAvcXHmvdq7d0t580rh4VJgoNVRAcgiyNkAAGQNyS64165dm5FxAEguw5CGDZPWrJE8PKS1a6XKla2OCkAWQs4GACBrYGQlwNm8/bY0a5Zks0kLF0oNGlgdEQAAAIBEUHADzuTzz6XRo83ladOkTp2sjQcAAABAkii4AWexebPUv7+5/Pzz0vDh1sYDAAAA4K4ouAFnsG+f1LGjdOuW1K2b2a0cAAAAQJZGwQ1kdcePSy1aSFevSo0bS/PnSy781wUAAACyOj61A1nZxYtmsR0RIVWpIq1aZY5MDgAAACDLo+AGsqobN6S2baU//5SKFZPCwsw5twEAAAA4BQpuICuKi5N69ZJ27pT8/KTwcLPoBgAAAOA0KLiBrMYwpBEjzO7j7u7SF19I991ndVQAAAAAUoiCG8hqJk+WZs40lz//XGrY0Np4AAAAAKQKBTeQlSxaJI0aZS5PnSp16WJtPAAAAABSjYIbyCq2bpX69TOXQ0KkkSOtjQcAAABAmlBwA1nBL79I7dtLsbFS165mt3IAAAAATo2CG7DaiRPmXNtXr0qNGkkLFkgu/NcEAAAAnF2W+FT/wQcfKCgoSJ6enqpTp45++OGHZG0XGhoqm82mdu3aZWyAQEa5eNEstk+flu6/X1q9WvLwsDoqAEgU+RoAgJSxvOBeunSpQkJCNHbsWO3du1dVq1ZV8+bNdfbs2btud/z4cT3//PNq0KBBJkUKpLObN6XHH5cOHJCKFpXCwqS8ea2OCgASRb4GACDlLC+4p06dqkGDBqlfv36qXLmyPvroI3l7e2vu3LlJbhMXF6eePXtq/PjxKl26dCZGC6STuDipVy/p228lPz9p40apeHGrowKAJJGvAQBIOUsL7piYGP30009q0qSJvc3FxUVNmjTR7t27k9xuwoQJKlSokAYMGJAZYQLpyzDMUchXrpTc3aU1a6QqVayOCgCSRL4GACB1cll58PPnzysuLk6FCxd2aC9cuLD+/PPPRLf59ttvNWfOHO3bty9Zx4iOjlZ0dLT9cWRkpCQpNjZWsbGxqQv8/7f/779AcrlMnSrX996TJN2aM0dG/frm6OQA0iy9zs2c2x1lRr6WyNkAkJOkx7nZGc7rlhbcKXX16lU98cQTmj17tvz9/ZO1zaRJkzR+/PgE7Zs2bZK3t3eaY9q8eXOa94Gco+g336jmtGmSpP39+ulInjzmvdsA0lVaz81RUVHpFEnOlJp8LZGzASAnSsu52Rnytc0wDMOqg8fExMjb21srVqxwGLm0T58+unz5sr744guH9fft26fq1avL1dXV3hYfHy/J7Np28OBBlSlTxmGbxL4tL168uM6fPy9fX99Uxx4bG6vNmzeradOmcnNzS/V+kHPYvv5arq1byxYbq7hhwxT/7rtWhwRkO+l1bo6MjJS/v7+uXLmSplyRXWRGvpbI2QCQk6THudkZ8rWlV7jd3d1Vo0YNbd261Z7A4+PjtXXrVg0dOjTB+hUrVtRvv/3m0Pbqq6/q6tWrmjFjhoonMuiUh4eHPBKZZsnNzS1dkm567QfZ3K+/Sp07m13HO3eW67RpcmWubSDDpPXczHndUWbka4mcDQA5UVrOzc5wTre8S3lISIj69OmjmjVrqnbt2po+fbquX7+ufv36SZJ69+6tokWLatKkSfL09NT999/vsH3e/59G6c52IMs4edKcazsyUnrkEemzzySKbQBOhnwNAEDKWV5wd+3aVefOndOYMWMUERGhatWqKTw83D4wy8mTJ+VCcQJndemSWWz/+690333miOSenlZHBQApRr4GACDlLC+4JWno0KGJdkmTpG3btt112/nz56d/QEB6uHlTatdO+uMPKTDQnGs7Xz6rowKAVCNfAwCQMnwVDWSE+Hipd29p+3bJ19cstpO4ZxEAAABA9kTBDWSE556Tli+X3NzMbuQPPGB1RAAAAAAyGQU3kN6mTpWmTzeXFyyQGje2NBwAAAAA1qDgBtJTaKh5dVuSJk+Wune3Nh4AAAAAlqHgBtLLtm1Snz7m8rBh/yu8AQAAAORIFNxAevjtN3NE8pgYqVMns1u5zWZ1VAAAAAAsRMENpNXff5tzbV+5IjVoIH3+ueTqanVUAAAAACxGwQ2kxeXLZrF96pRUqZI5Irmnp9VRAQAAAMgCKLiB1IqONruR//67FBgohYdL+fNbHRUAAACALIKCG0iN+Hipd2/pm2+kPHmksDCpRAmrowIAAACQhVBwA6nxwgvSsmWSm5u0erVUtarVEQEAAADIYii4gZSaNs0chVyS5s2THnvM2ngAAAAAZEkU3EBKLFsmhYSYy2+/LfXsaW08AAAAALIsCm4gub75RnriCXN56FCzWzkAAAAAJIGCG0iO/fulxx+XYmKkDh2k6dMlm83qqAAAAABkYRTcwL3884851/aVK1L9+tLChZKrq9VRAQAAAMjiKLiBu7l82Sy2//lHqlhRWrtW8vKyOioAAAAAToCCG0hKdLTUvr3ZnbxIESk8XMqf3+qoAAAAADgJCm4gMfHxUt++0rZtUp48UliYVLKk1VEBAAAAcCIU3EBiRo2SQkOlXLmklSulatWsjggAAACAk6HgBu40Y4b07rvm8ty5UtOm1sYDAAAAwClRcAP/tWKFNHKkuTxp0v/m3QYAAACAFKLgBm7bvl3q1UsyDGnIELNbOQAAAACkEgU3IEm//y49/vj/RiafMUOy2ayOCgAAAIATo+AGTp0y59q+fFmqV09atEhydbU6KgAAAABOjoIbOduVK2ax/fffUoUK0tq1kpeX1VEBAAAAyAYouJFzxcRIHTpIv/0mBQRI4eFSgQJWRwUAAAAgm6DgRs4UHy/16yd99ZXk4yOFhUlBQVZHBQAAACAboeBGzvTSS9LixVKuXNLKlVL16lZHBAAAACCboeBGzvP++9LkyebynDlSs2bWxgMAAAAgW6LgRs6ycqU0fLi5/MYbUu/e1sYDAAAAINui4EbOsWOH1LOnZBjSM89Io0dbHREAAACAbIyCGznDgQPS449L0dHmv++/L9lsVkcFAAAAIBuj4Eb29++/UnCwdOmS9NBD5mBprq5WRwUAAAAgm6PgRvYWGSm1aCGdPCmVLy+tWyd5e1sdFQAAAIAcgIIb2VdMjNShg/Trr1LhwlJ4uOTvb3VUAAAAAHIICm5kT/HxUv/+0tatUu7c0oYNUqlSVkcFAAAAIAeh4Eb29PLL0qJFUq5c0ooVUo0aVkcEAAAAIIeh4Eb2M3Om9Pbb5vLs2eaAaQAAAACQySi4kb2sWiUNG2Yuv/661LevpeEAAAAAyLkouJF97Nwp9ewpGYb01FNmt3IAAAAAsAgFN7KHAwekNm2kmzfNf2fOlGw2q6MCAAAAkINRcMP5nT5tzrV96ZJUp44UGmoOlgYAAAAAFqLghnOLjJRatpROnJDKlZPWr5e8va2OCgAAAAAouOHEYmKkjh2lffukQoWk8HDJ39/qqAAAAABAEgU3nJVhSAMHSlu2SLlzSxs2SKVLWx0VAAAAANhRcMM5vfKK9PnnkqurtHy5VLOm1REBAAAAgAMKbjifWbOkSZPM5dmzzQHTAAAAACCLoeCGc1mzRho61FyeMEHq18/ScAAAAAAgKRTccB67dkndu5v3bw8aJL36qtURAQAAAECSKLjhHA4elNq0kW7elFq3NruV22xWRwUAAAAASaLgRtYXESEFB0sXL0q1a0uhoVKuXFZHBQAAAAB3RcGNrO3qVallS+n4calsWWn9enMaMAAAAADI4ii4kXXFxkqdOkk//ywVLCiFh5v/AgAAAIAToOBG1mQY0sCB0qZNkre3tGGDVKaM1VEBAAAAQLJRcCNreu016bPPJFdXaflyqVYtqyMCAAAAgBSh4EbW89FH0htvmMsff2zeww0AAAAAToaCG1nLF19IQ4aYy+PGSQMGWBoOAAAAAKQWBTeyjt27pe7dpfh48/7tMWOsjggAAAAAUo2CG1nDX39JbdpIN26YXcg//FCy2ayOCgAAAABSjYIb1ouIkIKDpQsXzMHRli2TcuWyOioAAAAASBMKbljr6lWpVSvp2DFz2q/166Xcua2OCgAAAADSjIIb1omNlTp3lvbulQoWlMLDpUKFrI4KAAAAANIFBTesYRjSk09KX34peXubV7bLlrU6KgAAAABINxTcsMbYsdL8+ZKLi7R0qVS7ttURAQAAAEC6ouBG5vv4Y2niRHP5o4+k1q2tjQcAAAAAMgAFNzLXunXS4MHm8pgx0qBB1sYDAAAAABmEghuZ5/vvpa5dpfh4qX9/adw4qyMCAAAAgAxDwY3MceiQ2XX8xg2pRQuzK7nNZnVUAAAAAJBhKLiR8c6ckYKDpfPnpRo1pGXLJDc3q6MCAAAAgAyVJQruDz74QEFBQfL09FSdOnX0ww8/JLnu7Nmz1aBBA+XLl0/58uVTkyZN7ro+LHbtmnll++hRqXRpacMGycfH6qgAAKlAvgYAIGUsL7iXLl2qkJAQjR07Vnv37lXVqlXVvHlznT17NtH1t23bpu7du+vrr7/W7t27Vbx4cTVr1kynTp3K5MhxT7GxUpcu0o8/Sv7+Uni4VLiw1VEBAFKBfA0AQMpZXnBPnTpVgwYNUr9+/VS5cmV99NFH8vb21ty5cxNdf9GiRRo8eLCqVaumihUr6tNPP1V8fLy2bt2ayZHjrgxDevppaeNGyctLWr9eKlfO6qgAAKlEvgYAIOUsLbhjYmL0008/qUmTJvY2FxcXNWnSRLt3707WPqKiohQbG6v8+fNnVJhIjXHjpLlzJRcXaelSqU4dqyMCAKQS+RoAgNTJZeXBz58/r7i4OBW+o5tx4cKF9eeffyZrH6NGjVJgYKDDh4D/io6OVnR0tP1xZGSkJCk2NlaxsbGpjFz2bdOyj+zKNmeOck2YIEm6NXOmjOBgs3s5AGSw9Do3c253lBn5WiJnA0BOkh7nZmc4r1tacKfVW2+9pdDQUG3btk2enp6JrjNp0iSNHz8+QfumTZvk7e2d5hg2b96c5n1kJ4X37FHtSZMkSQc7d9afgYFSWJjFUQHIadJ6bo6KikqnSCAlL19L5GwAyInScm52hnxtacHt7+8vV1dXnTlzxqH9zJkzCggIuOu27777rt566y1t2bJFDzzwQJLrjR49WiEhIfbHkZGR9oFbfH19Ux17bGysNm/erKZNm8qNKa4kSbY9e+Q6bZps8fGK791bpWfPVmnm2gaQidLr3Hz7yipMmZGvJXI2AOQk6XFudoZ8bWnB7e7urho1amjr1q1q166dJNkHVBk6dGiS273zzjt644039OWXX6pmzZp3PYaHh4c8PDwStLu5uaVL0k2v/Ti9w4elxx+XoqKk4GC5fPqpXHhfAFgkredmzuuOMiNfS+RsAMiJ0nJudoZzuuVdykNCQtSnTx/VrFlTtWvX1vTp03X9+nX169dPktS7d28VLVpUk/6/m/Lbb7+tMWPGaPHixQoKClJERIQkycfHRz7M72yNs2el4GDp/HnpwQel5cslJ/jjBwAkH/kaAICUs7zg7tq1q86dO6cxY8YoIiJC1apVU3h4uH1glpMnT8rF5X+DqX/44YeKiYlRp06dHPYzduxYjRs3LjNDhyRdvy61bi0dOSKVKiVt2CDxQQoAsh3yNQAAKWd5wS1JQ4cOTbJL2rZt2xweHz9+POMDQvLcuiV16SLt2SMVKCCFh0v3uJcPAOC8yNcAAKSMpfNww4kZhvTMM+YI5J6e0rp1UvnyVkcFAAAAAFkGBTdSZ8IE6dNPJRcXKTRUqlvX6ogAAAAAIEuh4EbKzZkj3b7/7oMPzNHJAQAAAAAOKLiRMmFh0lNPmcsvvyw9/bS18QAAAABAFkXBjeTbs0fq3FmKi5N695Zef93qiAAAAAAgy6LgRvIcOSK1aiVFRUnNmpn3b9tsVkcFAAAAAFkWBTfu7dw5KTjY/Ld6dWnFCsnNzeqoAAAAACBLo+DG3V2/LrVuLR0+LAUFmfdw58ljdVQAAAAAkOVRcCNpt25J3bpJP/wg5c8vhYdLAQFWRwUAAAAAToGCG4kzDGnwYGn9esnTU1q3TqpQweqoAAAAAMBpUHAjca+/Ls2eLbm4SEuWSPXqWR0RAAAAADgVCm4kNG+eNGaMufz++1K7dpaGAwAAAADOiIIbjjZulAYNMpdHjza7lQMAAAAAUoyCG//z449S585SXJz0xBPSG29YHREAAAAAOC0KbpiOHpVatTKnAWvSRPr0U8lmszoqAAAAAHBaFNyQzp2TgoOls2elatWklSsld3erowIAAAAAp0bBndNFRUlt2kiHDkklS0phYZKvr9VRAQAAAIDTo+DOyW7dkrp3l77/XsqXzxwwrUgRq6MCAAAAgGyBgjunMgxp6FBp7VrJ01Nat06qVMnqqAAAAAAg26DgzqnefFP6+GNzYLTFi6X69a2OCAAAAACyFQrunGj+fOnVV83l996T2re3NBwAAAAAyI4ouHOaL7+UBg0yl0eNMruVAwAAAADSHQV3TvLTT1LHjuZgaT17mt3KAQAAAAAZgoI7pzh2TGrVSrp+XXrsMWnuXMmFXz8AAAAAZBQqrpzg/HkpOFg6c0aqWlVatUpyd7c6KgAAAADI1ii4s7uoKKltW+mvv6QSJaSwMMnX1+qoAAAAACDbo+DOzuLipB49pN27pXz5pPBwKTDQ6qgAAAAAIEeg4M6uDEN69lnpiy8kDw9p7VqpUiWrowIAAACAHIOCO7t66y3pww8lm01atEh6+GGrIwIAAACAHIWCOzv67DPp5ZfN5RkzzKnAAAAAAACZioI7u9m0SRowwFx+4QWzWzkAAAAAINNRcGcnP/9sXs2+dUvq3t3sVg4AAAAAsAQFd3Zx/LjUsqV07Zr06KPSvHmSC79eAAAAALAKFVl2cOGCFBwsRURIDzwgrVpljkwOAAAAALAMBbezu3FDattWOnhQKl5cCguT/PysjgoAAAAAcjwKbmcWFyf16CHt2iXlzStt3CgVLWp1VAAAAAAAUXA7L8OQhg+X1qyR3N2lL76Q7rvP6qgAAAAAAP+PgttZvfOO9MEHks0mLVwoPfKI1REBAAAAAP6DgtsZff659NJL5vK0aVLnztbGAwAAAABIgILb2WzeLPXvby4/95zZrRwAAAAAkOVQcDuTffukjh2lW7ekbt3MbuUAAAAAgCyJgttZnDghtWghXb0qNWokzZ8vufDrAwAAAICsiorNGVy8KAUHSxER0v33S6tXSx4eVkcFAAAAALgLCu6s7sYNqW1b6c8/pWLFzLm28+a1OioAAAAAwD1QcGdlcXFSr17Szp2Sn58UHm4W3QAAAACALI+CO6syDGnECGnVKsndXfriC+m++6yOCgAAAACQTBTcWdXkydLMmeby559LDRtaGw8AAAAAIEUouLOixYulUaPM5alTpS5drI0HAAAAAJBiFNxZzdatUt++5vLIkeYPAAAAAMDpUHBnJb/8IrVvL8XGmle1333X6ogAAAAAAKlEwZ1VnDwptWwpXb1q3q/92WeSC78eAAAAAHBWVHRZwcWLUnCw9O+/5kjka9ZIHh5WRwUAAAAASAMKbqvdvCm1aycdOCAVLSpt3CjlzWt1VAAAAACANKLgtlJcnPTEE9KOHZKvr1lsFy9udVQAAAAAgHRAwW0Vw5BCQqQVKyR3d7MbeZUqVkcFAAAAAEgnFNxWmTJFeu89c3nBAqlxY2vjAQAAAACkKwpuKyxZIr3wgrn87rtSt27WxgMAAAAASHcU3Jntq6+kPn3M5eHDzW7lAAAAAIBsh4I7M/36q9S+vRQbK3XuLE2dKtlsVkcFAAAAAMgAFNyZ5eRJqUULKTJSeuQR6bPPJBfefgAAAADIrqj4MsOlS2ax/e+/UuXK5ojknp5WRwUAAAAAyEAU3Bnt5k2pXTvpjz+kwEApPFzKl8/qqAAAAAAAGYyCOyPFx0u9e0vbt0u+vtLGjVLx4lZHBQAAAADIBBTcGem556TlyyU3N2n1aumBB6yOCAAAAACQSSi4M8rUqdL06ebyggXSo49aGg4AAAAAIHNRcGeE0FDz6rYkvfOO1L27tfEAAAAAADIdBXd627ZN6tPHXB42THr+eUvDAQAAAABYg4I7Pf32mzkieUyM1LGj2a3cZrM6KgAAAACABSi408vff5tzbV+5Ij38sLRwoeTqanVUAAAAAACL5LI6AKcUFyfbN9+o6PbtsuXOLVWvbhbbp05JlSpJX3wheXpaHSUAALgzZzduzBfiAIBMkyWucH/wwQcKCgqSp6en6tSpox9++OGu6y9fvlwVK1aUp6enqlSporCwsEyKVNKqVVJQkHI1baqaU6cqV9OmUmCg9PvvUpEiUni4lD9/5sUDAEAmcap8LSWes4OCzHYAADKB5QX30qVLFRISorFjx2rv3r2qWrWqmjdvrrNnzya6/q5du9S9e3cNGDBAP//8s9q1a6d27dpp//79GR/sqlVSp07SP/84tsfEmP8+/7xUokTGxwEAQCZzqnwtJZ2zT50y2ym6AQCZwGYYhmFlAHXq1FGtWrU0c+ZMSVJ8fLyKFy+uZ599Vi+99FKC9bt27arr169r/fr19raHHnpI1apV00cffXTP40VGRsrPz09XrlyRr69v8gONizO/Fb8zcf9X8eLSsWN0VQMAi8TGxiosLEwtW7aUm5tbqveT6lyRjWV2vpYyMGfbbFKxYuRsALBQeuRsZ8jXll7hjomJ0U8//aQmTZrY21xcXNSkSRPt3r070W12797tsL4kNW/ePMn1082OHXcvtiVz4LQdOzI2DgAAMplT5Wvp3jnbMMjZAIBMYemgaefPn1dcXJwKFy7s0F64cGH9+eefiW4TERGR6PoRERGJrh8dHa3o6Gj74ytXrkiSLl68qNjY2GTHavvrr2S9Wbf++ktGlSrJ3i8AIP3ExsYqKipKFy5cSNMV7qtXr0qSLO4ElmVkRr6WyNkAkJOkR852hnyd7UcpnzRpksaPH5+gvVSpUhlzwKeeMn8AAE7v6tWr8vPzszqMHIOcDQBIjaycry0tuP39/eXq6qozZ844tJ85c0YBAQGJbhMQEJCi9UePHq2QkBD74/j4eF28eFEFChSQzWZLdeyRkZEqXry4/v777yx7vwAA5DTpdW42DENXr15VYGBgOkbnvDIjX0vkbADISdLj3OwM+drSgtvd3V01atTQ1q1b1a5dO0lmct26dauGDh2a6DZ169bV1q1bNWLECHvb5s2bVbdu3UTX9/DwkIeHh0Nb3rx50yN8SZKvry/JGwCymPQ4N2fVb8qtkBn5WiJnA0BOlNZzc1bP15Z3KQ8JCVGfPn1Us2ZN1a5dW9OnT9f169fVr18/SVLv3r1VtGhRTZo0SZI0fPhwNWzYUFOmTFGrVq0UGhqqH3/8UZ988omVLwMAgGyNfA0AQMpZXnB37dpV586d05gxYxQREaFq1aopPDzcPtDKyZMn5eLyv8HU69Wrp8WLF+vVV1/Vyy+/rHLlymnNmjW6//77rXoJAABke+RrAABSzvJ5uJ1VdHS0Jk2apNGjRyfo/gYAsAbnZiSGvwsAyHpyyrmZghsAAAAAgAzgcu9VAAAAAABASlFwAwAAAACQASi4AQAAAADIAE5fcNtstrv+jBs3Lk37XrNmTbqtBwDOICucV2976qmn5OrqquXLl6f6mMg6ssLfFjkbQHaSFc6rt5GzE2f5tGBpdfr0afvy0qVLNWbMGB08eNDe5uPjY0VYAOC0ssp5NSoqSqGhoXrxxRc1d+5cde7cOVOOm5SYmBi5u7tbGoOzyyp/WwCQXWSV8yo5O2lOf4U7ICDA/uPn5yebzebQFhoaqkqVKsnT01MVK1bUrFmz7NvGxMRo6NChKlKkiDw9PVWyZElNmjRJkhQUFCRJat++vWw2m/1xSsXHx2vChAkqVqyYPDw87POWJicGwzA0btw4lShRQh4eHgoMDNSwYcNS90YBQDJllfPq8uXLVblyZb300kvavn27/v77b4fno6OjNWrUKBUvXlweHh4qW7as5syZY3/+999/V+vWreXr66s8efKoQYMGOnLkiCSpUaNGGjFihMP+2rVrp759+9ofBwUFaeLEierdu7d8fX315JNPSpJGjRql8uXLy9vbW6VLl9Zrr72m2NhYh32tW7dOtWrVkqenp/z9/dW+fXtJ0oQJExKdh7patWp67bXX7vp+ZAdZ5W8rKeRsAM4mq5xXydl3YWQj8+bNM/z8/OyPFy5caBQpUsRYuXKlcfToUWPlypVG/vz5jfnz5xuGYRiTJ082ihcvbmzfvt04fvy4sWPHDmPx4sWGYRjG2bNnDUnGvHnzjNOnTxtnz55N8riSjNWrVyf63NSpUw1fX19jyZIlxp9//mm8+OKLhpubm/HXX3/dM4bly5cbvr6+RlhYmHHixAnj+++/Nz755JN0eKcAIHmsOq8ahmE0aNDAmDlzpmEYhtGxY0djwoQJDs936dLFKF68uLFq1SrjyJEjxpYtW4zQ0FDDMAzjn3/+MfLnz2906NDB2LNnj3Hw4EFj7ty5xp9//mkYhmE0bNjQGD58uMP+Hn/8caNPnz72xyVLljR8fX2Nd9991zh8+LBx+PBhwzAMY+LEicbOnTuNY8eOGWvXrjUKFy5svP322/bt1q9fb7i6uhpjxowx/vjjD2Pfvn3Gm2++aRiGYfz999+Gi4uL8cMPP9jX37t3r2Gz2YwjR47c9f3IbsjZAJC+yNlZM2dn64K7TJky9j+a2yZOnGjUrVvXMAzDePbZZ41HH33UiI+PT3R/d0vKyV0vMDDQeOONNxzaatWqZQwePPieMUyZMsUoX768ERMTc88YACAjWHVe/euvvww3Nzfj3LlzhmEYxurVq41SpUrZ93vw4EFDkrF58+ZEtx89erRRqlSpJM+fyU3e7dq1u2eskydPNmrUqGF/XLduXaNnz55Jrt+iRQvjmWeesT9+9tlnjUaNGt3zONkNORsA0hc5O2vmbKfvUp6U69ev68iRIxowYIB8fHzsP6+//rq9e0Lfvn21b98+VahQQcOGDdOmTZvSNYbIyEj9+++/ql+/vkN7/fr1deDAgXvG0LlzZ924cUOlS5fWoEGDtHr1at26dStdYwSA5MrM8+rcuXPVvHlz+fv7S5JatmypK1eu6KuvvpIk7du3T66urmrYsGGi2+/bt08NGjSQm5tbqo5/W82aNRO0LV26VPXr11dAQIB8fHz06quv6uTJkw7Hfuyxx5Lc56BBg7RkyRLdvHlTMTExWrx4sfr375+mOJ0dORsA0hc525QVcrbTD5qWlGvXrkmSZs+erTp16jg85+rqKkl68MEHdezYMW3cuFFbtmxRly5d1KRJE61YsSLT4rxbDMWLF9fBgwe1ZcsWbd68WYMHD9bkyZP1zTffpPkPEgBSKrPOq3FxcVqwYIEiIiKUK1cuh/a5c+fqsccek5eX1133ca/nXVxcZBiGQ9ud93RJUu7cuR0e7969Wz179tT48ePVvHlz+fn5KTQ0VFOmTEn2sdu0aSMPDw+tXr1a7u7uio2NVadOne66TXZHzgaA9EXOzjo5O9sW3IULF1ZgYKCOHj2qnj17Jrmer6+vunbtqq5du6pTp04KDg7WxYsXlT9/frm5uSkuLi7VMfj6+iowMFA7d+50+EZn586dql27drJi8PLyUps2bdSmTRsNGTJEFStW1G+//aYHH3ww1XEBQGpk1nk1LCxMV69e1c8//2z/UCBJ+/fvV79+/XT58mVVqVJF8fHx+uabb9SkSZME+3jggQe0YMECxcbGJlrsFCxY0GFk17i4OO3fv1+NGze+a2y7du1SyZIl9corr9jbTpw4keDYW7duVb9+/RLdR65cudSnTx/NmzdP7u7u6tat2z0TfnZHzgaA9EXOzjo5O9sW3JI0fvx4DRs2TH5+fgoODlZ0dLR+/PFHXbp0SSEhIZo6daqKFCmi6tWry8XFRcuXL1dAQIDy5s0ryRztbuvWrapfv748PDyUL1++JI917Ngx7du3z6GtXLlyeuGFFzR27FiVKVNG1apV07x587Rv3z4tWrRIku4aw/z58xUXF6c6derI29tbCxculJeXl0qWLJlRbxkA3FVmnFfnzJmjVq1aqWrVqg7tlStX1siRI7Vo0SINGTJEffr0Uf/+/fXee++patWqOnHihM6ePasuXbpo6NChev/999WtWzeNHj1afn5++u6771S7dm1VqFBBjz76qEJCQrRhwwaVKVNGU6dO1eXLl+/5+suVK6eTJ08qNDRUtWrV0oYNG7R69WqHdcaOHavHHntMZcqUUbdu3XTr1i2FhYVp1KhR9nUGDhyoSpUqSTILOpCzASC9kbOzSM5O0R3fWdydAwUYhmEsWrTIqFatmuHu7m7ky5fPeOSRR4xVq1YZhmEYn3zyiVGtWjUjd+7chq+vr/HYY48Ze/futW+7du1ao2zZskauXLmMkiVLJnlcSYn+7Nixw4iLizPGjRtnFC1a1HBzczOqVq1qbNy40b7t3WJYvXq1UadOHcPX19fInTu38dBDDxlbtmxJvzcMAO4hs8+rERERRq5cuYxly5YlGs8zzzxjVK9e3TAMw7hx44YxcuRIo0iRIoa7u7tRtmxZY+7cufZ1f/nlF6NZs2aGt7e3kSdPHqNBgwb2UUVjYmKMZ555xsifP79RqFAhY9KkSYkOwDJt2rQEMbzwwgtGgQIFDB8fH6Nr167GtGnTErxHK1eutL9H/v7+RocOHRLsp0GDBsZ9992X6OvMCcjZAJC+yNnTEsSQFXK2zTDu6BAPAAAylGEYKleunAYPHqyQkBCrwwEAAElIa87O1l3KAQDIas6dO6fQ0FBFREQkec8YAACwXnrkbApuAAAyUaFCheTv769PPvnkrvcZAwAAa6VHzqZLOQAAAAAAGcDF6gAAAAAAAMiOKLgBAAAAAMgAFNwAAAAAAGQACm4AAAAAADIABTcAAAAAABmAghvAPdlsNq1Zs8bqMAAAwF2Qr4Gsh4IbcBJ9+/aVzWbT008/neC5IUOGyGazqW/fvsna17Zt22Sz2XT58uVkrX/69Gm1aNEiBdECAJAzka8B/BcFN+BEihcvrtDQUN24ccPedvPmTS1evFglSpRI9+PFxMRIkgICAuTh4ZHu+wcAIDsiXwO4jYIbcCIPPvigihcvrlWrVtnbVq1apRIlSqh69er2tvj4eE2aNEmlSpWSl5eXqlatqhUrVkiSjh8/rsaNG0uS8uXL5/BNe6NGjTR06FCNGDFC/v7+at68uaSEXdT++ecfde/eXfnz51fu3LlVs2ZNff/995KkX375RY0bN1aePHnk6+urGjVq6Mcff8zItwUAgCyFfA3gtlxWBwAgZfr376958+apZ8+ekqS5c+eqX79+2rZtm32dSZMmaeHChfroo49Urlw5bd++Xb169VLBggX18MMPa+XKlerYsaMOHjwoX19feXl52bddsGCBnnnmGe3cuTPR41+7dk0NGzZU0aJFtXbtWgUEBGjv3r2Kj4+XJPXs2VPVq1fXhx9+KFdXV+3bt09ubm4Z94YAAJAFka8BSBTcgNPp1auXRo8erRMnTkiSdu7cqdDQUHsCj46O1ptvvqktW7aobt26kqTSpUvr22+/1ccff6yGDRsqf/78kqRChQopb968DvsvV66c3nnnnSSPv3jxYp07d0579uyx76ds2bL250+ePKkXXnhBFStWtO8PAICchnwNQKLgBpxOwYIF1apVK82fP1+GYahVq1by9/e3P3/48GFFRUWpadOmDtvFxMQ4dGNLSo0aNe76/L59+1S9enV78r5TSEiIBg4cqM8//1xNmjRR586dVaZMmWS8MgAAsg/yNQCJghtwSv3799fQoUMlSR988IHDc9euXZMkbdiwQUWLFnV4LjkDqeTOnfuuz/+3O1tixo0bpx49emjDhg3auHGjxo4dq9DQULVv3/6exwYAIDshXwNg0DTACQUHBysmJkaxsbH2gVJuq1y5sjw8PHTy5EmVLVvW4ad48eKSJHd3d0lSXFxcio/9wAMPaN++fbp48WKS65QvX14jR47Upk2b1KFDB82bNy/FxwEAwNmRrwFQcANOyNXVVQcOHNAff/whV1dXh+fy5Mmj559/XiNHjtSCBQt05MgR7d27V++//74WLFggSSpZsqRsNpvWr1+vc+fO2b9lT47u3bsrICBA7dq1086dO3X06FGtXLlSu3fv1o0bNzR06FBt27ZNJ06c0M6dO7Vnzx5VqlQpXV8/AADOgHwNgIIbcFK+vr7y9fVN9LmJEyfqtdde06RJk1SpUiUFBwdrw4YNKlWqlCSpaNGiGj9+vF566SUVLlzY3t0tOdzd3bVp0yYVKlRILVu2VJUqVfTWW2/J1dVVrq6uunDhgnr37q3y5curS5cuatGihcaPH58urxkAAGdDvgZyNpthGIbVQQAAAAAAkN1whRsAAAAAgAxAwQ0AAAAAQAag4AYAAAAAIANQcAMAAAAAkAEouAEAAAAAyAAU3AAAAAAAZAAKbgAAAAAAMgAFNwAAAAAAGYCCGwAAAACADEDBDQAAAABABqDgBgAAAAAgA1BwAwAAAACQAf4P+Bn2z1/y8pkAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "metrics = ['Test Loss', 'Test Accuracy']\n",
        "values = [test_loss, test_accuracy]\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "# Plot gabungan garis antara loss dan accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(metrics, values, marker='o', color='red')\n",
        "plt.ylim(0, 1)\n",
        "plt.title('Test Loss and Accuracy')\n",
        "plt.ylabel('Value')\n",
        "plt.xlabel('Metrics')\n",
        "plt.grid(True)\n",
        "\n",
        "# Plot terpisah untuk loss dan accuracy dengan legend\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(['Test Loss'], [test_loss], marker='o', color='red', label='Test Loss')\n",
        "plt.plot(['Test Accuracy'], [test_accuracy], marker='o', color='green', label='Test Accuracy')\n",
        "plt.ylim(0, 1)\n",
        "plt.title('Model Evaluation Metrics')\n",
        "plt.ylabel('Value')\n",
        "plt.xlabel('Metrics')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09b490f9-6c05-4a05-b0b0-4237917eb71b",
      "metadata": {
        "id": "09b490f9-6c05-4a05-b0b0-4237917eb71b"
      },
      "source": [
        "# Model Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58b91d80-6022-4be6-ae72-21a0684e6fdd",
      "metadata": {
        "id": "58b91d80-6022-4be6-ae72-21a0684e6fdd"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "\n",
        "model = tf.keras.models.load_model('resnet_model.keras')\n",
        "\n",
        "dataset_path = 'Dataset'  # Pastikan ini path dataset setelah split (train/val)\n",
        "\n",
        "# Pakai kelas sesuai kondisi awal\n",
        "class_names = ['berat', 'sedang', 'sehat-ringan']\n",
        "\n",
        "def prepare_image(image_path):\n",
        "    \"\"\"Preprocesses the image for model prediction.\"\"\"\n",
        "    img = load_img(image_path, target_size=(224, 224))  # Ukuran sesuai model ResNet50\n",
        "    img_array = img_to_array(img)\n",
        "    img_array = preprocess_input(img_array)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    return img_array\n",
        "\n",
        "def predict_image(image_path):\n",
        "    \"\"\"Predicts the class and confidence of an image.\"\"\"\n",
        "    img_array = prepare_image(image_path)\n",
        "    predictions = model.predict(img_array)\n",
        "    predicted_class_idx = np.argmax(predictions, axis=1)[0]\n",
        "    predicted_class = class_names[predicted_class_idx]\n",
        "    confidence = np.max(predictions)\n",
        "    return predicted_class, confidence\n",
        "\n",
        "# Pilih random satu gambar dari tiap kelas\n",
        "sample_images = []\n",
        "for class_dir in class_names:\n",
        "    class_dir_path = os.path.join(dataset_path, class_dir)\n",
        "    images_in_class = [f for f in os.listdir(class_dir_path) if f.lower().endswith(('.jpg','.png','.jpeg'))]\n",
        "    random_image = random.choice(images_in_class)\n",
        "    sample_images.append(os.path.join(class_dir_path, random_image))\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i, image_path in enumerate(sample_images[:6]):\n",
        "    actual_class = os.path.basename(os.path.dirname(image_path))\n",
        "    predicted_class, confidence = predict_image(image_path)\n",
        "\n",
        "    plt.subplot(2, 3, i + 1)\n",
        "    img = load_img(image_path)\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"Actual: {actual_class}\\nPredicted: {predicted_class}\\nConfidence: {confidence:.2%}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"predicted_images_grid.png\", format=\"png\", dpi=300)  # Save with high resolution\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}